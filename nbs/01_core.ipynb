{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Code\n",
    "\n",
    "> This is the ‘literate’ source code for ***Scholaris***, a library to set up an advanced research assistant leveraging function calling capabilities with LLMs on your local computer. ***Scholaris*** was built to run with [Llama 3.1 8B](https://ollama.com/library/llama3.1) using the [ollama](https://ollama.com/) framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "This notebook was written using [nbdev](https://nbdev.fast.ai/) to show how the source code was created, to facilitate testing, continuous integration and documentation, all in a single context. Do not modify special comments, such as `#| default_exp`, `#| hide`, or `#| export`. These special comments serve as markdown directives and define the module name and content, and which code or markdown cells are rendered for documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "## Installation\n",
    "\n",
    "First, download and install Ollama on your computer. Go to [Download Ollama](https://ollama.com/download) and follow the instructions for your operating system. Then pull and run [llama3.1](https://ollama.com/library/llama3.1) (parameters: 8B, quantization: Q4_0, size: 4.7 GB) according to the ollama documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "## Using the Ollama API\n",
    "\n",
    "The code in this section is an application of the Ollama Python library. It is written to demonstrate the basic low-level functionality of the Ollama API, and should help the reader understand the basics underpinning the Scholaris library. Make sure to also check out the [blog post on tool support](https://ollama.com/blog/tool-support) on the official Ollama website. If you are already familiar with the Ollama API, you can skip this section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### Check if the ollama app is running and list all available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import ollama\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Alternatively, use the Ollama Python library to get the list and size of available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "errors = []\n",
    "try:\n",
    "    installed_models = [model for model in ollama.list()[\"models\"]]\n",
    "    for model in installed_models:\n",
    "        size = model[\"size\"] / (1024 ** 3)\n",
    "        # print(f\"{model[\"name\"]} \\t{size:.2f} GB\")\n",
    "    server_is_available = True\n",
    "except Exception as e:\n",
    "    print(f\"{e}. Is the ollama app running?\")\n",
    "    server_is_available = False\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### Using the basic chat functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42."
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# with stream=True, the response is streamed in chunks\n",
    "sys_message = \"\"\"You are a helpful AI assistant. Respond with the shortest possible answers while maintaining clarity and accuracy. \n",
    "Avoid unnecessary details, explanations, or pleasantries. Be direct and to the point in all responses.\n",
    "\"\"\" # For testing purposes & CI, we are looking for short responses.\n",
    "\n",
    "prompt = \"According to 'The Hitchhiker's Guide to the Galaxy' by Douglas Adams, what is the meaning of life?\"\n",
    "response = None\n",
    "try:\n",
    "    response = ollama.chat(\n",
    "        model='llama3.1', \n",
    "        messages=[\n",
    "            {'role': \"system\", 'content': sys_message},\n",
    "            {'role': 'user',\n",
    "            'content': prompt.format(str=prompt)} # Use built-in formatting to insert the prompt\n",
    "            ],\n",
    "        stream=True, # Set to True to stream the response\n",
    "        )  \n",
    "    for chunk in response:\n",
    "        print(chunk['message']['content'], end='', flush=True)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# with stream=False, the response is returned as a single dictionary object\n",
    "try:\n",
    "    response = ollama.chat(\n",
    "        model='llama3.1', \n",
    "        messages=[\n",
    "            {'role': \"system\", 'content': sys_message},\n",
    "            {'role': 'user',\n",
    "            'content': prompt.format(str=prompt)} # Use built-in formatting to insert the prompt\n",
    "            ],\n",
    "        stream=False, # Set to True to stream the response\n",
    "        )  \n",
    "    print(response['message']['content'])\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "type(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.1',\n",
       " 'created_at': '2024-09-11T19:43:53.157387Z',\n",
       " 'message': {'role': 'assistant', 'content': '42.'},\n",
       " 'done_reason': 'stop',\n",
       " 'done': True,\n",
       " 'total_duration': 145121625,\n",
       " 'load_duration': 44232167,\n",
       " 'prompt_eval_count': 80,\n",
       " 'prompt_eval_duration': 33679000,\n",
       " 'eval_count': 3,\n",
       " 'eval_duration': 65582000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "def ollama_chat(promot:str):\n",
    "    response = ollama.chat(\n",
    "        model='llama3.1', \n",
    "        messages=[\n",
    "            {'role': 'user',\n",
    "            'content': prompt} # Use built-in formatting to insert the prompt\n",
    "            ],\n",
    "        stream=False, # Set to True to stream the response\n",
    "        )\n",
    "    history.append(response['message']['content'])\n",
    "    return response['message']['content']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama_chat(\"According to 'The Hitchhiker's Guide to the Galaxy' by Douglas Adams, what is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### Demonstrate and test function calling\n",
    "\n",
    "To get started, we will go through function / tool calling step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 1. Define a function to call\n",
    "For demonstration purposes, we will define a simple addition tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def add_two_integers(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    A function to add two numbers.\n",
    "\n",
    "    Args:\n",
    "        a (int): First number.\n",
    "        b (int): Second number.\n",
    "\n",
    "    Returns:\n",
    "        int: Sum of the two numbers.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If inputs are not integers.\n",
    "    \"\"\"\n",
    "    if not isinstance(a, int) or not isinstance(b, int):\n",
    "        raise TypeError(\"Both inputs must be integers\")\n",
    "    \n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 2. Print the function name, docstring and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function name: add_two_integers \n",
      "---\n",
      "Docstring: \n",
      "    A function to add two numbers.\n",
      "\n",
      "    Args:\n",
      "        a (int): First number.\n",
      "        b (int): Second number.\n",
      "\n",
      "    Returns:\n",
      "        int: Sum of the two numbers.\n",
      "\n",
      "    Raises:\n",
      "        TypeError: If inputs are not integers.\n",
      "     \n",
      "---\n",
      "Annotations: {'a': <class 'int'>, 'b': <class 'int'>, 'return': <class 'int'>} \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "print(\"Function name:\", add_two_integers.__name__, \"\\n---\")\n",
    "print(\"Docstring:\", add_two_integers.__doc__,\"\\n---\")\n",
    "print(\"Annotations:\", add_two_integers.__annotations__,\"\\n---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 3. Define the JSON schema for the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "args = {\n",
    "    \"a\": {\n",
    "        \"type\": \"integer\",\n",
    "        \"description\": \"First number\"\n",
    "    },\n",
    "    \"b\": {\n",
    "        \"type\": \"integer\",\n",
    "        \"description\": \"Second number\"\n",
    "    }\n",
    "}\n",
    "\n",
    "addition_tool_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": add_two_integers.__name__,\n",
    "        \"description\": \"Function to add two numbers\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": args,\n",
    "            \"required\": [\"a\", \"b\"],\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 4. First API call: send query and JSON schema of the function to the model\n",
    "\n",
    "We will use random numbers for the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the sum of 2372167 and 7765676?\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "a = random.randint(1, 10000000)\n",
    "b = random.randint(1, 10000000)\n",
    "prompt = f\"What is the sum of {a} and {b}?\"\n",
    "print(prompt)\n",
    "\n",
    "sys_message = \"You are a an assistant provided with tools to help you answer questions.\"\n",
    "\n",
    "messages=[\n",
    "    {'role': \"system\", 'content': sys_message},\n",
    "    {'role': 'user',\n",
    "    'content': prompt.format(str=prompt)} # Use built-in formatting to insert the prompt\n",
    "]\n",
    "\n",
    "try: #\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.1\",\n",
    "        messages=messages,\n",
    "        tools=[addition_tool_schema],\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 5. Get the function return value with the arguments from the LLM response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool names: add_two_integers\n",
      "args: {'a': 2372167, 'b': 7765676}\n",
      "return: 10137843\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "try:\n",
    "    for tool in response['message'].get('tool_calls'):\n",
    "        print(\"tool names:\", tool['function'].get('name'))\n",
    "        print(\"args:\", tool['function'].get('arguments'))\n",
    "        # print first arg\n",
    "        a = tool['function'].get('arguments').get('a')\n",
    "        b = tool['function'].get('arguments').get('b')\n",
    "        output = f\"return: {add_two_integers(a, b)}\"\n",
    "        print(output)\n",
    "except Exception as e:\n",
    "    print(f\"{e}. If you get an error message, try re-running the cell above.\")\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 6. Add the output to the messages list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "try:\n",
    "    messages.append(\n",
    "        {\n",
    "            'role': 'tool',\n",
    "            'content': output,\n",
    "        }\n",
    "    )\n",
    "    messages\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}. Try fixing the error by re-running the two cells above.\")\n",
    "    errors.append(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 7. Second API call: get the final reponse from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of 2372167 and 7765676 is 10137843."
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "try:\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.1\",\n",
    "        messages=messages,\n",
    "        stream=True,\n",
    "    )\n",
    "    for chunk in response:\n",
    "        print(chunk['message']['content'], end='', flush=True)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Next, we will define helper functions to siplify the steps above. Documentation continues below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "The Ollama framework supports [tool calling](https://ollama.com/blog/tool-support) (also referred to as function calling) with models such as Llama 3.1. To leverage function calling, we need to pass the JSON schema for any given function as an argument to the LLM. This is the information based on which the LLM infers the most appropriate tool to use given a prompt, and which parameters/arguments to pass to a function. To simplify the process of generating JSON schemas, use the helper and decorator functions defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import inspect\n",
    "from typing import Callable, Dict, List, Tuple, Optional, Any, Union \n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_json_schema(func: Callable) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate a JSON schema for the given function based on its annotations and docstring.\n",
    "    \n",
    "    Args:\n",
    "        func (Callable): The function to generate a schema for.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: A JSON schema for the function.\n",
    "    \"\"\"\n",
    "    annotations = func.__annotations__\n",
    "    doc = inspect.getdoc(func)\n",
    "    \n",
    "    schema = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": func.__name__,\n",
    "            \"description\": \"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if doc:\n",
    "        lines = doc.split('\\n')\n",
    "        description = []\n",
    "        arg_descriptions = {}\n",
    "        in_args_section = False\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.lower().startswith('args:'):\n",
    "                in_args_section = True\n",
    "                continue\n",
    "            elif line.lower().startswith('returns:') or line.lower().startswith('raises:'):\n",
    "                break\n",
    "            \n",
    "            if not in_args_section:\n",
    "                description.append(line)\n",
    "            else:\n",
    "                parts = line.split(':')\n",
    "                if len(parts) >= 2:\n",
    "                    # print(parts) # Uncomment for debugging\n",
    "                    arg_name = parts[0].split(' ')[0].strip()\n",
    "                    arg_desc = ':'.join(parts[1:]).strip()\n",
    "                    # print(arg_name, arg_desc) # Uncomment for debugging\n",
    "                    arg_descriptions[arg_name] = arg_desc\n",
    "                    # print(arg_descriptions) # Uncomment for debugging\n",
    "                    if 'optional' not in parts[0].lower():\n",
    "                        schema['function']['parameters']['required'].append(arg_name)\n",
    "\n",
    "        \n",
    "        schema['function']['description'] = ' '.join(description).strip()\n",
    "    \n",
    "    for arg, arg_type in annotations.items():\n",
    "        if arg != 'return':\n",
    "            schema['function']['parameters']['properties'][arg] = {\n",
    "                \"type\": _get_type(arg_type),\n",
    "                \"description\": arg_descriptions.get(arg, \"\")\n",
    "            }\n",
    "    \n",
    "    return schema\n",
    "\n",
    "def _get_type(arg_type):\n",
    "    if 'List' in str(arg_type):\n",
    "        return \"list\"\n",
    "    elif 'Optional' in str(arg_type):\n",
    "        return \"optional\"\n",
    "    elif arg_type == int:\n",
    "        return \"integer\"\n",
    "    elif arg_type == str:\n",
    "        return \"string\"\n",
    "    elif arg_type == float:\n",
    "        return \"number\"\n",
    "    elif arg_type == bool:\n",
    "        return \"boolean\"\n",
    "    else:\n",
    "        return \"object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import functools\n",
    "from typing import TypeVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "T = TypeVar('T', bound=Callable)\n",
    "\n",
    "def json_schema_decorator(func: T) -> T:\n",
    "    \"\"\"\n",
    "    Decorator to generate and attach a JSON schema to a function.\n",
    "    \n",
    "    Args:\n",
    "        func (Callable): The function to decorate.\n",
    "    \n",
    "    Returns:\n",
    "        Callable: The decorated function with an attached JSON schema.\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        return func(*args, **kwargs)\n",
    "    \n",
    "    schema = generate_json_schema(func)\n",
    "    wrapper.json_schema = schema  # Attach the schema dictionary directly\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "The following code cells are for testing purposes only. They are not part of the final library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'add_two_integers',\n",
       "  'description': 'A function to add two numbers.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'a': {'type': 'integer', 'description': 'First number.'},\n",
       "    'b': {'type': 'integer', 'description': 'Second number.'}},\n",
       "   'required': ['a', 'b']}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "@json_schema_decorator\n",
    "def add_two_integers(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    A function to add two numbers.\n",
    "\n",
    "    Args:\n",
    "        a (int): First number.\n",
    "        b (int): Second number.\n",
    "\n",
    "    Returns:\n",
    "        int: Sum of the two numbers.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If inputs are not integers.\n",
    "    \"\"\"\n",
    "    if not isinstance(a, int) or not isinstance(b, int):\n",
    "        raise TypeError(\"Both inputs must be integers\")\n",
    "    \n",
    "    return a + b\n",
    "\n",
    "assert generate_json_schema(add_two_integers) == add_two_integers.json_schema\n",
    "assert generate_json_schema(add_two_integers)['function']['name'] == \"add_two_integers\"\n",
    "assert generate_json_schema(add_two_integers)['function']['description'] == \"A function to add two numbers.\"\n",
    "assert generate_json_schema(add_two_integers)['function']['parameters']['properties']['a']['description'] == \"First number.\"\n",
    "assert generate_json_schema(add_two_integers)['function']['parameters']['properties']['b']['description'] == \"Second number.\"\n",
    "assert generate_json_schema(add_two_integers)['function']['parameters']['properties']['a']['type'] == \"integer\"\n",
    "assert generate_json_schema(add_two_integers)['function']['parameters']['properties']['b']['type'] == \"integer\"\n",
    "assert generate_json_schema(add_two_integers)['function']['parameters']['required'] == ['a', 'b']\n",
    "add_two_integers.json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'multiply_two_integers',\n",
       "  'description': 'A function to multiply two numbers.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'a': {'type': 'integer', 'description': 'First number.'},\n",
       "    'b': {'type': 'integer', 'description': 'Second number.'}},\n",
       "   'required': ['a', 'b']}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "# Generate another JSON schema for a different function for testing purposes\n",
    "@json_schema_decorator\n",
    "def multiply_two_integers(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    A function to multiply two numbers.\n",
    "\n",
    "    Args:\n",
    "        a (int): First number.\n",
    "        b (int): Second number.\n",
    "\n",
    "    Returns:\n",
    "        int: Product of the two numbers.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If inputs are not integers.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(a, int) or not isinstance(b, int):\n",
    "        raise TypeError(\"Both inputs must be integers\")\n",
    "    \n",
    "    return a * b\n",
    "\n",
    "assert generate_json_schema(multiply_two_integers) == multiply_two_integers.json_schema\n",
    "assert generate_json_schema(multiply_two_integers)['function']['parameters']['properties']['a']['description'] == \"First number.\"\n",
    "assert generate_json_schema(multiply_two_integers)['function']['parameters']['properties']['b']['description'] == \"Second number.\"\n",
    "assert generate_json_schema(multiply_two_integers)['function']['parameters']['required'] == ['a', 'b']\n",
    "multiply_two_integers.json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'process_data',\n",
       "  'description': 'Process a list of integers based on an optional threshold.  This function filters and modifies the input list of integers. If a threshold is provided, it keeps only the numbers above the threshold. If no threshold is given, it returns the original list.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'data': {'type': 'list',\n",
       "     'description': 'A list of integers to process.'},\n",
       "    'threshold': {'type': 'optional',\n",
       "     'description': 'The minimum value to keep. Defaults to None.'}},\n",
       "   'required': ['data']}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "# Test decorator with an optional argument\n",
    "@json_schema_decorator\n",
    "def process_data(data: List[int], threshold: Optional[int] = None) -> List[int]:\n",
    "    \"\"\"\n",
    "    Process a list of integers based on an optional threshold.\n",
    "\n",
    "    This function filters and modifies the input list of integers.\n",
    "    If a threshold is provided, it keeps only the numbers above the threshold.\n",
    "    If no threshold is given, it returns the original list.\n",
    "\n",
    "    Args:\n",
    "        data (List[int]): A list of integers to process.\n",
    "        threshold (Optional[int], optional): The minimum value to keep. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        List[int]: A list of processed integers.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input data is empty.\n",
    "\n",
    "    Example:\n",
    "        >>> process_data([1, 5, 3, 7, 2], threshold=3)\n",
    "        [5, 7]\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        raise ValueError(\"Input data cannot be empty\")\n",
    "\n",
    "    if threshold is None:\n",
    "        return data\n",
    "    else:\n",
    "        return [num for num in data if num > threshold]\n",
    "\n",
    "assert generate_json_schema(process_data) == process_data.json_schema\n",
    "assert generate_json_schema(process_data)['function']['name'] == \"process_data\"\n",
    "assert \"Process a list of integers based\" in generate_json_schema(process_data)['function']['description']\n",
    "assert \"If no threshold is given, it returns the original list.\" in generate_json_schema(process_data)['function']['description']\n",
    "assert generate_json_schema(process_data)['function']['parameters']['properties']['data']['description'] == \"A list of integers to process.\"\n",
    "assert generate_json_schema(process_data)['function']['parameters']['properties']['threshold']['description'] == \"The minimum value to keep. Defaults to None.\"\n",
    "assert generate_json_schema(process_data)['function']['parameters']['required'] == ['data']\n",
    "process_data.json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the sum of 1303847 and 8919027?\n",
      "[{'function': {'name': 'add_two_integers', 'arguments': {'a': 1303847, 'b': 8919027}}}]\n",
      "What is the product of 1303847 and 8919027?\n",
      "[{'function': {'name': 'multiply_two_integers', 'arguments': {'a': 1303847, 'b': 8919027}}}]\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# In this code block, we will test tool use. We provide the LLM with multiple tools and let it decide which tool to use.\n",
    "a = random.randint(1, 10000000)\n",
    "b = random.randint(1, 10000000)\n",
    "prompts = [f\"What is the sum of {a} and {b}?\", f\"What is the product of {a} and {b}?\"]\n",
    "\n",
    "sys_message = \"You are a an assistant provided with tools to help you answer questions.\"\n",
    "\n",
    "for prompt in prompts:\n",
    "    messages=[\n",
    "        {'role': \"system\", 'content': sys_message},\n",
    "        {'role': 'user', 'content': prompt},\n",
    "    ]\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.1\",\n",
    "            messages=messages,\n",
    "            tools=[add_two_integers.json_schema, multiply_two_integers.json_schema],\n",
    "        )\n",
    "\n",
    "        print(prompt)\n",
    "        print(response.get('message').get('tool_calls'))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        errors.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local file processing: listing, content extraction, and summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "Below are the core functions the assistant can call. With these functions, the assistant will be able to get a list of file names in a specific data directory, can extract content from these files, and summarize them.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Note that for the json_schema_decorator() function to work properly, the function definitions require type hints and docstrings as shown below. Intentionally, docstrings are verbose, function names are descriptive, and type hints are explicitly set. This is because the LLM will make function calling decisions based on the function name, type annotations, and information in the docstring. \n",
    "\n",
    "It's crucial to understand that this metadata (function name, type hints, and docstring) is all the information the LLM has access to when deciding which function to call and how to use it. The LLM does not have access to or information about the actual source code or implementation of the functions (unless explicitly provided). Therefore, the metadata must be comprehensive and accurate to ensure proper function selection and usage by the LLM.\n",
    "\n",
    "We start by defining a tool that retrieves a list of file names with specified extensions in a specific data directory the assistant has access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def get_file_names(ext: str = \"pdf, txt\") -> str:\n",
    "    \"\"\"Retrieves a list of file names with specified extensions in a local data directory the assistant has access to on the user's computer.\n",
    "\n",
    "    Args:\n",
    "        ext: A comma-separated string of file extensions to filter the files by. Options are: pdf, txt, md, markdown, csv, and py. Defaults to \"pdf, txt\".\n",
    "\n",
    "    Returns:\n",
    "        str: A comma-separated string of file names with the specified extensions. If no files are found, a message is returned.\n",
    "\n",
    "    Example:\n",
    "        >>> get_file_names(ext=\"pdf, txt\")\n",
    "        \n",
    "        \"List of file names with the specified extensions in the local data directory: file1.pdf, file2.txt\"\n",
    "    \"\"\"\n",
    "\n",
    "    if 'DIR_PATH' not in globals():\n",
    "        return \"Error: The local data directory path is not defined.\"\n",
    "    \n",
    "    if not os.path.exists(DIR_PATH):\n",
    "        return f\"Error: The local data directory does not exist.\"\n",
    "\n",
    "    valid_extensions = [\"pdf\", \"txt\", \"md\", \"markdown\", \"csv\", \"py\"]\n",
    "\n",
    "    # Process the input extensions\n",
    "    selected_extensions = []\n",
    "    for e in ext.split(','):\n",
    "        e = e.lower().strip().lstrip('.').strip('{').strip('}').strip('[').strip(']').strip('(').strip(')').strip('\"').strip(\"'\") # Clean up the extension string\n",
    "        if e not in valid_extensions:\n",
    "            return f\"Error: Invalid file extension '{e}'. Please choose from: pdf, txt, md, markdown, csv, py.\" # Instead of raising an error, we return a message to the LLM to avoid stopping a conversation\n",
    "        selected_extensions.append(e)\n",
    "\n",
    "    # List all files with the specified extensions\n",
    "    file_names = [file for file in os.listdir(DIR_PATH) if any(file.endswith(f\".{e}\") for e in selected_extensions)]\n",
    "    # print(file_names) # Uncomment for debugging\n",
    "\n",
    "    if len(file_names) == 0:\n",
    "         return \"Access of local data directory successful but no files found with the specified extensions.\"\n",
    "\n",
    "    file_names_json = ', '.join(file_names)\n",
    "\n",
    "    # Convert list to a comma-separated string. This is because the object is returned to the LLM and the API accepts str only\n",
    "    return f\"List of file names with the specified extensions in the local data directory: {file_names_json}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "assert type(get_file_names.json_schema) == dict\n",
    "assert get_file_names.json_schema['function']['name'] == \"get_file_names\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "To test this and other functions defined below with an actual file, download a sample article from the internet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1722k  100 1722k    0     0  6237k      0 --:--:-- --:--:-- --:--:-- 6242k\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if \"CONDA_PREFIX\" in os.environ:\n",
    "    !mkdir -p ../data\n",
    "    pdf_urls = [\n",
    "        \"https://df6sxcketz7bb.cloudfront.net/manuscripts/144000/144499/jci.insight.144499.v2.pdf\",\n",
    "    ]\n",
    "    for url in pdf_urls:\n",
    "        !curl -o ../data/$(basename {url}) {url}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Below are several test cases for the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import copy\n",
    "import tempfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "global DIR_PATH\n",
    "DIR_PATH = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed successfully!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# Test case for get_file_names function\n",
    "if \"DIR_PATH\" in globals():\n",
    "    original_DIR_PATH = copy.deepcopy(DIR_PATH)\n",
    "    del globals()[\"DIR_PATH\"] # Remove the global variable for testing purposes\n",
    "with tempfile.TemporaryDirectory() as temp_dir: \n",
    "    assert get_file_names() == \"Error: The local data directory path is not defined.\", \"Test failed: get_file_names() should return an error message if DIR_PATH is not defined.\"\n",
    "    global DIR_PATH\n",
    "    DIR_PATH = temp_dir\n",
    "    assert get_file_names() == \"Access of local data directory successful but no files found with the specified extensions.\", \"Test failed: get_file_names() should return a message if no files are found in the directory.\"\n",
    "    test_files = [\"test_file1.txt\", \"test_file2.py\"] # Create some test files\n",
    "    for file in test_files:\n",
    "        with open(os.path.join(DIR_PATH, file), 'w') as f:\n",
    "            f.write(\"Test content\")\n",
    "    assert \"test_file1.txt\" in get_file_names(ext=\"txt\"), \"Test failed: get_file_names() should return a string with the test file name.\"\n",
    "    assert \"test_file2.py\" not in get_file_names(ext=\"txt\"), \"Test failed: get_file_names() should not return a file name with a different extension.\"\n",
    "    assert \"test_file2.py\" in get_file_names(ext=\"txt, py\"), \"Test failed: get_file_names() should return a string with the python test file name.\"\n",
    "    print(\"All tests passed successfully!\")\n",
    "\n",
    "global DIR_PATH\n",
    "DIR_PATH = original_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling get_file_names()...\n",
      "\n",
      "No PDF files available.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# Test function calling with the LLM using the get_file_names tool, if no files are found\n",
    "# Store the original DIR_PATH\n",
    "if \"DIR_PATH\" in globals():\n",
    "    original_DIR_PATH = copy.deepcopy(DIR_PATH)\n",
    "\n",
    "# Create a temporary, empty directory \n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    # Set DIR_PATH to the temporary directory\n",
    "    global DIR_PATH\n",
    "    DIR_PATH = temp_dir\n",
    "\n",
    "    prompt = f\"Can you provide me with a list of PDF files you have access to on the local computer?\"\n",
    "\n",
    "    sys_message = \"\"\"You are a helpful AI assistant. Respond with the shortest possible answers while maintaining clarity and accuracy. \n",
    "    Avoid unnecessary details, explanations, or pleasantries. Be direct and to the point in all responses.\n",
    "\n",
    "    Key instructions:\n",
    "    1. Use the provided tool to gather information before answering.\n",
    "    2. Interpret tool results and provide clear, concise answers in natural language.\n",
    "    3. If you can't answer with available tools, state this clearly.\n",
    "    4. Don't provide information if tool content is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    messages=[\n",
    "        {'role': \"system\", 'content': sys_message},\n",
    "        {'role': 'user', 'content': prompt},\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Make a request to the LLM to select a tool\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.1\",\n",
    "            messages=messages,\n",
    "            tools=[get_file_names.json_schema],\n",
    "        )\n",
    "    \n",
    "        if response.get('message').get('tool_calls'):\n",
    "            for tool in response['message']['tool_calls']:\n",
    "                function_to_call = tool['function']['name']\n",
    "                print(f\"Calling {function_to_call}()...\\n\")\n",
    "\n",
    "        # Call the function\n",
    "        for tool in response['message'].get('tool_calls'):\n",
    "            output = f\"return: {get_file_names()}\"\n",
    "            messages.append(\n",
    "                {\n",
    "                    'role': 'tool',\n",
    "                    'content': output,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Make a second request to the LLM with the tool output to generate a final response\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.1\",\n",
    "            messages=messages,\n",
    "            stream=False,\n",
    "        )\n",
    "\n",
    "        print(response['message']['content'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Reset DIR_PATH to its original value\n",
    "if \"DIR_PATH\" in globals():\n",
    "    DIR_PATH = original_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test file: test_750525c0.pdf\n",
      "\n",
      "Calling get_file_names()...\n",
      "\n",
      "LLM response:\n",
      "Here is the list of available PDF files:\n",
      "\n",
      "1. test_750525c0.pdf\n",
      "2. jci.insight.144499.v2.pdf\n",
      "\n",
      "\n",
      "Removing test file...\n",
      "Test completed.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# Test function calling; create a test file and check if it is included in the response\n",
    "if \"CONDA_PREFIX\" in os.environ: # For local testing only \n",
    "    unique_suffix = uuid.uuid4().hex[:8]  # Use first 8 characters of a UUID\n",
    "    test_file_name = f\"test_{unique_suffix}.pdf\"\n",
    "    test_file_path = os.path.join(DIR_PATH, test_file_name)\n",
    "\n",
    "    print(f\"Creating test file: {test_file_name}\\n\")\n",
    "    open(test_file_path, 'a').close()  # Create an empty file\n",
    "\n",
    "    prompt = f\"Can you provide me with a list of PDF files you have access to?\"\n",
    "\n",
    "    sys_message = \"\"\"You are a helpful AI assistant. Respond with the shortest possible answers while maintaining clarity and accuracy. \n",
    "    Avoid unnecessary details, explanations, or pleasantries. Be direct and to the point in all responses.\n",
    "\n",
    "    Key instructions:\n",
    "    1. Use the provided tool to gather information before answering.\n",
    "    2. Interpret tool results and provide clear, concise answers in natural language.\n",
    "    3. If you can't answer with available tools, state this clearly.\n",
    "    4. Don't provide information if tool content is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    messages=[\n",
    "        {'role': \"system\", 'content': sys_message},\n",
    "        {'role': 'user', 'content': prompt},\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Make a request to the LLM to select a tool\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.1\",\n",
    "            messages=messages,\n",
    "            tools=[get_file_names.json_schema],\n",
    "        )\n",
    "\n",
    "        if response.get('message').get('tool_calls'):\n",
    "            for tool in response['message']['tool_calls']:\n",
    "                function_to_call = tool['function']['name']\n",
    "                print(f\"Calling {function_to_call}()...\\n\")\n",
    "\n",
    "        # Call the function\n",
    "        for tool in response['message'].get('tool_calls'):\n",
    "            output = f\"return: {get_file_names()}\"\n",
    "            # print(output)\n",
    "            messages.append(\n",
    "                {\n",
    "                    'role': 'tool',\n",
    "                    'content': output,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Make a second request to the LLM with the tool output to generate a final response\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.1\",\n",
    "            messages=messages,\n",
    "            stream=False,\n",
    "        )\n",
    "        print(f\"LLM response:\\n{response['message']['content']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        errors.append(e)\n",
    "\n",
    "    print(f\"\\n\\nRemoving test file...\")\n",
    "    os.remove(test_file_path)\n",
    "    print(\"Test completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "The next two functions are executed when calling the tool `get_titles_and_first_authors`, which is defined below, to extract the title and first author from PDF files in the local data directory. The first function, `extract_text_from_pdf`, extracts text from a PDF file using the **PyPDF2** library. The second function, `extract_title_and_first_author`, will then use the LLM to extract the title and first author from the text extracted from the PDF file.\n",
    "\n",
    "In addition, the `extract_text_from_pdf` function can also be called directly by the assistant to extract user-specified pages or sections from a PDF file, to respond to user queries or to extract specific information from a PDF file specified by the user.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def extract_text_from_pdf(file_name: str, page_range: Optional[str] = None) -> str:\n",
    "    \"\"\"A function that extracts text from a PDF file.\n",
    "    Use this tool to extract specific details from a PDF document, such as abstract, authors, conclusions, or user-specified content of other sections.\n",
    "    If the user specifies a page rage, use the optional page_range parameter to extract text from specific pages.\n",
    "    If the user uses words such as beginning, middle, or end, to descripe the section, infer the page range based on the total number of 15 pages in a document.\n",
    "    Do not use this tool to summarize an entire PDF document. Only use this tool for documents with extensions .pdf, or .PDF.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): The file name of the PDF document in the local data directory.\n",
    "        page_range (Optional[str]): A string with page numbers and/or page ranges separated by commas (e.g., \"1\" or \"1, 2\", or \"5-7\"). Default is None to extract all pages.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted text from the PDF.\n",
    "\n",
    "    Example:\n",
    "    >>> text = extract_text_from_pdf(\"./test.pdf\", page_range=\"1\")\n",
    "    \"\"\"\n",
    "    verbose = False  # Set to True for debugging\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(DIR_PATH):\n",
    "        return \"Local data directory not found.\"\n",
    "    \n",
    "    # Construct the full file path; this will be handled by a try-except block because this function is alos used as a tool\n",
    "    try:\n",
    "        pdf_path = os.path.join(DIR_PATH, file_name)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "    \n",
    "    # Validate input\n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(f\"File not found: {pdf_path}\")\n",
    "    assert pdf_path.endswith('.pdf'), \"The file must be a PDF.\"\n",
    "    assert isinstance(page_range, (str, type(None))), \"The page_range must be a string or None.\"\n",
    "\n",
    "    if page_range:\n",
    "        # Clean up page range input in case of LLM formatting errors; must be a string, e.g., \"1\" or \"1, 2\", or \"5-7\", with no quotes or brackets   \n",
    "        page_range = page_range.strip().replace('\"', '').replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "\n",
    "        # Parse the page range string\n",
    "        page_numbers = []\n",
    "        for part in page_range.split(','):\n",
    "            if '-' in part:\n",
    "                a, b = part.split('-')\n",
    "                page_numbers.extend(range(int(a), int(b) + 1))\n",
    "            else:\n",
    "                page_numbers.append(int(part))\n",
    "        if verbose:\n",
    "            print(f\"Extracting text from pages: {page_numbers}\")\n",
    "\n",
    "    # Validate page numbers\n",
    "    if page_range:\n",
    "        start_page, end_page = min(page_numbers), max(page_numbers)\n",
    "        if start_page < 1 or end_page < start_page:\n",
    "            raise ValueError(\"Invalid page range. Please provide a valid range of pages to extract text from.\")\n",
    "\n",
    "    # Extract text from the PDF\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf = PyPDF2.PdfReader(file)\n",
    "            \n",
    "            # Check for invalid page numbers\n",
    "            if page_range:\n",
    "                max_page = len(pdf.pages)\n",
    "                invalid_pages = [p for p in page_numbers if p < 1 or p > max_page]\n",
    "                if invalid_pages:\n",
    "                    page_range = None # Reset page range to extract all pages\n",
    "            \n",
    "            if page_range:\n",
    "                for page_num in page_numbers:\n",
    "                    if verbose:\n",
    "                        print(f\"Extracting text from page {page_num}...\")\n",
    "                    page = pdf.pages[page_num - 1]  # Adjust for 0-based index\n",
    "                    text += f\"page {page_num} of {len(pdf.pages)}\\n{page.extract_text()}\"\n",
    "            else:\n",
    "                for page_num, page in enumerate(pdf.pages):\n",
    "                    if verbose:\n",
    "                        print(f\"Extracting text from page {page_num + 1}...\")\n",
    "                    text += f\"page {page_num} of {len(pdf.pages)}\\n{page.extract_text()}\"\n",
    "            \n",
    "            if verbose:\n",
    "                word_count = len(text.split())\n",
    "                total_pages = len(page_numbers) if page_range else len(pdf.pages)\n",
    "                print(f\"Text extraction completed.\\nTotal pages extracted: {total_pages}\\nWord count: {word_count}\\nNo. of characters (with spaces): {len(text)}\")\n",
    "    except PyPDF2.errors.PdfReadError as e:\n",
    "        return f\"Error reading PDF: {e}\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Testing the function with a sample PDF file\n",
    "# For this test to work, the specified PDF file must exist in the data directory\n",
    "try: \n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"1\")\n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"1, 2\")\n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"1-3\") # Should handle page ranges with hyphens\n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\" 1-3 \") # Should handle extra spaces\n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"1, 3\") \n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"1-3, 5\") # Should handle multiple ranges\n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"1-1000\") # Invalid page range will return all pages\n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"[1]\") # Should handle invalid formatting; brackets will be removed\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Note: The following function will be defined but not be callable directly by the LLM. \n",
    "Hence, we will not generate a JSON schema for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_title_and_first_author(contents: List[Dict[str, str]], model: str='llama3.1', verbose: Optional[bool] = False, show_progress: Optional[bool] = False) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    A function that extracts the titles and the first author's names from the text of one or more research articles.\n",
    "\n",
    "    Args:\n",
    "        contents (List[Dict[str, str]]): A list of dictionaries containing the file name and extracted text.\n",
    "        model (str): The model to use for the extraction. Default is 'llama3.1'.\n",
    "        verbose (Optional[bool]): Whether to print additional information. Default is False.\n",
    "        show_progress (Optional[bool]): Whether to show a progress bar. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        contents (List[Dict[str, str]]): The input list of dictionaries with the extracted title and first author added.\n",
    "\n",
    "    Raises:\n",
    "        JSONDecodeError: If the JSON response is invalid.\n",
    "\n",
    "    Example:\n",
    "    >>> contents = extract_title_and_first_author(contents)\n",
    "    Extracting titles and first authors: 100%|██████████| 3/3 [00:22<00:00,  7.35s/it]\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    The text below between the <text> XML like tags is extracted from the first page of a research article. \n",
    "    Your task is to identify the title of the research article and the first author's name.\n",
    "    The title is typically located immediately before the authors' names and the abstract.\n",
    "\n",
    "    <text>\n",
    "    {text}\n",
    "    </text>\n",
    "\n",
    "    The output must be provided in JSON format shown in the following example.\n",
    "\n",
    "    Example output:\n",
    "    {{\n",
    "        \"title\": \"<title>\",\n",
    "        \"first_author\": \"<first_author>\"\n",
    "    }}\n",
    "    Write the JSON output and nothing more. Do not include degree titles or affiliations in the author's name.\n",
    "\n",
    "    Here is the JSON output:\n",
    "    \"\"\"\n",
    "\n",
    "    pdf_iterator = tqdm(contents, desc=\"Extracting titles and first authors\") if show_progress else contents\n",
    "    \n",
    "    for pdf_item in pdf_iterator:\n",
    "        text = pdf_item['extracted_text']\n",
    "        if verbose:\n",
    "            tqdm.write(pdf_item['file_path'])\n",
    "            tqdm.write(\"---\")\n",
    "            tqdm.write(text[:500])\n",
    "            tqdm.write(\"---\")\n",
    "\n",
    "        try:\n",
    "            response = ollama.chat(model=model, messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': prompt.format(text=text),\n",
    "                },\n",
    "            ])\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Error: {e}\")\n",
    "            if \"Connection refused\" in str(e):\n",
    "                tqdm.write(\"Make sure Ollama is running and the correct model is available.\")\n",
    "            continue\n",
    "\n",
    "        if verbose:\n",
    "            tqdm.write(response['message']['content'])\n",
    "\n",
    "        try:\n",
    "            extracted_info = json.loads(response['message']['content'])\n",
    "        except json.JSONDecodeError:\n",
    "            tqdm.write(f\"Error: Invalid JSON response for {pdf_item['file_path']}\")\n",
    "            extracted_info = {\"title\": \"\", \"first_author\": \"\"}\n",
    "\n",
    "        pdf_item.update(extracted_info)\n",
    "\n",
    "    print(\"\\n\") if show_progress else None # Add a newline if showing progress bar\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "contents = [{\n",
    "    \"file_name\": \"de_medicina.pdf\",\n",
    "    \"extracted_text\": \"Titulus: De Medicina\\n\\nAuctor: Aulus Cornelius Celsus\\n\\nLiber I\\n\\nUt alimenta sanis corporibus agricultura, sic sanitatem aegris Medicina promittit. Haec nusquam quidem non est; siquidem etiam imperitissimae gentes herbas aliaque prompta in auxilium vulnerum morborumque noverunt. Verumtamen apud Graecos aliquanto magis quam in ceteris nationibus exculta est, ac ne apud hos quidem a prima origine, sed paucis ante nos saeculis; utpote cum vetustissimus auctor Aesculapius celebretur. Qui quoniam adhuc rudem et vulgarem hanc scientiam paulo subtilius excoluit, in deorum numerum receptus est.\"\n",
    "}]\n",
    "assert extract_title_and_first_author(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Run the following cells to test the `extract_text_from_pdf` & `extract_title_and_first_author` functions separately on actual PDF files. Remember, both of these functions are executed when the LLM calls the `get_titles_and_first_authors` function. These tests will be executed from the module as they require PDF files to be present in the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File paths: ['../data/jci.insight.144499.v2.pdf']\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# First, get the file paths from the local data directory\n",
    "# Make sure to have some PDF files in the data directory for this test\n",
    "DIR_PATH = \"../data/\"\n",
    "file_names = [file for file in os.listdir(DIR_PATH) if file.endswith('.pdf')]\n",
    "file_paths = [os.path.join(DIR_PATH, file) for file in file_names]\n",
    "print(\"File paths:\", file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'jci.insight.144499.v2.pdf',\n",
       "  'extracted_text': 'page 1 of 15\\n1\\nRESEARCH ARTICLEConflict of interest: The authors have \\ndeclared that no conflict of interest \\nexists.\\nCopyright: © 2021, Khan et al. This is \\nan open access article published under \\nthe terms of the Creative Commons \\nAttribution 4.0 International License.\\nSubmitted: September 21, 2020 \\nAccepted: January 13, 2021 \\nPublished: January 26, 2021\\nReference information: JCI Insight. \\n2021;6(4):e144499. \\nhttps://doi.org/10.1172/jci.\\ninsight.144499.Distinct antibody repertoires against \\nendemic human coronaviruses in  \\nchildren and adults\\nTaushif Khan,1 Mahbuba Rahman,1 Fatima Al Ali,1 Susie S. Y . Huang,1 Manar Ata,1 Qian Zhang,2  \\nPaul Bastard,2,3,4 Zhiyong Liu,2 Emmanuelle Jouanguy,2,3,4 Vivien Béziat,2,3,4 Aurélie Cobat,2,3,4  \\nGheyath K. Nasrallah,5,6 Hadi M. Yassine,5,6 Maria K. Smatti,6 Amira Saeed,7 Isabelle Vandernoot,8 \\n Jean-Christophe Goffard,9 Guillaume Smits,8 Isabelle Migeotte,10 Filomeen Haerynck,11 Isabelle Meyts,12,13 \\nLaurent Abel,2,3,4 Jean-Laurent Casanova,2,3,4,14 Mohammad R. Hasan,7,15 and Nico Marr1,16\\n1Research Branch, Sidra Medicine, Doha, Qatar. 2St. Giles Laboratory of Human Genetics of Infectious Diseases, Rockefeller \\nBranch, Rockefeller University, New York, New York, USA. 3Laboratory of Human Genetics of Infectious Diseases, Necker \\nBranch, INSERM U1163, Necker Hospital for Sick Children, Paris, France. 4University of Paris, Imagine Institute, Paris, \\nFrance. 5College of Health Sciences, QU Health, Qatar University, Doha, Qatar. 6Biomedical Research Center, Qatar \\nUniversity, Doha, Qatar. 7Department of Pathology, Sidra Medicine, Doha, Qatar. 8Center of Human Genetics, 9Department \\nof Internal Medicine, and 10Fonds de la Recherche Scientifique (FNRS) and Center of Human Genetics, Hôpital Erasme, \\nUniversité Libre de Bruxelles, Brussels, Belgium. 11Department of Pediatric Pulmonology and Immunology, Department \\nof Pediatrics and Internal Medicine, Center for Primary Immunodeficiencies Ghent, Jeffrey Modell Foundation Diagnostic \\nand Research Center, Ghent University Hospital, Belgium. 12Laboratory for Inborn Errors of Immunity, Department of \\nMicrobiology, Immunology and Transplantation, and Department of Pediatrics, University Hospitals Leuven, KU Leuven, \\nBelgium. 13Department of Pediatrics, University Hospitals Leuven, KU Leuven, Belgium. 14Howard Hughes Medical \\nInstitute, New York, New York, USA. 15Weill Cornell Medical College in Qatar, Doha, Qatar. 16College of Health and Life \\nSciences, Hamad Bin Khalifa University, Doha, Qatar.\\nIntroduction\\nFour endemic human-tropic coronaviruses (HCoVs) are commonly associated with respiratory illness in humans, \\nnamely HCoV-229E, -NL63, -OC43, and -HKU1 (1–4). Clinical outcomes of acute infection with these HCoVs \\nrange from mild upper respiratory tract infections in most patients, to viral bronchiolitis and pneumonia more \\nrarely in patients, the latter requiring hospitalization (5). The ratio of more severe versus mild outcomes of acute \\ninfection with endemic HCoVs is largely comparable to that of other “common cold” viruses, such as human \\nrespiratory syncytial virus (HRSV), human rhinoviruses (HRVs), human adenoviruses, and human parainfluen-\\nza viruses, albeit with differences in seasonality and prevalence of the viruses depending on the species (5–7). In Four endemic human coronaviruses (HCoVs) are commonly associated with acute respiratory \\ninfection in humans. B cell responses to these “common cold” viruses remain incompletely \\nunderstood. Here we report a comprehensive analysis of CoV-specific antibody repertoires in \\n231 children and 1168 adults using phage immunoprecipitation sequencing. Seroprevalence of \\nantibodies against endemic HCoVs ranged between approximately 4% and 27% depending on the \\nspecies and cohort. We identified at least 136 novel linear B cell epitopes. Antibody repertoires \\nagainst endemic HCoVs were qualitatively different between children and adults in that anti-\\nHCoV IgG specificities more frequently found among children targeted functionally important \\nand structurally conserved regions of the spike, nucleocapsid, and matrix proteins. Moreover, \\nantibody specificities targeting the highly conserved fusion peptide region and S2′  cleavage site \\nof the spike protein were broadly cross-reactive with peptides of epidemic human and nonhuman \\ncoronaviruses. In contrast, an acidic tandem repeat in the N-terminal region of the Nsp3 subdomain \\nof the HCoV-HKU1 polyprotein was the predominant target of antibody responses in adult \\ndonors. Our findings shed light on the dominant species-specific and pan-CoV target sites of \\nhuman antibody responses to coronavirus infection, thereby providing important insights for the \\ndevelopment of prophylactic or therapeutic monoclonal antibodies and vaccine design.'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "# Next, extract the text from the first page of each PDF file\n",
    "pdf_contents = []\n",
    "for file_path in file_paths:\n",
    "    pdf_contents.append({\n",
    "        \"file_name\": file_path.split(\"/\")[-1],\n",
    "        \"extracted_text\": extract_text_from_pdf(file_path, page_range=\"1\")\n",
    "        })\n",
    "pdf_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Now, we iterate through the contents and run the `extract_title_and_first_author` function to extract the title and first author from the text extracted from the PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting titles and first authors: 100%|██████████| 1/1 [00:07<00:00,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "jci.insight.144499.v2.pdf: 'Distinct antibody repertoires against endemic human coronaviruses in children and adults'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if len(pdf_contents) > 0:\n",
    "    response = extract_title_and_first_author(pdf_contents, show_progress=True)\n",
    "    for article in response:\n",
    "        print(f\"{article.get('file_name')}: '{article.get('title')}'\")\n",
    "else: \n",
    "    print(\"Add PDF files to the data directory to test the functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "The next function combines the two functions `extract_text_from_pdf` and `extract_title_and_first_author` to extract the title and first author from PDF files in the local data directory. This function will be callable by the LLM.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def get_titles_and_first_authors() -> str:\n",
    "    \"\"\"\n",
    "    A function that retrieves the titles of research articles from a directory of PDF files.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON-formatted string containing the titles, first authors and file names of the research articles.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified directory does not exist.\n",
    "\n",
    "    Example:\n",
    "    >>> get_titles_and_first_authors()\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(DIR_PATH):\n",
    "        return \"Local data directory not found.\"\n",
    "\n",
    "    # Initialize an empty list to store the file names and extracted text\n",
    "    pdf_contents = []\n",
    "\n",
    "    # Initialize an empty list of dictionaries to store file names, extracted titles and first authors\n",
    "    titles_and_authors = []\n",
    "\n",
    "    # Get the file paths of all PDF files in the local data directory\n",
    "    file_paths = [os.path.join(DIR_PATH, file) for file in os.listdir(DIR_PATH) if file.endswith('.pdf')]\n",
    "\n",
    "    # Extract text from the first page of each PDF file\n",
    "    for file_path in file_paths:\n",
    "        pdf_contents.append({\n",
    "            \"file_name\": file_path.split(\"/\")[-1],\n",
    "            \"extracted_text\": extract_text_from_pdf(file_path, page_range=\"1\")\n",
    "            })\n",
    "\n",
    "    # Extract titles and first authors from the extracted text of each PDF file\n",
    "    response = extract_title_and_first_author(pdf_contents, show_progress=True)\n",
    "    for article in response:\n",
    "        titles_and_authors.append({\n",
    "            \"title\": article.get('title'), \n",
    "            \"first_author\": article.get('first_author'),\n",
    "            \"file_name\": article.get('file_name'),\n",
    "            })\n",
    "    \n",
    "    if not titles_and_authors:\n",
    "        return \"No titles found.\"\n",
    "        \n",
    "    return json.dumps(titles_and_authors, indent=2) # Return as a JSON-formatted string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'get_titles_and_first_authors',\n",
       "  'description': 'A function that retrieves the titles of research articles from a directory of PDF files.',\n",
       "  'parameters': {'type': 'object', 'properties': {}, 'required': []}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "get_titles_and_first_authors.json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "assert type(get_titles_and_first_authors.json_schema) == dict\n",
    "assert get_titles_and_first_authors.json_schema['function']['name'] == \"get_titles_and_first_authors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting titles and first authors: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"title\": \"Distinct antibody repertoires against endemic human coronaviruses in children and adults\",\n",
      "    \"first_author\": \"Taushif Khan\",\n",
      "    \"file_name\": \"jci.insight.144499.v2.pdf\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting titles and first authors: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "print(get_titles_and_first_authors())\n",
    "print(type(get_titles_and_first_authors()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "The functions below are executed to summarize the content of files in the local data directory.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def summarize_local_document(file_name: str, ext: str = \"pdf\") -> str:\n",
    "    \"\"\"Summarize the content of a single PDF, markdown, or text document from the local data directory.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): The file name of the local document to summarize.\n",
    "        ext (str): The extension of the local document. Options are: pdf, txt, md, and markdown. Defaults to \"pdf\".\n",
    "\n",
    "    Returns:\n",
    "        str: The summary of the content of the local document.\n",
    "\n",
    "    Example:\n",
    "        >>> summarize_local_document(\"research_paper\", ext=\"pdf\")\n",
    "    \"\"\"\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(DIR_PATH):\n",
    "        return \"Local data directory not found.\"\n",
    "\n",
    "    # Ensure the extension is valid: delete spaces, hyphens, and quotation marks, and convert to lowercase in case of LLM input errors\n",
    "    ext = ext.lower().replace('\"', '').replace(\"'\", \"\").replace(\" \", \"\").replace(\".\", \"\")\n",
    "    if ext not in [\"pdf\", \"txt\", \"md\", \"markdown\"]:\n",
    "        return f\"Invalid file extension '{ext}'. Please choose from: pdf, txt, md, markdown.\"\n",
    "\n",
    "    # Get the file paths of all files in the local data directory\n",
    "    file_paths = [os.path.join(DIR_PATH, file) for file in os.listdir(DIR_PATH) if file.endswith(ext)]\n",
    "    # print(file_paths) # Uncomment for debugging\n",
    "    \n",
    "    # Find the file path that matches the specified file name\n",
    "    file_path = [path for path in file_paths if file_name in path]\n",
    "    # print(file_path) # Uncomment for debugging\n",
    "\n",
    "    if not file_path:\n",
    "        return f\"No file found with the name '{file_name}' and extension '{ext}'.\"\n",
    "    elif len(file_path) > 1:\n",
    "        return f\"Multiple files found with the name '{file_name}' and extension '{ext}'. Please specify a unique file name.\"\n",
    "    else:\n",
    "        file_path = file_path[0] # Convert the file path list to a string\n",
    "\n",
    "    if ext == \"pdf\":\n",
    "        # Extract text from a PDF file\n",
    "        try:\n",
    "            full_text = extract_text_from_pdf(file_path, page_range=None)\n",
    "        except Exception as e:\n",
    "            return f\"Error while extracting text from PDF file {file_name}: {e}\"\n",
    "    \n",
    "    if ext in [\"txt\", \"md\", \"markdown\"]:\n",
    "        # Read the full text content from a text file\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                full_text = file.read()\n",
    "        except Exception as e:\n",
    "            return f\"Error while reading the file {file_name}: {e}\"\n",
    "    # print(full_text[:500]) # Uncomment for debugging\n",
    "\n",
    "    # Remove references section from the full text content, if present\n",
    "    patterns = [\"References\", \"REFERENCES\", \"references\", \"Bibliography\", \"BIBLIOGRAPHY\", \"bibliography\"]\n",
    "    for pattern in patterns:\n",
    "        if pattern in full_text:\n",
    "            full_text = full_text.split(pattern)[0]\n",
    "            break\n",
    "\n",
    "    # Summarize the full text content of the document\n",
    "    prompt = f\"\"\"\n",
    "    The text below is the full text content from single document with the file name '{file_name}'.\n",
    "\n",
    "    <text>\n",
    "    {full_text}\n",
    "    </text>\n",
    "\n",
    "    If the document has an abstract, use the abstract for the summary. The abstract is typically located at the beginning of the document (page 1) and provides a concise summary of the research.\n",
    "    If there is no abstract, generate a concise summary (approx. 200 words) that captures the main points of the document, including key findings and conclusions.\n",
    "    Remember that your task is to summarize the content of the main text accurately and concisely, ignoring acknowledgements and references that are typically listed at the end of the document, after the conclusion section.\n",
    "    Start the summary with the title of the document, typically found on the first page before the author names.\n",
    "    \"\"\"\n",
    "\n",
    "    sys_message = \"\"\"You are a scientific summarization assistant for health and life sciences research. \n",
    "    Your task is to condense the contents of a complex research document with mutiple pages into a concise, accurate summary.\n",
    "    If the document describes a research study, highlight the main findings, methodologies, and conclusions of the study.\n",
    "    Start the summary with the title of the document found on the first page, followed by a brief summary of the content.\n",
    "    Ignore references typically listed at the end of a document after the conclusion section, as well as acknowledgements, and other non-content sections.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the model from the global variables\n",
    "    if 'MODEL' in globals():\n",
    "        model = MODEL\n",
    "    else:\n",
    "        model = \"llama3.1\" # Default model\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {'role': \"system\", 'content': sys_message},\n",
    "                {'role': 'user', 'content': prompt},\n",
    "            ]\n",
    "        )\n",
    "        # TODO: Try out different optional parameters for the ollama.chat function, such as temperature, max_tokens, etc. to improve the quality of the summary\n",
    "        # For details, see the Ollama API documentation:\n",
    "        # https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "        # https://github.com/ollama/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\n",
    "\n",
    "        summary = response['message']['content']\n",
    "        return summary\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error while summarizing the content of the document '{file_name}': {e}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'summarize_local_document',\n",
       "  'description': 'Summarize the content of a single PDF, markdown, or text document from the local data directory.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'file_name': {'type': 'string',\n",
       "     'description': 'The file name of the local document to summarize.'},\n",
       "    'ext': {'type': 'string',\n",
       "     'description': 'The extension of the local document. Options are: pdf, txt, md, and markdown. Defaults to \"pdf\".'}},\n",
       "   'required': ['file_name', 'ext']}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "summarize_local_document.json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "assert type(summarize_local_document.json_schema) == dict\n",
    "assert summarize_local_document.json_schema['function']['name'] == \"summarize_local_document\"\n",
    "assert 'file_name' in summarize_local_document.json_schema['function']['parameters']['properties'].keys()\n",
    "assert 'ext' in summarize_local_document.json_schema['function']['parameters']['properties'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-11 21:44:25--  https://raw.githubusercontent.com/ollama/ollama/main/docs/modelfile.md\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12893 (13K) [text/plain]\n",
      "Saving to: ‘../data/modelfile.md’\n",
      "\n",
      "../data/modelfile.m 100%[===================>]  12,59K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-09-11 21:44:26 (43,1 MB/s) - ‘../data/modelfile.md’ saved [12893/12893]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if \"CONDA_PREFIX\" in os.environ: # For local testing only\n",
    "    !wget -O ../data/modelfile.md https://raw.githubusercontent.com/ollama/ollama/main/docs/modelfile.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can’t provide a Modelfile as it is specific to a particular model. However, I can help you create a custom Modelfile for your needs.\n",
      "\n",
      "To get started, what type of text would you like the AI to generate? For example, should it be:\n",
      "\n",
      "1. **Answering questions**: Provide answers to user queries.\n",
      "2. **Writing articles**: Generate articles on a given topic.\n",
      "3. **Conversational dialogue**: Engage in natural-sounding conversations.\n",
      "4. **Summarizing content**: Summarize long pieces of text into concise versions.\n",
      "\n",
      "Please let me know your desired application, and I'll help you create a basic Modelfile with the necessary instructions to get started.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if \"CONDA_PREFIX\" in os.environ: # For local testing only\n",
    "    DIR_PATH = \"../data\" # for testing purposes; will be defined when the Assistant class is initialized\n",
    "    print(summarize_local_document(\"modelfile.md\", ext=\"md\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a concise summary (approx. 200 words) based on the provided text:\n",
      "\n",
      "Title: Deployment of Convalescent Plasma for the Prevention and Treatment of COVID-19.\n",
      "\n",
      "The deployment of convalescent plasma has emerged as a potential strategy for the prevention and treatment of COVID-19. Studies have shown that pre-existing immunity to SARS-CoV-2 can modulate and impair antibody responses to subsequent infections, indicating the potential for convalescent plasma to be effective. Fc-mediated antibody effector functions during respiratory syncytial virus infection and disease also suggest a role for convalescent plasma.\n",
      "\n",
      "Research has identified several key factors influencing the efficacy of convalescent plasma, including the presence of neutralizing antibodies, avidity responses in COVID-19 patients and donors, and inborn errors of type I IFN immunity. Studies have demonstrated that convalescent plasma can contain antibodies reacting against SARS-CoV-2 antigens, and pre-existing yellow fever immunity has been shown to impair and modulate the antibody response to tick-borne encephalitis vaccination.\n",
      "\n",
      "Overall, the use of convalescent plasma for the prevention and treatment of COVID-19 holds promise, with ongoing research seeking to optimize its deployment and efficacy.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if \"CONDA_PREFIX\" in os.environ: # For local testing only\n",
    "    print(summarize_local_document(\"jci.insight.144499.v2.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def describe_python_code(file_name: str) -> str:\n",
    "    \"\"\"Describe the purpose of the Python code in a local Python file.\n",
    "    This may involve summarizing the entire code, extracting key functions, or providing an overview of the code structure.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): The file name of the local Python code file document to describe.\n",
    "\n",
    "    Returns:\n",
    "        str: A description of the purpose of the Python code in the local file.\n",
    "\n",
    "    Example:\n",
    "        >>> describe_python_code(\"main.py\", ext=\"py\")\n",
    "    \"\"\"\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(DIR_PATH):\n",
    "        return \"Local data directory not found.\"\n",
    "\n",
    "    # Get the file paths of all files in the local data directory\n",
    "    file_paths = [os.path.join(DIR_PATH, file) for file in os.listdir(DIR_PATH) if file.endswith(\".py\")]\n",
    "    # print(file_paths) # Uncomment for debugging\n",
    "    \n",
    "    # Find the file path that matches the specified file name\n",
    "    file_path = [path for path in file_paths if file_name in path]\n",
    "    # print(file_path) # Uncomment for debugging\n",
    "\n",
    "    if not file_path:\n",
    "        return f\"No file found with the name '{file_name}' and extension '.py'.\"\n",
    "    elif len(file_path) > 1:\n",
    "        return f\"Multiple files found with the name '{file_name}' and extension '.py'. Please specify a unique file name.\"\n",
    "    else:\n",
    "        file_path = file_path[0] # Convert the file path list to a string\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            full_text = file.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error while reading the file {file_name}: {e}\"\n",
    "    # print(full_text[:500]) # Uncomment for debugging\n",
    "\n",
    "    # Summarize the full text content of the document\n",
    "    prompt = f\"\"\"\n",
    "    The text below is the full Python code content from the file '{file_name}'.\n",
    "\n",
    "    <code>\n",
    "    {full_text}\n",
    "    </code>\n",
    "\n",
    "    Your task is to describe the purpose of the Python code in the file. This may involve summarizing the entire code, extracting key functions, or providing an overview of the code structure.\n",
    "    \"\"\"\n",
    "\n",
    "    sys_message = \"\"\"You are a programming assistant for Python code. Your task is to describe the purpose of Python code in a local file for the user who may not be familiar with the code,\n",
    "    and may not know how to interpret the code. If not ask for specific content, provide a high-level overview of the code's functionality, key functions, and structure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the model from the global variables\n",
    "    if 'MODEL' in globals():\n",
    "        model = MODEL\n",
    "    else:\n",
    "        model = \"llama3.1\" # Default model\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {'role': \"system\", 'content': sys_message},\n",
    "                {'role': 'user', 'content': prompt},\n",
    "            ]\n",
    "        )\n",
    "        # TODO: Try out different optional parameters for the ollama.chat function, such as temperature, max_tokens, etc. to improve the quality of the summary\n",
    "        # For details, see the Ollama API documentation:\n",
    "        # https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "        # https://github.com/ollama/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\n",
    "\n",
    "        summary = response['message']['content']\n",
    "        return summary\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error while describing the Python code in the file '{file_name}': {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'describe_python_code',\n",
       "  'description': 'Describe the purpose of the Python code in a local Python file. This may involve summarizing the entire code, extracting key functions, or providing an overview of the code structure.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'file_name': {'type': 'string',\n",
       "     'description': 'The file name of the local Python code file document to describe.'}},\n",
       "   'required': ['file_name']}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "describe_python_code.json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "assert type(describe_python_code.json_schema) == dict\n",
    "assert describe_python_code.json_schema['function']['name'] == \"describe_python_code\"\n",
    "assert 'file_name' in describe_python_code.json_schema['function']['parameters']['properties'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Python code appears to be part of a larger project that provides an interface for interacting with AI models through the ollama library. The code defines several classes and functions for managing conversations, displaying conversation history, clearing conversation history, and printing tool information.\n",
      "\n",
      "Here's a high-level overview of the purpose of the code:\n",
      "\n",
      "1. **Conversation Management**: The `Assistant` class manages conversations by storing messages in a list (`self.messages`). It provides methods to show conversion history, clear conversion history, and print tool information.\n",
      "2. **Function Wrapping**: The `add_to_class` function is used to register new functions as methods of the `Assistant` class. This allows for easy extension of the conversation management functionality.\n",
      "3. **Conversation History Display**: The `show_conversion_history` method displays the conversation history, including user input, assistant responses, and tool output (if applicable).\n",
      "4. **Tool Information**: The `pprint_tools` method prints information about available tools, including their name and description.\n",
      "\n",
      "The code appears to be designed for use in a Jupyter notebook environment, as indicated by the `%% ../nbs/01_core.ipynb` cell magic commands.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if \"CONDA_PREFIX\" in os.environ: # For local testing only\n",
    "    !cp ../scholaris/core.py ../data/core.py\n",
    "    print(describe_python_code(\"core.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: ../data/.*\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "!rm ../data/modelfile.md\n",
    "!rm ../data/core.py\n",
    "!rm ../data/.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External data retrieval from NCBI, OpenAlex and Semantic Scholar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "The following functions are used to convert article IDs between different formats and detect the type of an article ID based on its format.\n",
    "\n",
    "- `convert_id`: Converts article IDs between PubMed Central, PubMed, DOI, and manuscript ID formats using the NCBI ID Converter API.\n",
    "\n",
    "- `detect_id_type`: Analyzes a given string to determine if it's a PMID, PMCID, DOI, OpenAlex ID, Semantic Scholar ID, potential article title, or an unknown format.\n",
    "\n",
    "- `id_converter_tool`: Combines the functionality of the above two functions to process a list of IDs, detecting their types and converting them using the NCBI API. This is callable by the LLM assistant.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_id(ids: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    For any article(s) in PubMed Central, find all the corresponding PubMed IDs (PMIDs), digital object identifiers (DOIs), and manuscript IDs (MIDs).\n",
    "    \n",
    "    Args:\n",
    "    ids (List[str]): A list of IDs to convert (max 200 per request).\n",
    "    \n",
    "    Returns:\n",
    "    Str: A JSON-formatted string containing the conversion results.\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'EMAIL' in globals():\n",
    "        email = EMAIL\n",
    "    else:\n",
    "        try:\n",
    "            email = os.environ['EMAIL']\n",
    "        except KeyError:\n",
    "            return {\"error\": \"Please provide an email address\"}\n",
    "\n",
    "    # API endpoint\n",
    "    base_url = \"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/\"\n",
    "    \n",
    "    # Prepare the IDs string\n",
    "    ids_string = \",\".join(ids)\n",
    "    \n",
    "    # Prepare the parameters\n",
    "    params = {\n",
    "        \"tool\": \"scholaris\",\n",
    "        \"email\": email,\n",
    "        \"ids\": ids_string,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Make the API request\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        \n",
    "        return response.json()\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def detect_id_type(id_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Detect the type of the given ID or title.\n",
    "    \n",
    "    Args:\n",
    "    id_string (str): The ID or title to detect.\n",
    "    \n",
    "    Returns:\n",
    "    str: The detected type ('pmid', 'pmcid', 'doi', 'openalex', 'semantic_scholar', 'potential_title', or 'unknown').\n",
    "    \"\"\"\n",
    "    if re.match(r'^\\d{1,8}$', id_string):\n",
    "        return 'pmid'\n",
    "    elif re.match(r'^PMC\\d+$', id_string):\n",
    "        return 'pmcid'\n",
    "    elif re.match(r'^10\\.\\d{4,9}/[-._;()/:A-Z0-9]+$', id_string, re.I): # Detect DOIs, case-insensitive\n",
    "        return 'doi'\n",
    "    elif re.match(r'^[WAIC]\\d{2,}$', id_string):\n",
    "        return 'openalex'\n",
    "    elif re.match(r'^[0-9a-f]{40}$', id_string): \n",
    "        return 'semantic_scholar'\n",
    "    elif re.match(r'^[A-Z][\\w\\s:,\\-()]{10,150}[.?!]?$', id_string, re.I): # A simple heuristic for detecting titles\n",
    "        return 'potential_title'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "\n",
    "@json_schema_decorator\n",
    "def id_converter_tool(ids: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    For any article(s) in PubMed Central, find all the corresponding PubMed IDs (PMIDs), digital object identifiers (DOIs), and manuscript IDs (MIDs).\n",
    "    Use this tool to convert a list of IDs, such as PMIDs, PMCIDs, or DOIs, and find the corresponding IDs for the same articles.\n",
    "    \n",
    "    Args:\n",
    "    ids (str): A string with a comma-separated list of IDs to convert. Must be PMIDs, PMCIDs, or DOIs. The maximum number of IDs per request is 200.\n",
    "    \n",
    "    Returns:\n",
    "    str: A JSON-formatted string containing the conversion results and the detected ID types.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(ids, str):\n",
    "        ids = ids.replace(\"https://doi.org/\", \"\").replace(\"doi.org/\", \"\") # Remove DOI URL prefixes, if present\n",
    "    \n",
    "    # Convert the input string to a list of IDs\n",
    "    try:\n",
    "        ids = ids.split(\",\")\n",
    "    except AttributeError:\n",
    "        return json.dumps({\"error\": \"Input must be a string of comma-separated IDs\"})\n",
    "\n",
    "    if len(ids) > 200:\n",
    "        return json.dumps({\"error\": \"Input IDs must be no more than 200\"})\n",
    "    \n",
    "    # Detect ID types\n",
    "    id_types = [detect_id_type(id_string) for id_string in ids]\n",
    "    \n",
    "    # Convert IDs\n",
    "    conversion_result = convert_id(ids)\n",
    "    \n",
    "    # Check if conversion_result is already a dictionary (error case)\n",
    "    if isinstance(conversion_result, dict):\n",
    "        parsed_result = conversion_result\n",
    "    else:\n",
    "        # Parse the JSON string result\n",
    "        try:\n",
    "            parsed_result = json.loads(conversion_result)\n",
    "        except json.JSONDecodeError:\n",
    "            return json.dumps({\"error\": \"Failed to parse conversion result\"})\n",
    "    \n",
    "    # Prepare the result\n",
    "    result = {\n",
    "        \"conversion_result\": parsed_result,\n",
    "        \"detected_id_types\": dict(zip(ids, id_types))\n",
    "    }\n",
    "    \n",
    "    return json.dumps(result, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "Check the JSON-schema for id_converter_tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'id_converter_tool',\n",
       "  'description': 'For any article(s) in PubMed Central, find all the corresponding PubMed IDs (PMIDs), digital object identifiers (DOIs), and manuscript IDs (MIDs). Use this tool to convert a list of IDs, such as PMIDs, PMCIDs, or DOIs, and find the corresponding IDs for the same articles.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'ids': {'type': 'list',\n",
       "     'description': 'A string with a comma-separated list of IDs to convert. Must be PMIDs, PMCIDs, or DOIs. The maximum number of IDs per request is 200.'}},\n",
       "   'required': ['ids']}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "id_converter_tool.json_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Test cases for `id_converter_tool`, `detect_id_types` and `convert_id` functions are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed 7 out of 7 tests.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# Test the id_converter_tool function with a list of mock IDs\n",
    "test_cases = [\n",
    "    (\"12345678\", \"pmid\"),\n",
    "    (\"PMC1234567\", \"pmcid\"),\n",
    "    (\"10.1234/abcd.efg\", \"doi\"),\n",
    "    (\"W1234567\", \"openalex\"),\n",
    "    (\"1234567890abcdef1234567890abcdef12345678\", \"semantic_scholar\"),\n",
    "    (\"This is a potential title\", \"potential_title\"),\n",
    "    (\"abc123\", \"unknown\")\n",
    "]\n",
    "\n",
    "# Run tests\n",
    "for input_string, expected_output in test_cases:\n",
    "    result = detect_id_type(input_string)\n",
    "    # print(f\"Input: {input_string}\")\n",
    "    # print(f\"Expected: {expected_output}\")\n",
    "    # print(f\"Result: {result}\")\n",
    "    # print(\"Pass\" if result == expected_output else \"Fail\")\n",
    "    # print()\n",
    "\n",
    "# Count passed tests\n",
    "passed_tests = sum(1 for input_string, expected_output in test_cases if detect_id_type(input_string) == expected_output)\n",
    "print(f\"Passed {passed_tests} out of {len(test_cases)} tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed successfully!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if \"CONDA_PREFIX\" in os.environ: # For local testing only\n",
    "    # Test with real IDs and by making a request to the API\n",
    "    ids = ['38776920', '38701783', '38557723', '38422122', '38363432', '38175961', '38157855', \n",
    "    '38048195', '37875108', '37779520', '37448622', '37083451', '37047709', '36763636', \n",
    "    '36515678', '36736301', '36326697', '36342405', '36425144', '36094518', '36003377', \n",
    "    '35670811', '35091979', '35090163', '34427831', '34623332', '34183838', '34413140', \n",
    "    '34137790', '34214472', '34183371', '33876776', '33529170', '33497357', '33510449', \n",
    "    '32960813', '33296702', '32972995', '32163377', '31995689', '31784499', '31270247', \n",
    "    '31346092', '31046570', '30578925', '31231515', '31559014', '30578352', '30143481', \n",
    "    '29907691', '29537367', '28437470', '28069966', '27347375', '26720836', '25819983', \n",
    "    '24949794', '24332264', '24603545', '24391215', '24119913', '23543769', '23467413', \n",
    "    '23487427', '22535679', '21695123', '21050116', '20176798', '18582518', '18424515']\n",
    "\n",
    "    ids_string = \",\".join(ids)\n",
    "\n",
    "    detected_id_types = json.loads(id_converter_tool(ids_string))[\"detected_id_types\"]\n",
    "    assert detected_id_types.values(), \"No ID types were detected for any of the input IDs.\"\n",
    "\n",
    "    data = convert_id(ids)\n",
    "    assert data.get(\"status\") == \"ok\", f\"Conversion failed with status: {data.get('status', 'unknown')}\"\n",
    "\n",
    "    for record in data.get(\"records\", []):\n",
    "        assert record.get(\"pmid\") or record.get(\"doi\"), f\"No PMID or DOI found for record: {record}\"\n",
    "        # print(f\"PMID: {record.get('pmid', 'N/A')}, DOI: {record.get('doi', 'N/A')}, PMCID: {record.get('pmcid', 'N/A')}\")\n",
    "    print(\"All tests passed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All DOIs detected successfully!\n",
      "All PMCIDs detected successfully!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if \"CONDA_PREFIX\" in os.environ: # For local testing only\n",
    "    # Generate a list of actual DOIs and PMCIDs from the API response\n",
    "    doi_list = []\n",
    "    pmcid_list = []\n",
    "    for record in data.get(\"records\", []):\n",
    "        doi_list.append(record.get(\"doi\"))\n",
    "        pmcid_list.append(record.get(\"pmcid\"))\n",
    "    doi_list = list(filter(None, doi_list)) # filter to remore None values\n",
    "    pmcid_list = list(filter(None, pmcid_list)) # filter to remore None values\n",
    "\n",
    "    for doi in doi_list:\n",
    "        assert detect_id_type(doi) == \"doi\", f\"Failed to detect DOI for {doi}\"\n",
    "    print(\"All DOIs detected successfully!\")\n",
    "    for pmcid in pmcid_list:\n",
    "        assert detect_id_type(pmcid) == \"pmcid\", f\"Failed to detect PMCID for {pmcid}\"\n",
    "    print(\"All PMCIDs detected successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "The function `query_openalex_api` below is executed to query the OpenAlex database for additional information about a given a article, either by title, PubMed ID, PMC ID, or DOI.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def query_openalex_api(query_param: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve metadata for a given article from OpenAlex, a comprehensive open-access catalog of global research papers.\n",
    "    Use this tool to search the OpenAlex API by using the article title, the PubMed ID (PMID), the PubMed Central ID (PMCID) or the digital object identifier (DOI) of an article as the query parameter. \n",
    "    This tool returns the following metadata:\n",
    "    - the OpenAlex ID\n",
    "    - the digital object identifier (DOI) URL\n",
    "    - Citation count\n",
    "    - The open access status\n",
    "    - URL to the open-access location for the work\n",
    "    - Publication year\n",
    "    - A URL to a website listing works that have cite the article\n",
    "    - The type of the article\n",
    "    Use this tool only if an article title, PubMed ID or DOI is provided by the user or was extracted from a local PDF file and is present in the conversation history.\n",
    "    \n",
    "    Args:\n",
    "        query_param (str): The article title, the PubMed ID (PMID), the PubMed Central ID (PMCID) or the digital object identifier (DOI) of the article to retrieve metadata for. May be provided by the user or extracted from a local PDF file and present in the conversation history.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON-formatted string including the search results from the OpenAlex database. If no results are found or the API query fails, an appropriate message is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    if 'EMAIL' not in globals():\n",
    "        try:\n",
    "            EMAIL = os.getenv(\"EMAIL\")\n",
    "        except KeyError:\n",
    "            EMAIL = \"\"\n",
    "\n",
    "    # Validate the input\n",
    "    if query_param is None or query_param == \"\":\n",
    "        return json.dumps({\"error\": \"The query parameter must be a non-empty string.\"})\n",
    "    elif not isinstance(query_param, str):\n",
    "        query_param = str(query_param)\n",
    "    \n",
    "    if query_param.startswith(\"https://doi.org/\"):\n",
    "        query_param = query_param.replace(\"https://doi.org/\", \"\")\n",
    "    elif query_param.startswith(\"doi.org/\"):\n",
    "        query_param = query_param.replace(\"doi.org/\", \"\")\n",
    "\n",
    "    # Constants\n",
    "    base_url = \"https://api.openalex.org/\" # Define the base URL for the OpenAlex API\n",
    "    \n",
    "    # Initialize variables\n",
    "    filter = \"\"\n",
    "\n",
    "    if detect_id_type(query_param) == \"potential_title\":\n",
    "        url = f\"{base_url}works?\"\n",
    "        filter = f\"title.search:{query_param}\"\n",
    "    elif detect_id_type(query_param) == \"pmid\":\n",
    "        url = f\"{base_url}works/pmid:{query_param}\"\n",
    "    elif detect_id_type(query_param) == \"doi\":\n",
    "        url = f\"{base_url}works/https://doi.org/{query_param}\"\n",
    "    elif detect_id_type(query_param) == \"pmcid\":\n",
    "        url = f\"{base_url}works/pmcid:{query_param}\"\n",
    "    else:\n",
    "        return json.dumps({\"error\": \"The query parameter must be a valid title, PMID, PMCID, or DOI.\"})\n",
    "        \n",
    "    # Set the query parameters\n",
    "    params = {\n",
    "        \"mailto\": EMAIL,\n",
    "        \"page\": 1,\n",
    "        \"per-page\": 5,\n",
    "        \"select\": \"id,doi,title,publication_year,cited_by_count,cited_by_api_url,open_access,type,type_crossref\",\n",
    "    }\n",
    "    if filter:\n",
    "        params[\"filter\"] = filter # Add the filter parameter for title search\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return {\"error\": f\"Failed to query OpenAlex API. Status code: {response.status_code}\"}\n",
    "\n",
    "    raw_search_results = response.json()\n",
    "\n",
    "    if filter:\n",
    "        number_of_search_matches = raw_search_results['meta']['count']\n",
    "        if len(raw_search_results['results']) == 0:\n",
    "            return \"No results found for the provided title.\"\n",
    "        elif number_of_search_matches > 5:\n",
    "            return \"Error: The search results are more than 5. Please provide a correct title.\"\n",
    "        else:\n",
    "            formatted_results = []\n",
    "            for result in raw_search_results['results']:\n",
    "                formatted_results.append(result)\n",
    "            return json.dumps(formatted_results, indent=2)\n",
    "\n",
    "    \n",
    "    if len(raw_search_results) == 0:\n",
    "        return {\"search result\": \"None\"}\n",
    "    else:\n",
    "        return json.dumps(raw_search_results, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Assert the correct format of the JSON schema..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "assert type(query_openalex_api.json_schema) == dict\n",
    "assert query_openalex_api.json_schema['function']['name'] == \"query_openalex_api\"\n",
    "assert 'query_param' in query_openalex_api.json_schema['function']['parameters']['properties'].keys()\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "A test case for the `query_openalex_api()` function is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import json\n",
    "from unittest.mock import patch\n",
    "\n",
    "# Mock responses for different scenarios\n",
    "mock_title_response = {\n",
    "    \"meta\": {\"count\": 1},\n",
    "    \"results\": [{\n",
    "        \"id\": \"https://openalex.org/W1234567890\",\n",
    "        \"doi\": \"https://doi.org/10.1234/example\",\n",
    "        \"title\": \"Example Article\",\n",
    "        \"publication_year\": 2023,\n",
    "        \"cited_by_count\": 42,\n",
    "        \"cited_by_api_url\": \"https://api.openalex.org/works?filter=cites:W1234567890\",\n",
    "        \"open_access\": {\"is_oa\": True, \"oa_status\": \"gold\"},\n",
    "        \"type\": \"journal-article\",\n",
    "        \"type_crossref\": \"journal-article\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "mock_pmid_response = {\n",
    "    \"id\": \"https://openalex.org/W9876543210\",\n",
    "    \"doi\": \"https://doi.org/10.5678/example\",\n",
    "    \"title\": \"Example Article with a PMID\",\n",
    "    \"publication_year\": 2022,\n",
    "    \"cited_by_count\": 10,\n",
    "    \"cited_by_api_url\": \"https://api.openalex.org/works?filter=cites:W9876543210\",\n",
    "    \"open_access\": {\"is_oa\": False, \"oa_status\": \"closed\"},\n",
    "    \"type\": \"journal-article\",\n",
    "    \"type_crossref\": \"journal-article\"\n",
    "}\n",
    "\n",
    "mock_doi_response = {\n",
    "    \"id\": \"https://openalex.org/W1357924680\",\n",
    "    \"doi\": \"https://doi.org/10.9876/example\",\n",
    "    \"title\": \"Example Book Chapter\",\n",
    "    \"publication_year\": 2021,\n",
    "    \"cited_by_count\": 100,\n",
    "    \"cited_by_api_url\": \"https://api.openalex.org/works?filter=cites:W1357924680\",\n",
    "    \"open_access\": {\"is_oa\": True, \"oa_status\": \"bronze\"},\n",
    "    \"type\": \"book-chapter\",\n",
    "    \"type_crossref\": \"book-chapter\"\n",
    "}\n",
    "\n",
    "# Test case\n",
    "def test_query_openalex_api():\n",
    "    # Mock the requests.get function\n",
    "    with patch('requests.get') as mock_get:\n",
    "        # Test with a title\n",
    "        mock_get.return_value.status_code = 200\n",
    "        mock_get.return_value.json.return_value = mock_title_response\n",
    "        result = query_openalex_api(\"Example Article\")\n",
    "        assert isinstance(result, str), \"Result should be a string\"\n",
    "        parsed_result = json.loads(result)\n",
    "        assert len(parsed_result) == 1, \"Should return one result for title search\"\n",
    "        assert parsed_result[0]['title'] == \"Example Article\", \"Title should match\"\n",
    "\n",
    "        # Test with a PMID\n",
    "        mock_get.return_value.json.return_value = mock_pmid_response\n",
    "        result = query_openalex_api(\"12345678\")\n",
    "        assert isinstance(result, str), \"Result should be a string\"\n",
    "        parsed_result = json.loads(result)\n",
    "        assert parsed_result['title'] == \"Example Article with a PMID\", \"Title should match for PMID search\"\n",
    "\n",
    "        # Test with a DOI\n",
    "        mock_get.return_value.json.return_value = mock_doi_response\n",
    "        result = query_openalex_api(\"10.9876/example\")\n",
    "        assert isinstance(result, str), \"Result should be a string\"\n",
    "        parsed_result = json.loads(result)\n",
    "        assert parsed_result['doi'] == \"https://doi.org/10.9876/example\", \"DOI should match\"\n",
    "\n",
    "        # Test with an empty identifier\n",
    "        result = query_openalex_api(\"\")\n",
    "        assert \"error\" in json.loads(result), \"Should return an error message for empty identifier\"\n",
    "\n",
    "        # Test with multiple results for title search\n",
    "        mock_get.return_value.json.return_value = {\"meta\": {\"count\": 10}, \"results\": [{}] * 10}\n",
    "        result = query_openalex_api(\"Common Title\")\n",
    "        assert result == \"Error: The search results are more than 5. Please provide a correct title.\", \"Should return error for too many results\"\n",
    "\n",
    "        # Test with no results\n",
    "        mock_get.return_value.json.return_value = {\"meta\": {\"count\": 0}, \"results\": []}\n",
    "        result = query_openalex_api(\"Non-existent Article\")\n",
    "        assert result == \"No results found for the provided title.\", \"Should return a message indicating no results found\"\n",
    "\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_query_openalex_api()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Below are tests that make calls to the OpenAlex API... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"https://openalex.org/W4290546253\",\n",
      "  \"doi\": \"https://doi.org/10.3389/fimmu.2022.856497\",\n",
      "  \"title\": \"Human leukocyte antigen class II gene diversity tunes antibody repertoires to common pathogens\",\n",
      "  \"publication_year\": 2022,\n",
      "  \"cited_by_count\": 9,\n",
      "  \"cited_by_api_url\": \"https://api.openalex.org/works?filter=cites:W4290546253\",\n",
      "  \"open_access\": {\n",
      "    \"is_oa\": true,\n",
      "    \"oa_status\": \"gold\",\n",
      "    \"oa_url\": \"https://www.frontiersin.org/articles/10.3389/fimmu.2022.856497/pdf\",\n",
      "    \"any_repository_has_fulltext\": true\n",
      "  },\n",
      "  \"type\": \"article\",\n",
      "  \"type_crossref\": \"journal-article\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "try:\n",
    "    print(query_openalex_api(\"36003377\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "title = \"Human leukocyte antigen class II gene diversity tunes antibody repertoires to common pathogens\"\n",
    "args = [title, \"36003377\", \"10.3389/fimmu.2022.856497\", \"doi.org/10.3389/fimmu.2022.856497\", \"https://doi.org/10.3389/fimmu.2022.856497\"]\n",
    "try:\n",
    "    api_responses = [query_openalex_api(arg) for arg in args]\n",
    "    # for response in api_responses:\n",
    "    #     print(response[:300])\n",
    "    assert all(title in response for response in api_responses), \"All responses should contain the title.\"\n",
    "    assert all(isinstance(response, str) for response in api_responses), \"All responses should be strings.\"\n",
    "    assert all(response == api_responses[1] for response in api_responses[1:]), \"All responses should be the same, except for the title search.\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "The follwoing code cells are for demonstrating the use of **Semantic Scholar's Academic Graph API** to retrieve information about scholarly articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.semanticscholar.org/graph/v1/paper/PMID:36003377?fields=title,year,tldr\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# Try loading the Semantic Scholar API key from the environment variables\n",
    "try:\n",
    "    SEMANTIC_SCHOLAR_API_KEY\n",
    "except NameError:\n",
    "    SEMANTIC_SCHOLAR_API_KEY = os.environ.get(\"SEMANTIC_SCHOLAR_API_KEY\")\n",
    "\n",
    "# Construct the URL to query the Semantic Scholar API by paper ID, and define headers with an API key\n",
    "paper_id = \"PMID:36003377\"  # Example paper ID\n",
    "academicgraph_base_url = \"https://api.semanticscholar.org/graph/v1\"\n",
    "resource = \"/paper/\"\n",
    "resource_path = f\"{resource}{paper_id}\"\n",
    "fields = \"title,year,tldr\"\n",
    "query_params = f\"?fields={fields}\"\n",
    "url = f\"{academicgraph_base_url}{resource_path}{query_params}\"\n",
    "headers = {'x-api-key': SEMANTIC_SCHOLAR_API_KEY}\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"paperId\": \"4d29302308973a7a92dc3a9f1295b2ba761e2a77\",\n",
      "  \"title\": \"Human leukocyte antigen class II gene diversity tunes antibody repertoires to common pathogens\",\n",
      "  \"year\": 2021,\n",
      "  \"tldr\": {\n",
      "    \"model\": \"tldr@v2.0.0\",\n",
      "    \"text\": \"It is demonstrated that multiple HLA class II alleles play a synergistic role in shaping the antibody repertoire, and HLA-DRB1 genotypes with specific antigens were identified, suggesting that HLAclass II gene polymorphisms confer specific humoral immunity against common pathogens.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# Send the API request\n",
    "try:\n",
    "   response = requests.get(url, headers=headers)\n",
    "\n",
    "   if response.status_code == 200:\n",
    "      response_data = response.json()\n",
    "      # Process and print the response data as needed\n",
    "      print(json.dumps(response_data, indent=2))\n",
    "   else:\n",
    "      print(f\"Request failed with status code {response.status_code}: {response.text}\")\n",
    "   time.sleep(1) # sleep for 1 second to avoid rate limiting issues\n",
    "except Exception as e:\n",
    "   print(f\"Error: {e}\")\n",
    "   errors.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed successfully!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# Query by title; this may return multiple results\n",
    "title = \"Human leukocyte antigen class II gene diversity tunes antibody repertoires to common pathogens\"\n",
    "url = f\"{academicgraph_base_url}/paper/search?query={title}&fields={fields}\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        # print(json.dumps(response_data, indent=2))\n",
    "        assert title in response_data['data'][0]['title'], \"Title should match the query\"\n",
    "        print(\"Test passed successfully!\")\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}: {response.text}\")\n",
    "    time.sleep(1) # sleep for 1 second to avoid rate limiting issues\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed successfully!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# Title search; this only returns the top result\n",
    "title = \"Human leukocyte antigen class II gene diversity tunes antibody repertoires to common pathogens\"\n",
    "url = f\"{academicgraph_base_url}/paper/search/match?query={title}&fields={fields}\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        # print(json.dumps(response_data, indent=2))\n",
    "        assert title in response_data[\"data\"][0][\"title\"], \"Title should match the query\"\n",
    "        print(\"Test passed successfully!\")\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}: {response.text}\")\n",
    "    time.sleep(1) # sleep for 1 second to avoid rate limiting issues\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "The function `query_semantic_scholar_api()` below is executed to query the Semantic Scholar database for additional information about a given article, either by title, PubMed ID, or DOI. To\n",
    "increase the rate limit, provide your own API key (see the documentation for more information).\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Assert the correct format of the JSON schema..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def query_semantic_scholar_api(query_param: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve metadata for a given article from the Semantic Scholar Academic Graph (S2AG), a large knowledge graph of scientific literature that combines data from multiple sources.\n",
    "    Use this tool to query the Semantic Scholar Graph API by using either the article title, the PubMed ID, or the digital object identifier (DOI) to retrieve the following metadata:\n",
    "    - the title\n",
    "    - the publication year\n",
    "    - the abstract\n",
    "    - a tldr (too long, didn't read) summary\n",
    "    - the authors of the article\n",
    "    - the URL to the open-access PDF version of the article, if available\n",
    "    - the journal name\n",
    "    - a url to the article on the Semantic Scholar website\n",
    "    Use this tool only if an article title, PubMed ID or DOI is provided by the user or was extracted from a local PDF file and is present in the conversation history.\n",
    "    \n",
    "    Args:\n",
    "        query_param (str): The article title, the PubMed ID, or the digital object identifier of the article to retrieve metadata for. May be provided by the user or extracted from a local PDF file and present in the conversation history. Do not include the 'https://doi.org/' prefix for DOIs, or keys such as 'DOI', 'PMCID' or 'PMID'. The tool will automatically detect the type of identifier provided.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON-formatted string including the search results from the Semantic Scholar database. If no results are found or the API query fails, an appropriate message is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    # Try to get the API key from the environment variables, if available, and define the headers\n",
    "    try:\n",
    "        SEMANTIC_SCHOLAR_API_KEY\n",
    "    except NameError:\n",
    "        SEMANTIC_SCHOLAR_API_KEY = os.environ.get(\"SEMANTIC_SCHOLAR_API_KEY\")\n",
    "    headers = {'x-api-key': SEMANTIC_SCHOLAR_API_KEY}\n",
    "\n",
    "    # Validate the input\n",
    "    if query_param is None or query_param == \"\":\n",
    "        return json.dumps({\"error\": \"The query parameter must be a non-empty string.\"})\n",
    "    elif not isinstance(query_param, str):\n",
    "        query_param = str(query_param)\n",
    "    \n",
    "    # Clean the query parameter\n",
    "    query_param = query_param.strip().lower() # Convert to lowercase and remove leading/trailing whitespace\n",
    "    if query_param.startswith(\"https://doi.org/\"):\n",
    "        query_param = query_param.replace(\"https://doi.org/\", \"\")\n",
    "    elif query_param.startswith(\"doi.org/\"):\n",
    "        query_param = query_param.replace(\"doi.org/\", \"\")\n",
    "    elif query_param.startswith(\"doi\"):\n",
    "        query_param = query_param.replace(\"doi\", \"\")\n",
    "    elif query_param.startswith(\"pmid\"):\n",
    "        query_param = query_param.replace(\"pmid\", \"\")\n",
    "    elif query_param.startswith(\"pmcid\"):\n",
    "        query_param = query_param.replace(\"pmcid\", \"\")\n",
    "    if detect_id_type(query_param) != \"potential_title\":\n",
    "        query_param = query_param.replace(\":\", \"\") # Remove any colons from the query parameter if it is not a title\n",
    "        query_param = query_param.replace(\" \", \"\") # Remove spaces from the query parameter if it is not a title\n",
    "\n",
    "    # Constants\n",
    "    academicgraph_base_url = \"https://api.semanticscholar.org/graph/v1\"\n",
    "    fields = \"title,year,authors,tldr,abstract,citationCount,openAccessPdf,journal,url\" # The values to retrieve from the API\n",
    "\n",
    "\n",
    "    # Construct the URL based on the identifier type\n",
    "    if detect_id_type(query_param) == \"potential_title\":\n",
    "        url = f\"{academicgraph_base_url}/paper/search/match?query={query_param}&fields={fields}\"\n",
    "    elif detect_id_type(query_param) == \"pmid\":\n",
    "        url = f\"{academicgraph_base_url}/paper/PMID:{query_param}?&fields={fields}\"\n",
    "    elif detect_id_type(query_param) == \"doi\":\n",
    "        url = f\"{academicgraph_base_url}/paper/DOI:{query_param}?&fields={fields}\"\n",
    "    else:\n",
    "        return json.dumps({\"error\": \"The query parameter must be a valid title, PMID, or DOI.\"})\n",
    "    \n",
    "    response = requests.get(url, headers=headers) # Send the API request\n",
    "    # print(response.url) # Uncomment for debugging\n",
    "    time.sleep(2) # sleep for 2 seconds to avoid rate limiting issues\n",
    "    \n",
    "    # Check response status\n",
    "    if response.status_code == 200:\n",
    "        return json.dumps(response.json(), indent=2)\n",
    "    else:\n",
    "        return f\"Error: Failed to query Semantic Scholar API. Status code: {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "assert type(query_semantic_scholar_api.json_schema) == dict\n",
    "assert query_semantic_scholar_api.json_schema['function']['name'] == \"query_semantic_scholar_api\"\n",
    "assert 'query_param' in query_semantic_scholar_api.json_schema['function']['parameters']['properties'].keys()\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "A test case for the `query_semantic_scholar_api()` function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import json\n",
    "from unittest.mock import patch\n",
    "\n",
    "# Mock response for successful API call\n",
    "mock_success_response = {\n",
    "    \"title\": \"Example Article\",\n",
    "    \"year\": 2023,\n",
    "    \"authors\": [{\"name\": \"John Doe\"}, {\"name\": \"Jane Smith\"}],\n",
    "    \"tldr\": {\"text\": \"This is a summary of the article.\"},\n",
    "    \"abstract\": \"This is the abstract of the example article.\",\n",
    "    \"citationCount\": 42,\n",
    "    \"openAccessPdf\": {\"url\": \"https://example.com/paper.pdf\"},\n",
    "    \"journal\": {\"name\": \"Example Journal\"},\n",
    "    \"url\": \"https://www.semanticscholar.org/paper/example\"\n",
    "}\n",
    "\n",
    "# Test case for query_semantic_scholar_api function\n",
    "def test_query_semantic_scholar_api():\n",
    "    # Mock the requests.get function\n",
    "    with patch('requests.get') as mock_get:\n",
    "        # Configure the mock to return a successful response\n",
    "        mock_get.return_value.status_code = 200\n",
    "        mock_get.return_value.json.return_value = mock_success_response\n",
    "\n",
    "        # Test with a title\n",
    "        result = query_semantic_scholar_api(\"Example Article\")\n",
    "        assert isinstance(result, str), \"Result should be a string\"\n",
    "        \n",
    "        parsed_result = json.loads(result)\n",
    "        assert parsed_result == mock_success_response, \"Returned JSON should match the mock response\"\n",
    "\n",
    "        # Test with a DOI\n",
    "        result = query_semantic_scholar_api(\"10.1234/example.doi\")\n",
    "        assert isinstance(result, str), \"Result should be a string\"\n",
    "        \n",
    "        parsed_result = json.loads(result)\n",
    "        assert parsed_result == mock_success_response, \"Returned JSON should match the mock response\"\n",
    "\n",
    "    # Test with an empty identifier\n",
    "    result = query_semantic_scholar_api(\"\")\n",
    "    assert \"error\" in json.loads(result), \"Should return an error message for empty identifier\"\n",
    "\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "# Run the test\n",
    "test_query_semantic_scholar_api()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Below are tests that make API calls to Semantic Scholar to retrieve information about an actual article in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"paperId\": \"4d29302308973a7a92dc3a9f1295b2ba761e2a77\",\n",
      "  \"url\": \"https://www.semanticscholar.org/paper/4d29302308973a7a92dc3a9f1295b2ba761e2a77\",\n",
      "  \"title\": \"Human leukocyte antigen class II gene diversity tunes antibody repertoires to common pathogens\",\n",
      "  \"abstract\": \"Allelic diversity of HLA class II genes may help maintain humoral immunity against infectious diseases. We investigated the relative contribution of specific HLA class II alleles, haplotypes and genotypes on the variation of antibody responses to a variety of common pathogens in a cohort of 800 adults representing the general Arab population. We found that classical HLA class II gene heterozygosity confers a selective advantage. Moreover, we demonstrated that multiple HLA class II alleles play a synergistic role in shaping the antibody repertoire. Interestingly, associations of HLA-DRB1 genotypes with specific antigens were identified. Our findings suggest that HLA class II gene polymorphisms confer specific humoral immunity against common pathogens, which may have contributed to the genetic diversity of HLA class II loci during hominine evolution.\",\n",
      "  \"year\": 2021,\n",
      "  \"citationCount\": 11,\n",
      "  \"openAccessPdf\": {\n",
      "    \"url\": \"https://www.frontiersin.org/articles/10.3389/fimmu.2022.856497/pdf\",\n",
      "    \"status\": \"GOLD\"\n",
      "  },\n",
      "  \"tldr\": {\n",
      "    \"model\": \"tldr@v2.0.0\",\n",
      "    \"text\": \"It is demonstrated that multiple HLA class II alleles play a synergistic role in shaping the antibody repertoire, and HLA-DRB1 genotypes with specific antigens were identified, suggesting that HLAclass II gene polymorphisms confer specific humoral immunity against common pathogens.\"\n",
      "  },\n",
      "  \"journal\": {\n",
      "    \"name\": \"Frontiers in Immunology\",\n",
      "    \"volume\": \"13\"\n",
      "  },\n",
      "  \"authors\": [\n",
      "    {\n",
      "      \"authorId\": \"1563540694\",\n",
      "      \"name\": \"Taushif Khan\"\n",
      "    },\n",
      "    {\n",
      "      \"authorId\": \"144779428\",\n",
      "      \"name\": \"Mahbuba Rahman\"\n",
      "    },\n",
      "    {\n",
      "      \"authorId\": \"40495379\",\n",
      "      \"name\": \"Ikhlak Ahmed\"\n",
      "    },\n",
      "    {\n",
      "      \"authorId\": \"2061171685\",\n",
      "      \"name\": \"Fatima Al Ali\"\n",
      "    },\n",
      "    {\n",
      "      \"authorId\": \"2681265\",\n",
      "      \"name\": \"P. Jithesh\"\n",
      "    },\n",
      "    {\n",
      "      \"authorId\": \"5899497\",\n",
      "      \"name\": \"N. Marr\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "try:\n",
    "    print(query_semantic_scholar_api(\"36003377\"))\n",
    "    response = query_semantic_scholar_api(\"36003377\")\n",
    "    response = json.loads(response)\n",
    "    assert response[\"paperId\"] == \"4d29302308973a7a92dc3a9f1295b2ba761e2a77\", \"PubMed ID should match the corresponding paper ID\"\n",
    "    print(\"Test passed!\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "title = \"Human leukocyte antigen class II gene diversity tunes antibody repertoires to common pathogens\"\n",
    "args = [title, \"36003377\", \"10.3389/fimmu.2022.856497\", \"doi.org/10.3389/fimmu.2022.856497\", \"https://doi.org/10.3389/fimmu.2022.856497\"]\n",
    "try: \n",
    "    api_responses = [query_semantic_scholar_api(arg) for arg in args]\n",
    "    # for response in api_responses:\n",
    "    #     print(response[:300])\n",
    "    assert all(title in response for response in api_responses), \"All responses should contain the title.\"\n",
    "    assert all(isinstance(response, str) for response in api_responses), \"All responses should be strings.\"\n",
    "    assert all(response == api_responses[1] for response in api_responses[1:]), \"All responses should be the same, except for the title search.\"\n",
    "    print(\"All tests passed!\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def respond_to_generic_queries() -> str:\n",
    "    \"\"\"\n",
    "    A function to respond to generic questions or queries from the user. Use this tool if no better tool is available.\n",
    "\n",
    "    This tool does not take any arguments.\n",
    "\n",
    "    Returns:\n",
    "        str: A response to a generic question.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"There is no specific tool available to respond this query from the user. State your capabilities based the system message or provide a response based on the conversation history.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "assert type(respond_to_generic_queries.json_schema) == dict\n",
    "assert respond_to_generic_queries.json_schema['function']['name'] == \"respond_to_generic_queries\"\n",
    "assert type(respond_to_generic_queries()) == str\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assistant class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "The Assistant class below is defined to simplify the process of chat and tool use, along with a function to show responses.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_response(response: Dict[str, Any] or Generator[Dict[str, Any], None, None]) -> None:\n",
    "    \"\"\"\n",
    "    Print the response from the LLM in a human-readable format.\n",
    "\n",
    "    Args:\n",
    "        response (Dict[str, Any] or Generator[Dict[str, Any], None, None]): The response from the LLM.\n",
    "    \"\"\"\n",
    "    # ANSI escape code for blue and red text\n",
    "    BLUE = \"\\033[94m\"\n",
    "    RED = \"\\033[91m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "\n",
    "    if isinstance(response, dict):\n",
    "        print(f\"\\n{BLUE}{response['message']['content']}{RESET}\")\n",
    "        return response['message']['content']\n",
    "\n",
    "    elif isinstance(response, Generator):\n",
    "        print(\"\\n\")\n",
    "        _response = \"\"\n",
    "        for chunk in response:\n",
    "            _response += chunk['message']['content']\n",
    "            print(f\"{BLUE}{chunk['message']['content']}{RESET}\", end='', flush=True)\n",
    "        return _response\n",
    "    \n",
    "    elif response is None:\n",
    "        print(f\"\\n{RED}No response from the LLM.{RESET}\")\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"\\n{RED}nvalid response type. Must be a dictionary or a generator.{RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94mThis is a mock response for testing.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# Test with dictionary input\n",
    "mock_response = {\n",
    "    \"message\": {\n",
    "        \"content\": \"This is a mock response for testing.\"\n",
    "    }\n",
    "}\n",
    "response = show_response(mock_response)\n",
    "assert response == \"This is a mock response for testing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import ollama\n",
    "from typing import Dict, Any, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import sys\n",
    "import io\n",
    "from pathlib import Path\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self,\n",
    "        sys_message: str or None = None, # The system message for the assistant; if not provided, a default message is used\n",
    "        model: str = \"llama3.1:latest\", # The model to use for the assistant\n",
    "        tools: Dict[str, Any] = { # The tools available to the assistant\n",
    "           \"get_file_names\": get_file_names,\n",
    "           \"extract_text_from_pdf\": extract_text_from_pdf,\n",
    "           \"get_titles_and_first_authors\": get_titles_and_first_authors,\n",
    "           \"summarize_local_document\": summarize_local_document,\n",
    "           \"describe_python_code\": describe_python_code,\n",
    "           \"id_converter_tool\": id_converter_tool,\n",
    "           \"query_openalex_api\": query_openalex_api,\n",
    "           \"query_semantic_scholar_api\": query_semantic_scholar_api,\n",
    "           \"respond_to_generic_queries\": respond_to_generic_queries,\n",
    "        },\n",
    "        add_tools: Dict[str, Any] = {}, # Optional argument to add additional tools to the assistant, when initializing\n",
    "        authentication: Optional[Dict[str, str]] = None, # Authentication credentials for API calls to external services\n",
    "        dir_path: str = \"../data\", # The directory path to which the assistant has access on the local computer\n",
    "        messages: List[Dict[str, str]] = []): # The conversation history\n",
    "        \n",
    "        self.sys_message = sys_message\n",
    "        self.model = model\n",
    "        self.tools = tools\n",
    "        self.tools.update(add_tools) # Add additional tools to the assistant, if provided\n",
    "        if self.tools:\n",
    "            self.tools[\"describe_tools\"] = self.describe_tools # Add the describe_tools function to the tools list for the assistant, if the tools list is not empty\n",
    "        self.authentication = authentication or {}\n",
    "        self.dir_path = Path(dir_path).resolve()\n",
    "        self.messages = messages\n",
    "\n",
    "        # Set global variables\n",
    "        global DIR_PATH\n",
    "        DIR_PATH = self.dir_path\n",
    "        global MODEL\n",
    "        MODEL = self.model\n",
    "        # TODO: Consider allowing the user to set different models for different tasks and tools\n",
    "        # e.g. a model such as llama 3.1 for function calls, command-r-plus for summarization, aya for translation, etc.\n",
    "        \n",
    "        # ANSI escape codes, used for output formatting\n",
    "        GREY = \"\\033[90m\"\n",
    "        BLUE = \"\\033[94m\"\n",
    "        RED = \"\\033[91m\"\n",
    "        RESET = \"\\033[0m\"\n",
    "\n",
    "        # Load the API keys from the environment variables or the authentication dictionary\n",
    "        self.SEMANTIC_SCHOLAR_API_KEY = self.authentication.get(\"SEMANTIC_SCHOLAR_API_KEY\")\n",
    "        self.EMAIL = self.authentication.get(\"EMAIL\")\n",
    "\n",
    "        if not self.SEMANTIC_SCHOLAR_API_KEY:\n",
    "            self.SEMANTIC_SCHOLAR_API_KEY = os.environ.get(\"SEMANTIC_SCHOLAR_API_KEY\")\n",
    "            if self.SEMANTIC_SCHOLAR_API_KEY:\n",
    "                print(f\"{GREY}Loaded Semantic Scholar API key from the environment variables.{RESET}\")\n",
    "        if not self.EMAIL:\n",
    "            self.EMAIL = os.environ.get(\"EMAIL\")\n",
    "            if self.EMAIL:\n",
    "                print(f\"{GREY}Loaded email address from the environment variables.{RESET}\")\n",
    "\n",
    "        # Generate the default directory for storing data files if it does not exist\n",
    "        if not os.path.exists(DIR_PATH):\n",
    "            os.mkdir(DIR_PATH)\n",
    "            print(f\"{GREY}Created directory {DIR_PATH} for storing data files.{RESET}\\n\")\n",
    "        else: \n",
    "            print(f\"{GREY}A local directory {DIR_PATH} already exists for storing data files. No of files: {len(os.listdir(DIR_PATH))}{RESET}\\n\")\n",
    "\n",
    "        # Set the default system message if not provided\n",
    "        if not self.sys_message:\n",
    "            self.sys_message =\"\"\"You are an AI assistant specialized in analyzing research articles.\n",
    "        Your role is to provide concise, human-readable responses based on information from tools and conversation history.\n",
    "\n",
    "        Key instructions:\n",
    "        1. Use provided tools to gather information before answering.\n",
    "        2. Interpret tool results and provide clear, concise answers in natural language.\n",
    "        3. If you can't answer with available tools, state this clearly.\n",
    "        4. Don't provide information if tool content is empty.\n",
    "        5. Never include raw JSON, tool outputs, or formatting tags in responses.\n",
    "        6. Format responses as plain text for direct human communication.\n",
    "        7. Use clear formatting (e.g., numbered or bulleted lists) when appropriate.\n",
    "        8. Provide article details (e.g., DOI, citation count) in a conversational manner.\n",
    "\n",
    "        Act as a knowledgeable research assistant, offering clear and helpful information based on available tools and data.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check if the model is available\n",
    "        downloaded_models = []\n",
    "        for model in ollama.list()[\"models\"]:\n",
    "            downloaded_models.append((model[\"name\"].replace(\":latest\", \"\")))\n",
    "        assert self.model.replace(\":latest\", \"\") in downloaded_models, f\"Model {self.model} not found. Please pull the latest version from the server.\"\n",
    "\n",
    "        # Check if the selected model supports tool calling\n",
    "        # for more information, visit https://ollama.com/blog/tool-support\n",
    "        assert self.model.split(\":\")[0] in [\"llama3.1\", \"command-r-plus\", \"mistral-nemo\", \"firefunction-v2\"], f\"Model {self.model} does not support tool calling. Please select a different model.\"\n",
    "\n",
    "        if len(self.tools) == 0:\n",
    "            print(f\"\\033[91mNo tools provided! Please add tools to the assistant.\\033[0m\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Assistant, powered by {self.model.split(':')[0]}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def list_tools(self):\n",
    "        \"List the available tools in the assistant.\"\n",
    "        for tool in self.tools.keys():\n",
    "            print(tool)\n",
    "\n",
    "    def get_tools_schema(self):\n",
    "        \"Return the JSON schema for the available tools.\"\n",
    "        return [func.json_schema for func in self.tools.values()]\n",
    "\n",
    "    @json_schema_decorator\n",
    "    def describe_tools(self) -> str:\n",
    "        \"\"\"Use this tool when asked about the assistant's available tools and capabilities.\n",
    "\n",
    "        Returns:\n",
    "            str: A string with the descriptions of the available tools.\n",
    "        \"\"\"\n",
    "        return f\"Available tools are: {self.get_tools_schema()}\\n State your capabilities based the available tools in a conversational manner.\"\n",
    "        # return f\"{self.pprint_tools()}\\n State your capabilities based the available tools in a conversational manner.\"\n",
    "\n",
    "    def chat(self, prompt: str, show_progress: bool = False, stream_response: bool = True, redirect_output: bool = False):\n",
    "        \"\"\"\n",
    "        Start a conversation with the AI assistant.\n",
    "\n",
    "        Args:\n",
    "            prompt (str): The user's prompt or question.\n",
    "            show_progress (bool): Whether to show the step-by-step progress of the fuction calls, including the tool calls and tool outputs. Default is False.\n",
    "            stream_response (bool): Whether to stream the final response from the LLM. Default is True. Automatically set to True if redirect_output is True.\n",
    "            redirect_output (bool): Whether to redirect the output to be compatible with st.write_stream. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            str: The AI assistant's response.\n",
    "        \"\"\"\n",
    "        # At the start of the conversation, if no messages are provided, add the system message and user prompt\n",
    "        if not self.messages:\n",
    "            self.messages = [\n",
    "                {'role': \"system\", 'content': self.sys_message},\n",
    "                {'role': 'user', 'content': prompt},\n",
    "            ]\n",
    "        else:\n",
    "            self.messages.append({'role': 'user', 'content': prompt})\n",
    "\n",
    "        # Generate JSON schemas for the available tools\n",
    "        tools_schema = self.get_tools_schema()\n",
    "\n",
    "        # Make a request to the LLM to select a tool\n",
    "        if show_progress: print(\"Selecting tools...\\n\")\n",
    "        response = ollama.chat(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            tools=tools_schema,\n",
    "            stream=False, # Set to False to avoid streaming the tool calls\n",
    "        )\n",
    "\n",
    "        # Add the model's response to the conversation history\n",
    "        if response.get('message', {}).get('tool_calls'):\n",
    "            if show_progress: print(response['message']['tool_calls']) # Uncomment for debugging\n",
    "            self.messages.append(\n",
    "                {'role': 'assistant', 'tool_calls': response['message']['tool_calls']}\n",
    "                )\n",
    "        else:\n",
    "            # print(\"LLM response (not added to the conversation history):\", response['message']['content']) # Uncomment for debugging\n",
    "            self.messages.append(\n",
    "                {'role': 'assistant', 'tool_calls': []}\n",
    "                )\n",
    "            print(f\"\\033[91mNo tool calls found in the response. Adding an empty tool_calls list to the conversation history. Aborting...\\033[0m\\n\")\n",
    "            return None # Abort the function if no tool calls are found in the response. Goal is to force the assistant to use a tool. We will generate a tool for generic responses.\n",
    "\n",
    "        # Call the function if a tool is selected\n",
    "        for tool in response['message']['tool_calls']:\n",
    "            # print(\"Arguments:\", tool['function']['arguments'])\n",
    "            function_to_call = self.tools[tool['function']['name']]\n",
    "            if show_progress: print(f\"Calling {tool['function']['name']}() with arguments {tool['function']['arguments']}...\\n\")\n",
    "            args = tool['function']['arguments']\n",
    "\n",
    "            try:\n",
    "                function_response = function_to_call(**args)\n",
    "                # print(f\"Function response type: {type(function_response)}\\n\") # Uncomment for debugging\n",
    "                # print(f\"Function response: {function_response}\\n\") # Uncomment for debugging\n",
    "                function_response = str(function_response) if function_response is not None else \"\"\n",
    "                # assert isinstance(function_response, str), \"Function response must be a string.\"\n",
    "            except Exception as e:\n",
    "                function_response = f\"Error: {e}\"\n",
    "\n",
    "                if show_progress: print(f\"Function response:\\n{function_response}\\n\")\n",
    "            # Add the fucntion response to the conversation history\n",
    "            self.messages.append( \n",
    "                {\n",
    "                    'role': 'tool',\n",
    "                    'content': function_response,\n",
    "                }\n",
    "            ) \n",
    "\n",
    "        if redirect_output: # If the output is to be redirected...\n",
    "            stream_response = True # always use streaming for compatibility with st.write_stream\n",
    "\n",
    "        # Make a second request to the LLM with the tool output to generate a final response\n",
    "        if show_progress: print(\"Generating final response...\")\n",
    "        response = ollama.chat(\n",
    "            model=self.model,\n",
    "            format=\"\", # Set to empty string to avoid JSON formatting; If JSON formatting is needed, set to \"json\"\n",
    "            messages=self.messages,\n",
    "            stream=stream_response, # Set to True , response will be a generator\n",
    "        )\n",
    "        \n",
    "        # Advanced parameters (optional):\n",
    "        # keep_alive: controls how long the model will stay loaded into memory following the request (default: 5m)\n",
    "        # options: additional model parameters listed in the documentation for the Modelfile such as temperature\n",
    "        # for more information, visi:\n",
    "        # https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "        # https://github.com/ollama/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\n",
    "        \n",
    "        if redirect_output:\n",
    "            # Return a generator for st.write_stream\n",
    "            def response_generator():\n",
    "                full_content = \"\"\n",
    "                for chunk in response:\n",
    "                    content = chunk['message']['content']\n",
    "                    full_content += content\n",
    "                    yield content\n",
    "                self.messages.append({'role': 'assistant', 'content': full_content})\n",
    "            return response_generator()\n",
    "\n",
    "        else:\n",
    "            if isinstance(response, dict):\n",
    "                content = response['message']['content']\n",
    "                self.messages.append({'role': 'assistant', 'content': content})\n",
    "                print(content)\n",
    "                return content  # Return the content directly, not as a generator\n",
    "                \n",
    "            elif hasattr(response, '__iter__'):  # Check if it's iterable (for streaming)\n",
    "                full_content = \"\"\n",
    "                for chunk in response:\n",
    "                    content = chunk['message']['content']\n",
    "                    full_content += content\n",
    "                    print(content, end='', flush=True)\n",
    "                self.messages.append({'role': 'assistant', 'content': full_content})\n",
    "                return full_content  # Return the full content, not as a generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell is for testing purposes only. It is not part of the final library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mLoaded Semantic Scholar API key from the environment variables.\u001b[0m\n",
      "\u001b[90mLoaded email address from the environment variables.\u001b[0m\n",
      "\u001b[90mA local directory /Users/user2/GitHub/scholaris/data already exists for storing data files. No of files: 1\u001b[0m\n",
      "\n",
      "I can summarize research articles, provide information on various tools, extract text from PDF files, convert IDs, query OpenAlex API, and more! I've got a range of functions that can help with specific tasks.\n",
      "\n",
      "* I can summarize local documents (PDF, markdown, or text) using the `summarize_local_document` function.\n",
      "* The `get_titles_and_first_authors` function retrieves titles and first authors from research articles in PDF files.\n",
      "* You can use `extract_text_from_pdf` to extract specific details from a PDF file, such as abstract, authors, conclusions, or user-specified content of other sections.\n",
      "* If you have a list of IDs (PMIDs, PMCIDs, DOIs), the `id_converter_tool` function can convert them and find corresponding IDs for the same articles.\n",
      "* The `query_openalex_api` tool retrieves metadata from OpenAlex API using article title, PubMed ID, PMCID, or DOI as query parameters.\n",
      "* You can use the `respond_to_generic_queries` function if no other tool is available.\n",
      "\n",
      "Just let me know what you need help with, and I'll do my best to assist!"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# Test the Assistant class' chat method with no additional arguments\n",
    "try:\n",
    "    assistant = Assistant()\n",
    "    response = assistant.chat(\"Tell me about the tools you have available.\")\n",
    "    assert isinstance(response, str), f\"Expected response type str but got {type(response)}\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mLoaded Semantic Scholar API key from the environment variables.\u001b[0m\n",
      "\u001b[90mLoaded email address from the environment variables.\u001b[0m\n",
      "\u001b[90mA local directory /Users/user2/GitHub/scholaris/data already exists for storing data files. No of files: 1\u001b[0m\n",
      "\n",
      "I can perform various tasks based on the available tools. Here are some of my capabilities:\n",
      "\n",
      "* I can summarize the content of local documents such as PDFs, markdown files, and text documents.\n",
      "* I can describe the purpose of Python code in a local file.\n",
      "* I can extract specific details from a PDF document using the `extract_text_from_pdf` tool.\n",
      "* I can get titles and first authors from a directory of PDF files using the `get_titles_and_first_authors` function.\n",
      "* I can query the OpenAlex API to retrieve metadata for an article based on its title, PMID, PMCID, or DOI.\n",
      "* I can query the Semantic Scholar Academic Graph (S2AG) API to retrieve metadata for an article based on its title, PMID, or DOI.\n",
      "\n",
      "These capabilities are based on the available tools and functions. If you have any specific questions or tasks, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# Test the Assistant class' chat method with the stream_response argument set to False\n",
    "try:\n",
    "    assistant = Assistant()\n",
    "    response = assistant.chat(\"Tell me about the tools you have available.\", stream_response=False)\n",
    "    assert isinstance(response, str), f\"Expected response type str but got {type(response)}\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mLoaded Semantic Scholar API key from the environment variables.\u001b[0m\n",
      "\u001b[90mLoaded email address from the environment variables.\u001b[0m\n",
      "\u001b[90mA local directory /Users/user2/GitHub/scholaris/data already exists for storing data files. No of files: 1\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "try:\n",
    "    # Test the Assistant class' chat method with the redirect_output argument set to True\n",
    "    assistant = Assistant()\n",
    "    response = assistant.chat(\"Tell me about the tools you have available.\", redirect_output=True)\n",
    "    assert isinstance(response, Generator), f\"Expected response type to be a generator, but got {type(response)}\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mLoaded Semantic Scholar API key from the environment variables.\u001b[0m\n",
      "\u001b[90mLoaded email address from the environment variables.\u001b[0m\n",
      "\u001b[90mA local directory /Users/user2/GitHub/scholaris/data already exists for storing data files. No of files: 1\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "try:\n",
    "    # Test the Assistant class' initialization and the dir_path attribute; should be a valid Path object that exists\n",
    "    assistant = Assistant()\n",
    "    assert isinstance(assistant.dir_path, Path), f\"Expected dir_path to be a Path object, but got {type(assistant.dir_path)}\"\n",
    "    assert assistant.dir_path.exists(), f\"Expected dir_path to exist, but it does not.\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mLoaded Semantic Scholar API key from the environment variables.\u001b[0m\n",
      "\u001b[90mLoaded email address from the environment variables.\u001b[0m\n",
      "\u001b[90mA local directory /Users/user2/GitHub/scholaris/data already exists for storing data files. No of files: 1\u001b[0m\n",
      "\n",
      "Selecting tools...\n",
      "\n",
      "[{'function': {'name': 'get_file_names', 'arguments': {'ext': 'pdf, txt'}}}]\n",
      "Calling get_file_names() with arguments {'ext': 'pdf, txt'}...\n",
      "\n",
      "Generating final response...\n",
      "I have access to the following PDF files:\n",
      "\n",
      "* jci.insight.144499.v2.pdf"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "try:\n",
    "    # Test the Assistant class' chat method with with a prompt that should call the get_file_names tool\n",
    "    assistant = Assistant()\n",
    "    assistant.chat(\"Which PDF files do you have access to in the local data directory?\", show_progress=True)\n",
    "    assert any('get_file_names' == item.get('tool_calls', [{}])[0].get('function', {}).get('name') for item in assistant.messages), \"Function 'get_file_names' not found in the messages\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Continuing with the implementation of additional Assistant class methods..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def add_to_class(Class: type):\n",
    "    \"\"\"Register functions as methods in a class that has already been defined.\"\"\"\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@add_to_class(Assistant)\n",
    "def show_conversion_history(self, show_function_calls: bool = False):\n",
    "    \"\"\"Display the conversation history.\n",
    "    \n",
    "    Args:\n",
    "        show_function_calls (bool): Whether to show function calls and returns in the conversation history. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # ANSI escape code for blue and red text\n",
    "    BLUE = \"\\033[94m\"\n",
    "    BOLD = \"\\033[1m\"\n",
    "    GREY = \"\\033[90m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "\n",
    "    for message in self.messages:\n",
    "        if message['role'] != 'system':\n",
    "            if message['role'] == 'user':\n",
    "                print(f\"{BOLD}User:{RESET} {message['content']}\\n\")\n",
    "            elif message['role'] == 'assistant':\n",
    "                if 'content' in message and message['content']:\n",
    "                    print(f\"{BOLD}{BLUE}Assistant response:{RESET} {BLUE}{message['content']}{RESET}\\n\")\n",
    "                if 'tool_calls' in message and message['tool_calls'] and show_function_calls:\n",
    "                    print(f\"{BOLD}{BLUE}Assistant function calls:{RESET} \", end='')\n",
    "                    for tool in message['tool_calls']:\n",
    "                        print(f\"{BLUE}{tool['function']['name']}() with arguments {tool['function']['arguments']}{RESET}\\n\")\n",
    "            elif message['role'] == 'tool' and show_function_calls:\n",
    "                # convert str to list\n",
    "                if isinstance(message['content'], str):\n",
    "                    message['content'] = [message['content']]\n",
    "                for fn_return in message['content']:\n",
    "                    print(f\"{BOLD}{GREY}Function return:{RESET} {GREY}{fn_return}{RESET}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@add_to_class(Assistant)\n",
    "def clear_conversion_history(self):\n",
    "    \"\"\"Clear the conversation history.\"\"\"\n",
    "    self.messages = [{'role': \"system\", 'content': self.sys_message},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "try:\n",
    "    assistant.clear_conversion_history()\n",
    "    assert assistant.show_conversion_history() == None\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    errors.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@add_to_class(Assistant)\n",
    "def pprint_tools(self):\n",
    "    for tool in self.get_tools_schema():   \n",
    "        print(f\"\"\"* Tool name: {tool.get(\"function\", {}).get(\"name\", \"No name available.\")}\n",
    "    Description: {tool.get(\"function\", {}).get(\"description\", \"No description available.\")}\n",
    "        \"\"\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors and exceptions.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# Print all errors and exceptions, if any\n",
    "if len(errors) > 0:    \n",
    "    for (error) in errors:\n",
    "        print(error)\n",
    "else:\n",
    "    print(\"No errors and exceptions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# remember to save the notebook before running this command\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
