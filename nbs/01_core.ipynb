{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Code\n",
    "\n",
    "> This is the ‘literate’ source code for ***Scholaris***, a library to set up an advanced research assistant leveraging function calling capabilities with LLMs on your local computer. ***Scholaris*** was built to run with [Llama 3.1 8B](https://ollama.com/library/llama3.1) using the [ollama](https://ollama.com/) framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "This notebook was written using [nbdev](https://nbdev.fast.ai/) to show how the source code was created, to facilitate testing, continuous integration and documentation, all in a single context. Do not modify special comments, such as `#| default_exp`, `#| hide`, or `#| export`. These special comments serve as markdown directives and define the module name and content, and which code or markdown cells are rendered for documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "## Installation\n",
    "\n",
    "First, download and install Ollama on your computer. Go to [Download Ollama](https://ollama.com/download) and follow the instructions for your operating system. Then pull and run [llama3.1](https://ollama.com/library/llama3.1) (parameters: 8B, quantization: Q4_0, size: 4.7 GB) according to the ollama documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "## Using the Ollama API\n",
    "\n",
    "The code in this section is an application of the Ollama Python library. It is written to demonstrate the basic low-level functionality of the Ollama API, and should help the reader understand the basics underpinning the Scholaris library. Make sure to also check out the [blog post on tool support](https://ollama.com/blog/tool-support) on the official Ollama website. If you are already familiar with the Ollama API, you can skip this section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### Check if the ollama app is running and list all available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import ollama\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Alternatively, use the Ollama Python library to get the list and size of available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "try:\n",
    "    installed_models = [model for model in ollama.list()[\"models\"]]\n",
    "    for model in installed_models:\n",
    "        size = model[\"size\"] / (1024 ** 3)\n",
    "        # print(f\"{model[\"name\"]} \\t{size:.2f} GB\")\n",
    "except Exception as e:\n",
    "    print(f\"{e}. Is the ollama app running?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### Using the basic chat functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "sys_message = \"\"\"You are a helpful AI assistant. Respond with the shortest possible answers while maintaining clarity and accuracy. \n",
    "Avoid unnecessary details, explanations, or pleasantries. Be direct and to the point in all responses.\n",
    "\"\"\" # For testing purposes & CI/CD, we are looking for short responses.\n",
    "\n",
    "prompt = \"According to 'The Hitchhiker's Guide to the Galaxy' by Douglas Adams, what is the meaning of life?\"\n",
    "\n",
    "try:\n",
    "    response = ollama.chat(\n",
    "        model='llama3.1', \n",
    "        messages=[\n",
    "            {'role': \"system\", 'content': sys_message},\n",
    "            {'role': 'user',\n",
    "            'content': prompt.format(str=prompt)} # Use built-in formatting to insert the prompt\n",
    "            ],\n",
    "        stream=True, # Set to True to stream the response\n",
    "        )\n",
    "        \n",
    "    for chunk in response:\n",
    "        print(chunk['message']['content'], end='', flush=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### Demonstrate and test function calling\n",
    "\n",
    "To get started, we will go through function / tool calling step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 1. Define a function to call\n",
    "For demonstration purposes, we will define a simple addition tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def add_two_integers(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    A function to add two numbers.\n",
    "\n",
    "    Args:\n",
    "        a (int): First number.\n",
    "        b (int): Second number.\n",
    "\n",
    "    Returns:\n",
    "        int: Sum of the two numbers.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If inputs are not integers.\n",
    "    \"\"\"\n",
    "    if not isinstance(a, int) or not isinstance(b, int):\n",
    "        raise TypeError(\"Both inputs must be integers\")\n",
    "    \n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 2. Print the function name, docstring and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "print(\"Function name:\", add_two_integers.__name__, \"\\n---\")\n",
    "print(\"Docstring:\", add_two_integers.__doc__,\"\\n---\")\n",
    "print(\"Annotations:\", add_two_integers.__annotations__,\"\\n---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 3. Define the JSON schema for the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "args = {\n",
    "    \"a\": {\n",
    "        \"type\": \"integer\",\n",
    "        \"description\": \"First number\"\n",
    "    },\n",
    "    \"b\": {\n",
    "        \"type\": \"integer\",\n",
    "        \"description\": \"Second number\"\n",
    "    }\n",
    "}\n",
    "\n",
    "addition_tool_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": add_two_integers.__name__,\n",
    "        \"description\": \"Function to add two numbers\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": args,\n",
    "            \"required\": [\"a\", \"b\"],\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 4. First API call: send query and JSON schema of the function to the model\n",
    "\n",
    "We will use random numbers for the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "a = random.randint(1, 10000000)\n",
    "b = random.randint(1, 10000000)\n",
    "prompt = f\"What is the sum of {a} and {b}?\"\n",
    "print(prompt)\n",
    "\n",
    "sys_message = \"You are a an assistant provided with tools to help you answer questions.\"\n",
    "\n",
    "messages=[\n",
    "    {'role': \"system\", 'content': sys_message},\n",
    "    {'role': 'user',\n",
    "    'content': prompt.format(str=prompt)} # Use built-in formatting to insert the prompt\n",
    "]\n",
    "\n",
    "try: # Try and except block enable CI to run on GitHub without stopping the execution\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.1\",\n",
    "        messages=messages,\n",
    "        tools=[addition_tool_schema],\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 5. Get the function return value with the arguments from the LLM response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "try:\n",
    "    for tool in response['message'].get('tool_calls'):\n",
    "        print(\"tool names:\", tool['function'].get('name'))\n",
    "        print(\"args:\", tool['function'].get('arguments'))\n",
    "        # print first arg\n",
    "        a = tool['function'].get('arguments').get('a')\n",
    "        b = tool['function'].get('arguments').get('b')\n",
    "        output = f\"return: {add_two_integers(a, b)}\"\n",
    "        print(output)\n",
    "except Exception as e:\n",
    "    print(e, \"If you get an error message, try re-running the cell above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 6. Add the output to the messages list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "try:\n",
    "    messages.append(\n",
    "        {\n",
    "            'role': 'tool',\n",
    "            'content': output,\n",
    "        }\n",
    "    )\n",
    "    messages\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}. Try fixing the error by re-running the two cells above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "#### 7. Second API call: get the final reponse from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "try: # Try and except block enable CI to run on GitHub without stopping the execution\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.1\",\n",
    "        messages=messages,\n",
    "        stream=True,\n",
    "    )\n",
    "    for chunk in response:\n",
    "        print(chunk['message']['content'], end='', flush=True)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Next, we will define helper functions to siplify the steps above. Documentation continues below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "The Ollama framework supports [tool calling](https://ollama.com/blog/tool-support) (also referred to as function calling) with models such as Llama 3.1. To leverage function calling, we need to pass the JSON schema for any given function as an argument to the LLM. This is the information based on which the LLM infers the most appropriate tool to use given a prompt, and which parameters/arguments to pass to a function. To simplify the process of generating JSON schemas, use the helper and decorator functions defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import inspect\n",
    "from typing import Callable, Dict, List, Tuple, Optional, Any, Union \n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_json_schema(func: Callable) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate a JSON schema for the given function based on its annotations and docstring.\n",
    "    \n",
    "    Args:\n",
    "        func (Callable): The function to generate a schema for.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: A JSON schema for the function.\n",
    "    \"\"\"\n",
    "    annotations = func.__annotations__\n",
    "    doc = inspect.getdoc(func)\n",
    "    \n",
    "    schema = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": func.__name__,\n",
    "            \"description\": \"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if doc:\n",
    "        lines = doc.split('\\n')\n",
    "        description = []\n",
    "        arg_descriptions = {}\n",
    "        in_args_section = False\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.lower().startswith('args:'):\n",
    "                in_args_section = True\n",
    "                continue\n",
    "            elif line.lower().startswith('returns:') or line.lower().startswith('raises:'):\n",
    "                break\n",
    "            \n",
    "            if not in_args_section:\n",
    "                description.append(line)\n",
    "            else:\n",
    "                parts = line.split(':')\n",
    "                if len(parts) >= 2:\n",
    "                    # print(parts)\n",
    "                    arg_name = parts[0].split(' ')[0].strip()\n",
    "                    arg_desc = ':'.join(parts[1:]).strip()\n",
    "                    # print(arg_name, arg_desc)\n",
    "                    arg_descriptions[arg_name] = arg_desc\n",
    "                    # print(arg_descriptions)\n",
    "                    if 'optional' not in parts[0].lower():\n",
    "                        schema['function']['parameters']['required'].append(arg_name)\n",
    "\n",
    "        \n",
    "        schema['function']['description'] = ' '.join(description).strip()\n",
    "    \n",
    "    for arg, arg_type in annotations.items():\n",
    "        if arg != 'return':\n",
    "            schema['function']['parameters']['properties'][arg] = {\n",
    "                \"type\": _get_type(arg_type),\n",
    "                \"description\": arg_descriptions.get(arg, \"\")\n",
    "            }\n",
    "    \n",
    "    return schema\n",
    "\n",
    "def _get_type(arg_type):\n",
    "    if 'List' in str(arg_type):\n",
    "        return \"list\"\n",
    "    elif 'Optional' in str(arg_type):\n",
    "        return \"optional\"\n",
    "    elif arg_type == int:\n",
    "        return \"integer\"\n",
    "    elif arg_type == str:\n",
    "        return \"string\"\n",
    "    elif arg_type == float:\n",
    "        return \"number\"\n",
    "    elif arg_type == bool:\n",
    "        return \"boolean\"\n",
    "    else:\n",
    "        return \"object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import functools\n",
    "from typing import TypeVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "T = TypeVar('T', bound=Callable)\n",
    "\n",
    "def json_schema_decorator(func: T) -> T:\n",
    "    \"\"\"\n",
    "    Decorator to generate and attach a JSON schema to a function.\n",
    "    \n",
    "    Args:\n",
    "        func (Callable): The function to decorate.\n",
    "    \n",
    "    Returns:\n",
    "        Callable: The decorated function with an attached JSON schema.\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        return func(*args, **kwargs)\n",
    "    \n",
    "    schema = generate_json_schema(func)\n",
    "    wrapper.json_schema = schema  # Attach the schema dictionary directly\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "In the follwoing code block, we define a simple addition tool to test the decorator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "@json_schema_decorator\n",
    "def add_two_integers(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    A function to add two numbers.\n",
    "\n",
    "    Args:\n",
    "        a (int): First number.\n",
    "        b (int): Second number.\n",
    "\n",
    "    Returns:\n",
    "        int: Sum of the two numbers.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If inputs are not integers.\n",
    "    \"\"\"\n",
    "    if not isinstance(a, int) or not isinstance(b, int):\n",
    "        raise TypeError(\"Both inputs must be integers\")\n",
    "    \n",
    "    return a + b\n",
    "\n",
    "assert generate_json_schema(add_two_integers) == add_two_integers.json_schema\n",
    "assert generate_json_schema(add_two_integers)['function']['name'] == \"add_two_integers\"\n",
    "assert generate_json_schema(add_two_integers)['function']['description'] == \"A function to add two numbers.\"\n",
    "assert generate_json_schema(add_two_integers)['function']['parameters']['properties']['a']['description'] == \"First number.\"\n",
    "assert generate_json_schema(add_two_integers)['function']['parameters']['properties']['b']['description'] == \"Second number.\"\n",
    "assert generate_json_schema(add_two_integers)['function']['parameters']['properties']['a']['type'] == \"integer\"\n",
    "assert generate_json_schema(add_two_integers)['function']['parameters']['properties']['b']['type'] == \"integer\"\n",
    "assert generate_json_schema(add_two_integers)['function']['parameters']['required'] == ['a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "add_two_integers.json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Generate another JSON schema for a different function for testing purposes\n",
    "@json_schema_decorator\n",
    "def multiply_two_integers(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    A function to multiply two numbers.\n",
    "\n",
    "    Args:\n",
    "        a (int): First number.\n",
    "        b (int): Second number.\n",
    "\n",
    "    Returns:\n",
    "        int: Product of the two numbers.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If inputs are not integers.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(a, int) or not isinstance(b, int):\n",
    "        raise TypeError(\"Both inputs must be integers\")\n",
    "    \n",
    "    return a * b\n",
    "\n",
    "assert generate_json_schema(multiply_two_integers) == multiply_two_integers.json_schema\n",
    "assert generate_json_schema(multiply_two_integers)['function']['parameters']['properties']['a']['description'] == \"First number.\"\n",
    "assert generate_json_schema(multiply_two_integers)['function']['parameters']['properties']['b']['description'] == \"Second number.\"\n",
    "assert generate_json_schema(multiply_two_integers)['function']['parameters']['required'] == ['a', 'b']\n",
    "multiply_two_integers.json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Test decorator with an optional argument\n",
    "@json_schema_decorator\n",
    "def process_data(data: List[int], threshold: Optional[int] = None) -> List[int]:\n",
    "    \"\"\"\n",
    "    Process a list of integers based on an optional threshold.\n",
    "\n",
    "    This function filters and modifies the input list of integers.\n",
    "    If a threshold is provided, it keeps only the numbers above the threshold.\n",
    "    If no threshold is given, it returns the original list.\n",
    "\n",
    "    Args:\n",
    "        data (List[int]): A list of integers to process.\n",
    "        threshold (Optional[int], optional): The minimum value to keep. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        List[int]: A list of processed integers.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input data is empty.\n",
    "\n",
    "    Example:\n",
    "        >>> process_data([1, 5, 3, 7, 2], threshold=3)\n",
    "        [5, 7]\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        raise ValueError(\"Input data cannot be empty\")\n",
    "\n",
    "    if threshold is None:\n",
    "        return data\n",
    "    else:\n",
    "        return [num for num in data if num > threshold]\n",
    "\n",
    "assert generate_json_schema(process_data) == process_data.json_schema\n",
    "assert generate_json_schema(process_data)['function']['name'] == \"process_data\"\n",
    "assert \"Process a list of integers based\" in generate_json_schema(process_data)['function']['description']\n",
    "assert \"If no threshold is given, it returns the original list.\" in generate_json_schema(process_data)['function']['description']\n",
    "assert generate_json_schema(process_data)['function']['parameters']['properties']['data']['description'] == \"A list of integers to process.\"\n",
    "assert generate_json_schema(process_data)['function']['parameters']['properties']['threshold']['description'] == \"The minimum value to keep. Defaults to None.\"\n",
    "assert generate_json_schema(process_data)['function']['parameters']['required'] == ['data']\n",
    "process_data.json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# In this code block, we will test tool use. We provide the LLM with multiple tools and let it decide which tool to use.\n",
    "a = random.randint(1, 10000000)\n",
    "b = random.randint(1, 10000000)\n",
    "prompts = [f\"What is the sum of {a} and {b}?\", f\"What is the product of {a} and {b}?\"]\n",
    "\n",
    "\n",
    "sys_message = \"You are a an assistant provided with tools to help you answer questions.\"\n",
    "\n",
    "for prompt in prompts:\n",
    "    messages=[\n",
    "        {'role': \"system\", 'content': sys_message},\n",
    "        {'role': 'user', 'content': prompt},\n",
    "    ]\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.1\",\n",
    "            messages=messages,\n",
    "            tools=[add_two_integers.json_schema, multiply_two_integers.json_schema],\n",
    "        )\n",
    "\n",
    "        print(prompt)\n",
    "        print(response.get('message').get('tool_calls'))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "Below are the core functions the assistant can call. With these functions, the assistant will be able to get a list of file names in a specific data directory, can extract content from these files, and summarize them. In addition, the assistant can make API calls to external data sources, such as OpenAlex or Semantic Scholar, to retrieve information about a large number of scholarly articles.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local File Processing: Listing, Content Extraction, and Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Note that for the json_schema_decorator() function to work properly, the function definitions require type hints and docstrings as shown below. Intentionally, docstrings are verbose, function names are descriptive, and type hints are explicitly set. This is because the LLM will make function calling decisions based on the function name, type annotations, and information in the docstring. \n",
    "\n",
    "It's crucial to understand that this metadata (function name, type hints, and docstring) is all the information the LLM has access to when deciding which function to call and how to use it. The LLM does not have access to or information about the actual source code or implementation of the functions (unless explicitly provided). Therefore, the metadata must be comprehensive and accurate to ensure proper function selection and usage by the LLM.\n",
    "\n",
    "We start by defining a tool that retrieves a list of file names with specified extensions in a specific data directory the assistant has access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def get_file_names(ext: str = \"pdf, txt\") -> str:\n",
    "    \"\"\"Retrieves a list of file names with specified extensions in a local data directory the assistant has access to on the user's computer.\n",
    "\n",
    "    Args:\n",
    "        ext: A comma-separated string of file extensions to filter the files by. Options are: pdf, txt, md, markdown, csv, and py. Defaults to \"pdf, txt\".\n",
    "\n",
    "    Returns:\n",
    "        str: A comma-separated string of file names with the specified extensions. If no files are found, a message is returned.\n",
    "\n",
    "    Example:\n",
    "        >>> get_file_names(ext=\"pdf, txt\")\n",
    "        \"List of file names with the specified extensions in the local data directory: file1.pdf, file2.txt\"\n",
    "    \"\"\"\n",
    "\n",
    "    if 'DIR_PATH' not in globals():\n",
    "        return \"Error: The local data directory path is not defined.\"\n",
    "    \n",
    "    if not os.path.exists(DIR_PATH):\n",
    "        return f\"Error: The local data directory does not exist.\"\n",
    "\n",
    "    valid_extensions = [\"pdf\", \"txt\", \"md\", \"markdown\", \"csv\", \"py\"]\n",
    "\n",
    "    # Process the input extensions\n",
    "    selected_extensions = []\n",
    "    for e in ext.split(','):\n",
    "        e = e.lower().strip().lstrip('.').strip('{').strip('}').strip('[').strip(']').strip('(').strip(')').strip('\"').strip(\"'\") # Clean up the extension string\n",
    "        if e not in valid_extensions:\n",
    "            return f\"Error: Invalid file extension '{e}'. Please choose from: pdf, txt, md, markdown, csv, py.\" # Instead of raising an error, we return a message to the LLM to avoid stopping a conversation\n",
    "        selected_extensions.append(e)\n",
    "\n",
    "    # List all files with the specified extensions\n",
    "    file_names = [file for file in os.listdir(DIR_PATH) if any(file.endswith(f\".{e}\") for e in selected_extensions)]\n",
    "    # print(file_names) # Uncomment for debugging\n",
    "\n",
    "    if len(file_names) == 0:\n",
    "         return \"Access of local data directory successful but no files found with the specified extensions.\"\n",
    "\n",
    "    file_names_json = ', '.join(file_names)\n",
    "\n",
    "    # Convert list to a comma-separated string. This is because the object is returned to the LLM and the API accepts str only\n",
    "    return f\"List of file names with the specified extensions in the local data directory: {file_names_json}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "assert type(get_file_names.json_schema) == dict\n",
    "assert get_file_names.json_schema['function']['name'] == \"get_file_names\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "To test this and other functions defined below with an actual file, download a sample article from the internet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "!mkdir -p ../data\n",
    "pdf_urls = [\n",
    "    \"https://df6sxcketz7bb.cloudfront.net/manuscripts/144000/144499/jci.insight.144499.v2.pdf\",\n",
    "]\n",
    "for url in pdf_urls:\n",
    "    !curl -o ../data/$(basename {url}) {url}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Below are several test cases for the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import copy\n",
    "import tempfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "global DIR_PATH\n",
    "DIR_PATH = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Test case for get_file_names function\n",
    "if \"DIR_PATH\" in globals():\n",
    "    original_DIR_PATH = copy.deepcopy(DIR_PATH)\n",
    "    del globals()[\"DIR_PATH\"] # Remove the global variable for testing purposes\n",
    "with tempfile.TemporaryDirectory() as temp_dir: \n",
    "    assert get_file_names() == \"Error: The local data directory path is not defined.\", \"Test failed: get_file_names() should return an error message if DIR_PATH is not defined.\"\n",
    "    global DIR_PATH\n",
    "    DIR_PATH = temp_dir\n",
    "    assert get_file_names() == \"Access of local data directory successful but no files found with the specified extensions.\", \"Test failed: get_file_names() should return a message if no files are found in the directory.\"\n",
    "    test_files = [\"test_file1.txt\", \"test_file2.py\"] # Create some test files\n",
    "    for file in test_files:\n",
    "        with open(os.path.join(DIR_PATH, file), 'w') as f:\n",
    "            f.write(\"Test content\")\n",
    "    assert \"test_file1.txt\" in get_file_names(ext=\"txt\"), \"Test failed: get_file_names() should return a string with the test file name.\"\n",
    "    assert \"test_file2.py\" not in get_file_names(ext=\"txt\"), \"Test failed: get_file_names() should not return a file name with a different extension.\"\n",
    "    assert \"test_file2.py\" in get_file_names(ext=\"txt, py\"), \"Test failed: get_file_names() should return a string with the python test file name.\"\n",
    "    print(\"All tests passed successfully!\")\n",
    "\n",
    "global DIR_PATH\n",
    "DIR_PATH = original_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Test function calling with the LLM using the get_file_names tool, if no files are found\n",
    "# Store the original DIR_PATH\n",
    "if \"DIR_PATH\" in globals():\n",
    "    original_DIR_PATH = copy.deepcopy(DIR_PATH)\n",
    "\n",
    "# Create a temporary, empty directory \n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    # Set DIR_PATH to the temporary directory\n",
    "    global DIR_PATH\n",
    "    DIR_PATH = temp_dir\n",
    "\n",
    "    prompt = f\"Can you provide me with a list of PDF files you have access to on the local computer?\"\n",
    "\n",
    "    sys_message = \"\"\"You are a helpful AI assistant. Respond with the shortest possible answers while maintaining clarity and accuracy. \n",
    "    Avoid unnecessary details, explanations, or pleasantries. Be direct and to the point in all responses.\n",
    "\n",
    "    Key instructions:\n",
    "    1. Use the provided tool to gather information before answering.\n",
    "    2. Interpret tool results and provide clear, concise answers in natural language.\n",
    "    3. If you can't answer with available tools, state this clearly.\n",
    "    4. Don't provide information if tool content is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    messages=[\n",
    "        {'role': \"system\", 'content': sys_message},\n",
    "        {'role': 'user', 'content': prompt},\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Make a request to the LLM to select a tool\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.1\",\n",
    "            messages=messages,\n",
    "            tools=[get_file_names.json_schema],\n",
    "        )\n",
    "    \n",
    "        if response.get('message').get('tool_calls'):\n",
    "            for tool in response['message']['tool_calls']:\n",
    "                function_to_call = tool['function']['name']\n",
    "                print(f\"Calling {function_to_call}()...\\n\")\n",
    "\n",
    "        # Call the function\n",
    "        for tool in response['message'].get('tool_calls'):\n",
    "            output = f\"return: {get_file_names()}\"\n",
    "            messages.append(\n",
    "                {\n",
    "                    'role': 'tool',\n",
    "                    'content': output,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Make a second request to the LLM with the tool output to generate a final response\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.1\",\n",
    "            messages=messages,\n",
    "            stream=False,\n",
    "        )\n",
    "\n",
    "        print(response['message']['content'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Reset DIR_PATH to its original value\n",
    "if \"DIR_PATH\" in globals():\n",
    "    DIR_PATH = original_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Test function calling; create a test file and check if it is included in the response\n",
    "unique_suffix = uuid.uuid4().hex[:8]  # Use first 8 characters of a UUID\n",
    "test_file_name = f\"test_{unique_suffix}.pdf\"\n",
    "test_file_path = os.path.join(DIR_PATH, test_file_name)\n",
    "\n",
    "print(f\"Creating test file: {test_file_name}\\n\")\n",
    "open(test_file_path, 'a').close()  # Create an empty file\n",
    "\n",
    "prompt = f\"Can you provide me with a list of PDF files you have access to?\"\n",
    "\n",
    "sys_message = \"\"\"You are a helpful AI assistant. Respond with the shortest possible answers while maintaining clarity and accuracy. \n",
    "Avoid unnecessary details, explanations, or pleasantries. Be direct and to the point in all responses.\n",
    "\n",
    "Key instructions:\n",
    "1. Use the provided tool to gather information before answering.\n",
    "2. Interpret tool results and provide clear, concise answers in natural language.\n",
    "3. If you can't answer with available tools, state this clearly.\n",
    "4. Don't provide information if tool content is empty.\n",
    "\"\"\"\n",
    "\n",
    "messages=[\n",
    "    {'role': \"system\", 'content': sys_message},\n",
    "    {'role': 'user', 'content': prompt},\n",
    "]\n",
    "\n",
    "try: # We use a try-except block to ensure the code runs without stopping the execution; the ollama API will not be available for GitHub Actions\n",
    "    # Make a request to the LLM to select a tool\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.1\",\n",
    "        messages=messages,\n",
    "        tools=[get_file_names.json_schema],\n",
    "    )\n",
    "\n",
    "    if response.get('message').get('tool_calls'):\n",
    "        for tool in response['message']['tool_calls']:\n",
    "            function_to_call = tool['function']['name']\n",
    "            print(f\"Calling {function_to_call}()...\\n\")\n",
    "\n",
    "    # Call the function\n",
    "    for tool in response['message'].get('tool_calls'):\n",
    "        output = f\"return: {get_file_names()}\"\n",
    "        # print(output)\n",
    "        messages.append(\n",
    "            {\n",
    "                'role': 'tool',\n",
    "                'content': output,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Make a second request to the LLM with the tool output to generate a final response\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.1\",\n",
    "        messages=messages,\n",
    "        stream=False,\n",
    "    )\n",
    "    print(f\"LLM response:\\n{response['message']['content']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(f\"\\n\\nRemoving test file...\")\n",
    "os.remove(test_file_path)\n",
    "print(\"Test completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "The next two functions are executed when calling the tool `get_titles_and_first_authors()`, which is defined below, to extract the title and first author from PDF files in the local data directory. The first function, `extract_text_from_pdf()`, extracts text from a PDF file using the **PyPDF2** library. The second function, `extract_title_and_first_author()`, will then use the LLM to extract the title and first author from the text extracted from the PDF file.\n",
    "\n",
    "In addition, the `extract_text_from_pdf()` function can also be called directly by the assistant to extract user-specified pages or sections from a PDF file, to respond to user queries or to extract specific information from a PDF file specified by the user.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def extract_text_from_pdf(file_name: str, page_range: Optional[str] = None) -> str:\n",
    "    \"\"\"A function that extracts text from a PDF file.\n",
    "    Use this tool to extract specific details from a PDF document, such as abstract, authors, conclusions, or user-specified content of other sections.\n",
    "    If the user specifies a page rage, use the optional page_range parameter to extract text from specific pages.\n",
    "    If the user uses words such as beginning, middle, or end, to descripe the section, infer the page range based on the total number of 15 pages in a document.\n",
    "    Do not use this tool to summarize an entire PDF document. Only use this tool for documents with extensions .pdf, or .PDF.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): The file name of the PDF document in the local data directory.\n",
    "        page_range (Optional[str]): A string with page numbers and/or page ranges separated by commas (e.g., \"1\" or \"1, 2\", or \"5-7\"). Default is None to extract all pages.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted text from the PDF.\n",
    "\n",
    "    Example:\n",
    "    >>> text = extract_text_from_pdf(\"./test.pdf\", page_range=\"1\")\n",
    "    \"\"\"\n",
    "    verbose = False  # Set to True for debugging\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(DIR_PATH):\n",
    "        return \"Local data directory not found.\"\n",
    "    \n",
    "    # Construct the full file path; this will be handled by a try-except block because this function is alos used as a tool\n",
    "    try:\n",
    "        pdf_path = os.path.join(DIR_PATH, file_name)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "    \n",
    "    # Validate input\n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(f\"File not found: {pdf_path}\")\n",
    "    assert pdf_path.endswith('.pdf'), \"The file must be a PDF.\"\n",
    "    assert isinstance(page_range, (str, type(None))), \"The page_range must be a string or None.\"\n",
    "\n",
    "    if page_range:\n",
    "        # Clean up page range input in case of LLM formatting errors; must be a string, e.g., \"1\" or \"1, 2\", or \"5-7\", with no quotes or brackets   \n",
    "        page_range = page_range.strip().replace('\"', '').replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "\n",
    "        # Parse the page range string\n",
    "        page_numbers = []\n",
    "        for part in page_range.split(','):\n",
    "            if '-' in part:\n",
    "                a, b = part.split('-')\n",
    "                page_numbers.extend(range(int(a), int(b) + 1))\n",
    "            else:\n",
    "                page_numbers.append(int(part))\n",
    "        if verbose:\n",
    "            print(f\"Extracting text from pages: {page_numbers}\")\n",
    "\n",
    "    # Validate page numbers\n",
    "    if page_range:\n",
    "        start_page, end_page = min(page_numbers), max(page_numbers)\n",
    "        if start_page < 1 or end_page < start_page:\n",
    "            raise ValueError(\"Invalid page range. Please provide a valid range of pages to extract text from.\")\n",
    "\n",
    "    # Extract text from the PDF\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf = PyPDF2.PdfReader(file)\n",
    "            \n",
    "            # Check for invalid page numbers\n",
    "            if page_range:\n",
    "                max_page = len(pdf.pages)\n",
    "                invalid_pages = [p for p in page_numbers if p < 1 or p > max_page]\n",
    "                if invalid_pages:\n",
    "                    page_range = None # Reset page range to extract all pages\n",
    "            \n",
    "            if page_range:\n",
    "                for page_num in page_numbers:\n",
    "                    if verbose:\n",
    "                        print(f\"Extracting text from page {page_num}...\")\n",
    "                    page = pdf.pages[page_num - 1]  # Adjust for 0-based index\n",
    "                    text += f\"page {page_num} of {len(pdf.pages)}\\n{page.extract_text()}\"\n",
    "            else:\n",
    "                for page_num, page in enumerate(pdf.pages):\n",
    "                    if verbose:\n",
    "                        print(f\"Extracting text from page {page_num + 1}...\")\n",
    "                    text += f\"page {page_num} of {len(pdf.pages)}\\n{page.extract_text()}\"\n",
    "            \n",
    "            if verbose:\n",
    "                word_count = len(text.split())\n",
    "                total_pages = len(page_numbers) if page_range else len(pdf.pages)\n",
    "                print(f\"Text extraction completed.\\nTotal pages extracted: {total_pages}\\nWord count: {word_count}\\nNo. of characters (with spaces): {len(text)}\")\n",
    "    except PyPDF2.errors.PdfReadError as e:\n",
    "        return f\"Error reading PDF: {e}\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Testing the function with a sample PDF file\n",
    "# For this test to work, a file \"test.pdf\" must be present in the data directory\n",
    "# Copy or create your own test.pdf file in the data directory to run this test\n",
    "try: \n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"1\")\n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"1, 2\")\n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"1-3\") # Should handle page ranges with hyphens\n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\" 1-3 \") # Should handle extra spaces\n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"1, 3\") \n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"1-3, 5\") # Should handle multiple ranges\n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"1-1000\") # Invalid page range will return all pages\n",
    "    extract_text_from_pdf(\"../data/jci.insight.144499.v2.pdf\", page_range=\"[1]\") # Should handle invalid formatting; brackets will be removed\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Note: The following function will be defined but not be callable directly by the LLM. \n",
    "Hence, we will not generate a JSON schema for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_title_and_first_author(contents: List[Dict[str, str]], model: str='llama3.1', verbose: Optional[bool] = False, show_progress: Optional[bool] = False) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    A function that extracts the titles and the first author's names from the text of one or more research articles.\n",
    "\n",
    "    Args:\n",
    "        contents (List[Dict[str, str]]): A list of dictionaries containing the file name and extracted text.\n",
    "        model (str): The model to use for the extraction. Default is 'llama3.1'.\n",
    "        verbose (Optional[bool]): Whether to print additional information. Default is False.\n",
    "        show_progress (Optional[bool]): Whether to show a progress bar. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        contents (List[Dict[str, str]]): The input list of dictionaries with the extracted title and first author added.\n",
    "\n",
    "    Raises:\n",
    "        JSONDecodeError: If the JSON response is invalid.\n",
    "\n",
    "    Example:\n",
    "    >>> contents = extract_title_and_first_author(contents)\n",
    "    Extracting titles and first authors: 100%|██████████| 3/3 [00:22<00:00,  7.35s/it]\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    The text below between the <text> XML like tags is extracted from the first page of a research article. \n",
    "    Your task is to identify the title of the research article and the first author's name.\n",
    "    The title is typically located immediately before the authors' names and the abstract.\n",
    "\n",
    "    <text>\n",
    "    {text}\n",
    "    </text>\n",
    "\n",
    "    The output must be provided in JSON format shown in the following example.\n",
    "\n",
    "    Example output:\n",
    "    {{\n",
    "        \"title\": \"<title>\",\n",
    "        \"first_author\": \"<first_author>\"\n",
    "    }}\n",
    "    Write the JSON output and nothing more. Do not include degree titles or affiliations in the author's name.\n",
    "\n",
    "    Here is the JSON output:\n",
    "    \"\"\"\n",
    "\n",
    "    pdf_iterator = tqdm(contents, desc=\"Extracting titles and first authors\") if show_progress else contents\n",
    "    \n",
    "    for pdf_item in pdf_iterator:\n",
    "        text = pdf_item['extracted_text']\n",
    "        if verbose:\n",
    "            tqdm.write(pdf_item['file_path'])\n",
    "            tqdm.write(\"---\")\n",
    "            tqdm.write(text[:500])\n",
    "            tqdm.write(\"---\")\n",
    "\n",
    "        try:\n",
    "            response = ollama.chat(model=model, messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': prompt.format(text=text),\n",
    "                },\n",
    "            ])\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Error: {e}\")\n",
    "            if \"Connection refused\" in str(e):\n",
    "                tqdm.write(\"Make sure Ollama is running and the correct model is available.\")\n",
    "            continue\n",
    "\n",
    "        if verbose:\n",
    "            tqdm.write(response['message']['content'])\n",
    "\n",
    "        try:\n",
    "            extracted_info = json.loads(response['message']['content'])\n",
    "        except json.JSONDecodeError:\n",
    "            tqdm.write(f\"Error: Invalid JSON response for {pdf_item['file_path']}\")\n",
    "            extracted_info = {\"title\": \"\", \"first_author\": \"\"}\n",
    "\n",
    "        pdf_item.update(extracted_info)\n",
    "\n",
    "    print(\"\\n\") if show_progress else None # Add a newline if showing progress bar\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "contents = [{\n",
    "    \"file_name\": \"de_medicina.pdf\",\n",
    "    \"extracted_text\": \"Titulus: De Medicina\\n\\nAuctor: Aulus Cornelius Celsus\\n\\nLiber I\\n\\nUt alimenta sanis corporibus agricultura, sic sanitatem aegris Medicina promittit. Haec nusquam quidem non est; siquidem etiam imperitissimae gentes herbas aliaque prompta in auxilium vulnerum morborumque noverunt. Verumtamen apud Graecos aliquanto magis quam in ceteris nationibus exculta est, ac ne apud hos quidem a prima origine, sed paucis ante nos saeculis; utpote cum vetustissimus auctor Aesculapius celebretur. Qui quoniam adhuc rudem et vulgarem hanc scientiam paulo subtilius excoluit, in deorum numerum receptus est.\"\n",
    "}]\n",
    "assert extract_title_and_first_author(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Run the following cells to test the `extract_text_from_pdf()` & `extract_title_and_first_author()` functions separately on actual PDF files. Remember, both of these functions are executed when the LLM calls the `get_titles_and_first_authors()` function. These tests will be executed from the module as they require PDF files to be present in the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# First, get the file paths from the local data directory\n",
    "# Make sure to have some PDF files in the data directory for this test\n",
    "DIR_PATH = \"../data/\"\n",
    "file_names = [file for file in os.listdir(DIR_PATH) if file.endswith('.pdf')]\n",
    "file_paths = [os.path.join(DIR_PATH, file) for file in file_names]\n",
    "print(\"File paths:\", file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Next, extract the text from the first page of each PDF file\n",
    "pdf_contents = []\n",
    "for file_path in file_paths:\n",
    "    pdf_contents.append({\n",
    "        \"file_name\": file_path.split(\"/\")[-1],\n",
    "        \"extracted_text\": extract_text_from_pdf(file_path, page_range=\"1\")\n",
    "        })\n",
    "pdf_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Now, we iterate through the contents and run the `extract_title_and_first_author()` function to extract the title and first author from the text extracted from the PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if len(pdf_contents) > 0:\n",
    "    response = extract_title_and_first_author(pdf_contents, show_progress=True)\n",
    "    for article in response:\n",
    "        print(f\"{article.get('file_name')}: '{article.get('title')}'\")\n",
    "else: \n",
    "    print(\"Add PDF files to the data directory to test the functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function combines the two functions `extract_text_from_pdf()` and `extract_title_and_first_author()` to extract the title and first author from PDF files in the local data directory. This function will be callable by the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def get_titles_and_first_authors() -> str:\n",
    "    \"\"\"\n",
    "    A function that retrieves the titles of research articles from a directory of PDF files.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON-formatted string containing the titles, first authors and file names of the research articles.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified directory does not exist.\n",
    "\n",
    "    Example:\n",
    "    >>> get_titles_and_first_authors()\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(DIR_PATH):\n",
    "        return \"Local data directory not found.\"\n",
    "\n",
    "    # Initialize an empty list to store the file names and extracted text\n",
    "    pdf_contents = []\n",
    "\n",
    "    # Initialize an empty list of dictionaries to store file names, extracted titles and first authors\n",
    "    titles_and_authors = []\n",
    "\n",
    "    # Get the file paths of all PDF files in the local data directory\n",
    "    file_paths = [os.path.join(DIR_PATH, file) for file in os.listdir(DIR_PATH) if file.endswith('.pdf')]\n",
    "\n",
    "    # Extract text from the first page of each PDF file\n",
    "    for file_path in file_paths:\n",
    "        pdf_contents.append({\n",
    "            \"file_name\": file_path.split(\"/\")[-1],\n",
    "            \"extracted_text\": extract_text_from_pdf(file_path, page_range=\"1\")\n",
    "            })\n",
    "\n",
    "    # Extract titles and first authors from the extracted text of each PDF file\n",
    "    response = extract_title_and_first_author(pdf_contents, show_progress=True)\n",
    "    for article in response:\n",
    "        titles_and_authors.append({\n",
    "            \"title\": article.get('title'), \n",
    "            \"first_author\": article.get('first_author'),\n",
    "            \"file_name\": article.get('file_name'),\n",
    "            })\n",
    "    \n",
    "    if not titles_and_authors:\n",
    "        return \"No titles found.\"\n",
    "        \n",
    "    return json.dumps(titles_and_authors, indent=2) # Return as a JSON-formatted string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_titles_and_first_authors.json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "assert type(get_titles_and_first_authors.json_schema) == dict\n",
    "assert get_titles_and_first_authors.json_schema['function']['name'] == \"get_titles_and_first_authors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "print(get_titles_and_first_authors())\n",
    "print(type(get_titles_and_first_authors()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def summarize_local_document(file_name: str, ext: str = \"pdf\") -> str:\n",
    "    \"\"\"Summarize the content of a single PDF, markdown, or text document from the local data directory.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): The file name of the local document to summarize.\n",
    "        ext (str): The extension of the local document. Options are: pdf, txt, md, and markdown. Defaults to \"pdf\".\n",
    "\n",
    "    Returns:\n",
    "        str: The summary of the content of the local document.\n",
    "\n",
    "    Example:\n",
    "        >>> summarize_local_document(\"research_paper\", ext=\"pdf\")\n",
    "    \"\"\"\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(DIR_PATH):\n",
    "        return \"Local data directory not found.\"\n",
    "\n",
    "    # Ensure the extension is valid: delete spaces, hyphens, and quotation marks, and convert to lowercase in case of LLM input errors\n",
    "    ext = ext.lower().replace('\"', '').replace(\"'\", \"\").replace(\" \", \"\").replace(\".\", \"\")\n",
    "    if ext not in [\"pdf\", \"txt\", \"md\", \"markdown\"]:\n",
    "        return f\"Invalid file extension '{ext}'. Please choose from: pdf, txt, md, markdown.\"\n",
    "\n",
    "    # Get the file paths of all files in the local data directory\n",
    "    file_paths = [os.path.join(DIR_PATH, file) for file in os.listdir(DIR_PATH) if file.endswith(ext)]\n",
    "    # print(file_paths) # Uncomment for debugging\n",
    "    \n",
    "    # Find the file path that matches the specified file name\n",
    "    file_path = [path for path in file_paths if file_name in path]\n",
    "    # print(file_path) # Uncomment for debugging\n",
    "\n",
    "    if not file_path:\n",
    "        return f\"No file found with the name '{file_name}' and extension '{ext}'.\"\n",
    "    elif len(file_path) > 1:\n",
    "        return f\"Multiple files found with the name '{file_name}' and extension '{ext}'. Please specify a unique file name.\"\n",
    "    else:\n",
    "        file_path = file_path[0] # Convert the file path list to a string\n",
    "\n",
    "    if ext == \"pdf\":\n",
    "        # Extract text from a PDF file\n",
    "        try:\n",
    "            full_text = extract_text_from_pdf(file_path, page_range=None)\n",
    "        except Exception as e:\n",
    "            return f\"Error while extracting text from PDF file {file_name}: {e}\"\n",
    "    \n",
    "    if ext in [\"txt\", \"md\", \"markdown\"]:\n",
    "        # Read the full text content from a text file\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                full_text = file.read()\n",
    "        except Exception as e:\n",
    "            return f\"Error while reading the file {file_name}: {e}\"\n",
    "    # print(full_text[:500]) # Uncomment for debugging\n",
    "\n",
    "    # Remove references section from the full text content, if present\n",
    "    patterns = [\"References\", \"REFERENCES\", \"references\", \"Bibliography\", \"BIBLIOGRAPHY\", \"bibliography\"]\n",
    "    for pattern in patterns:\n",
    "        if pattern in full_text:\n",
    "            full_text = full_text.split(pattern)[0]\n",
    "            break\n",
    "\n",
    "    # Summarize the full text content of the document\n",
    "    prompt = f\"\"\"\n",
    "    The text below is the full text content from single document with the file name '{file_name}'.\n",
    "\n",
    "    <text>\n",
    "    {full_text}\n",
    "    </text>\n",
    "\n",
    "    If the document has an abstract, use the abstract for the summary. The abstract is typically located at the beginning of the document (page 1) and provides a concise summary of the research.\n",
    "    If there is no abstract, generate a concise summary (approx. 200 words) that captures the main points of the document, including key findings and conclusions.\n",
    "    Remember that your task is to summarize the content of the main text accurately and concisely, ignoring acknowledgements and references that are typically listed at the end of the document, after the conclusion section.\n",
    "    Start the summary with the title of the document, typically found on the first page before the author names.\n",
    "    \"\"\"\n",
    "\n",
    "    sys_message = \"\"\"You are a scientific summarization assistant for health and life sciences research. \n",
    "    Your task is to condense the contents of a complex research document with mutiple pages into a concise, accurate summary.\n",
    "    If the document describes a research study, highlight the main findings, methodologies, and conclusions of the study.\n",
    "    Start the summary with the title of the document found on the first page, followed by a brief summary of the content.\n",
    "    Ignore references typically listed at the end of a document after the conclusion section, as well as acknowledgements, and other non-content sections.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the model from the global variables\n",
    "    if 'MODEL' in globals():\n",
    "        model = MODEL\n",
    "    else:\n",
    "        model = \"llama3.1\" # Default model\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {'role': \"system\", 'content': sys_message},\n",
    "                {'role': 'user', 'content': prompt},\n",
    "            ]\n",
    "        )\n",
    "        # TODO: Try out different optional parameters for the ollama.chat function, such as temperature, max_tokens, etc. to improve the quality of the summary\n",
    "        # For details, see the Ollama API documentation:\n",
    "        # https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "        # https://github.com/ollama/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\n",
    "\n",
    "        summary = response['message']['content']\n",
    "        return summary\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error while summarizing the content of the document '{file_name}': {e}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_local_document.json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "assert type(summarize_local_document.json_schema) == dict\n",
    "assert summarize_local_document.json_schema['function']['name'] == \"summarize_local_document\"\n",
    "assert 'file_name' in summarize_local_document.json_schema['function']['parameters']['properties'].keys()\n",
    "assert 'ext' in summarize_local_document.json_schema['function']['parameters']['properties'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "!wget -O ../data/modelfile.md https://raw.githubusercontent.com/ollama/ollama/main/docs/modelfile.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "DIR_PATH = \"../data\" # for testing purposes; will be defined when the Assistant class is initialized\n",
    "print(summarize_local_document(\"modelfile.md\", ext=\"md\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "print(summarize_local_document(\"jci.insight.144499.v2.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def describe_python_code(file_name: str) -> str:\n",
    "    \"\"\"Describe the purpose of the Python code in a local Python file.\n",
    "    This may involve summarizing the entire code, extracting key functions, or providing an overview of the code structure.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): The file name of the local Python code file document to describe.\n",
    "\n",
    "    Returns:\n",
    "        str: A description of the purpose of the Python code in the local file.\n",
    "\n",
    "    Example:\n",
    "        >>> describe_python_code(\"main.py\", ext=\"py\")\n",
    "    \"\"\"\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(DIR_PATH):\n",
    "        return \"Local data directory not found.\"\n",
    "\n",
    "    # Get the file paths of all files in the local data directory\n",
    "    file_paths = [os.path.join(DIR_PATH, file) for file in os.listdir(DIR_PATH) if file.endswith(\".py\")]\n",
    "    # print(file_paths) # Uncomment for debugging\n",
    "    \n",
    "    # Find the file path that matches the specified file name\n",
    "    file_path = [path for path in file_paths if file_name in path]\n",
    "    # print(file_path) # Uncomment for debugging\n",
    "\n",
    "    if not file_path:\n",
    "        return f\"No file found with the name '{file_name}' and extension '.py'.\"\n",
    "    elif len(file_path) > 1:\n",
    "        return f\"Multiple files found with the name '{file_name}' and extension '.py'. Please specify a unique file name.\"\n",
    "    else:\n",
    "        file_path = file_path[0] # Convert the file path list to a string\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            full_text = file.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error while reading the file {file_name}: {e}\"\n",
    "    # print(full_text[:500]) # Uncomment for debugging\n",
    "\n",
    "    # Summarize the full text content of the document\n",
    "    prompt = f\"\"\"\n",
    "    The text below is the full Python code content from the file '{file_name}'.\n",
    "\n",
    "    <code>\n",
    "    {full_text}\n",
    "    </code>\n",
    "\n",
    "    Your task is to describe the purpose of the Python code in the file. This may involve summarizing the entire code, extracting key functions, or providing an overview of the code structure.\n",
    "    \"\"\"\n",
    "\n",
    "    sys_message = \"\"\"You are a programming assistant for Python code. Your task is to describe the purpose of Python code in a local file for the user who may not be familiar with the code,\n",
    "    and may not know how to interpret the code. If not ask for specific content, provide a high-level overview of the code's functionality, key functions, and structure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the model from the global variables\n",
    "    if 'MODEL' in globals():\n",
    "        model = MODEL\n",
    "    else:\n",
    "        model = \"llama3.1\" # Default model\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {'role': \"system\", 'content': sys_message},\n",
    "                {'role': 'user', 'content': prompt},\n",
    "            ]\n",
    "        )\n",
    "        # TODO: Try out different optional parameters for the ollama.chat function, such as temperature, max_tokens, etc. to improve the quality of the summary\n",
    "        # For details, see the Ollama API documentation:\n",
    "        # https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "        # https://github.com/ollama/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\n",
    "\n",
    "        summary = response['message']['content']\n",
    "        return summary\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error while describing the Python code in the file '{file_name}': {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_python_code.json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "assert type(describe_python_code.json_schema) == dict\n",
    "assert describe_python_code.json_schema['function']['name'] == \"describe_python_code\"\n",
    "assert 'file_name' in describe_python_code.json_schema['function']['parameters']['properties'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "!cp ../scholaris/core.py ../data/core.py\n",
    "print(describe_python_code(\"core.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "!rm ../data/modelfile.md\n",
    "!rm ../data/core.py\n",
    "!rm ../data/.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Data Retrieval: API Calls to OpenAlex and Semantic Scholar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "The following functions are used to convert article IDs between different formats and detect the type of an article ID based on its format.\n",
    "1. `convert_id`: Converts article IDs between PubMed Central, PubMed, DOI, and manuscript ID formats using the NCBI ID Converter API.\n",
    "2. `detect_id_type`: Analyzes a given string to determine if it's a PMID, PMCID, DOI, OpenAlex ID, Semantic Scholar ID, potential article title, or an unknown format.\n",
    "3. `id_converter_tool`: Combines the functionality of the above two functions to process a list of IDs, detecting their types and converting them using the NCBI API. This is callable by the LLM assistant.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_id(ids: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    For any article(s) in PubMed Central, find all the corresponding PubMed IDs (PMIDs), digital object identifiers (DOIs), and manuscript IDs (MIDs).\n",
    "    \n",
    "    Args:\n",
    "    ids (List[str]): A list of IDs to convert (max 200 per request).\n",
    "    \n",
    "    Returns:\n",
    "    Str: A JSON-formatted string containing the conversion results.\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'EMAIL' in globals():\n",
    "        email = EMAIL\n",
    "    else:\n",
    "        try:\n",
    "            email = os.environ['EMAIL']\n",
    "        except KeyError:\n",
    "            return {\"error\": \"Please provide an email address\"}\n",
    "\n",
    "    # API endpoint\n",
    "    base_url = \"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/\"\n",
    "    \n",
    "    # Prepare the IDs string\n",
    "    ids_string = \",\".join(ids)\n",
    "    \n",
    "    # Prepare the parameters\n",
    "    params = {\n",
    "        \"tool\": \"scholaris\",\n",
    "        \"email\": email,\n",
    "        \"ids\": ids_string,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Make the API request\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        \n",
    "        return response.json()\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def detect_id_type(id_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Detect the type of the given ID or title.\n",
    "    \n",
    "    Args:\n",
    "    id_string (str): The ID or title to detect.\n",
    "    \n",
    "    Returns:\n",
    "    str: The detected type ('pmid', 'pmcid', 'doi', 'openalex', 'semantic_scholar', 'potential_title', or 'unknown').\n",
    "    \"\"\"\n",
    "    if re.match(r'^\\d{1,8}$', id_string):\n",
    "        return 'pmid'\n",
    "    elif re.match(r'^PMC\\d+$', id_string):\n",
    "        return 'pmcid'\n",
    "    elif re.match(r'^10\\.\\d{4,9}/[-._;()/:A-Z0-9]+$', id_string, re.I): # Detect DOIs, case-insensitive\n",
    "        return 'doi'\n",
    "    elif re.match(r'^[WAIC]\\d{2,}$', id_string):\n",
    "        return 'openalex'\n",
    "    elif re.match(r'^[0-9a-f]{40}$', id_string): \n",
    "        return 'semantic_scholar'\n",
    "    elif re.match(r'^[A-Z][\\w\\s:,\\-()]{10,150}[.?!]?$', id_string, re.I): # A simple heuristic for detecting titles\n",
    "        return 'potential_title'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "\n",
    "@json_schema_decorator\n",
    "def id_converter_tool(ids: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    For any article(s) in PubMed Central, find all the corresponding PubMed IDs (PMIDs), digital object identifiers (DOIs), and manuscript IDs (MIDs).\n",
    "    Use this tool to convert a list of IDs, such as PMIDs, PMCIDs, or DOIs, and find the corresponding IDs for the same articles.\n",
    "    \n",
    "    Args:\n",
    "    ids (str): A string with a comma-separated list of IDs to convert. Must be PMIDs, PMCIDs, or DOIs. The maximum number of IDs per request is 200.\n",
    "    \n",
    "    Returns:\n",
    "    str: A JSON-formatted string containing the conversion results and the detected ID types.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(ids, str):\n",
    "        ids = ids.replace(\"https://doi.org/\", \"\").replace(\"doi.org/\", \"\") # Remove DOI URL prefixes, if present\n",
    "    \n",
    "    # Convert the input string to a list of IDs\n",
    "    try:\n",
    "        ids = ids.split(\",\")\n",
    "    except AttributeError:\n",
    "        return json.dumps({\"error\": \"Input must be a string of comma-separated IDs\"})\n",
    "\n",
    "    if len(ids) > 200:\n",
    "        return json.dumps({\"error\": \"Input IDs must be no more than 200\"})\n",
    "    \n",
    "    # Detect ID types\n",
    "    id_types = [detect_id_type(id_string) for id_string in ids]\n",
    "    \n",
    "    # Convert IDs\n",
    "    conversion_result = convert_id(ids)\n",
    "    \n",
    "    # Check if conversion_result is already a dictionary (error case)\n",
    "    if isinstance(conversion_result, dict):\n",
    "        parsed_result = conversion_result\n",
    "    else:\n",
    "        # Parse the JSON string result\n",
    "        try:\n",
    "            parsed_result = json.loads(conversion_result)\n",
    "        except json.JSONDecodeError:\n",
    "            return json.dumps({\"error\": \"Failed to parse conversion result\"})\n",
    "    \n",
    "    # Prepare the result\n",
    "    result = {\n",
    "        \"conversion_result\": parsed_result,\n",
    "        \"detected_id_types\": dict(zip(ids, id_types))\n",
    "    }\n",
    "    \n",
    "    return json.dumps(result, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the JSON-schema for id_converter_tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_converter_tool.json_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test cases for id_converter_tool, detect_id_types and convert_id functions are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the id_converter_tool function with a list of mock IDs\n",
    "test_cases = [\n",
    "    (\"12345678\", \"pmid\"),\n",
    "    (\"PMC1234567\", \"pmcid\"),\n",
    "    (\"10.1234/abcd.efg\", \"doi\"),\n",
    "    (\"W1234567\", \"openalex\"),\n",
    "    (\"1234567890abcdef1234567890abcdef12345678\", \"semantic_scholar\"),\n",
    "    (\"This is a potential title\", \"potential_title\"),\n",
    "    (\"abc123\", \"unknown\")\n",
    "]\n",
    "\n",
    "# Run tests\n",
    "for input_string, expected_output in test_cases:\n",
    "    result = detect_id_type(input_string)\n",
    "    # print(f\"Input: {input_string}\")\n",
    "    # print(f\"Expected: {expected_output}\")\n",
    "    # print(f\"Result: {result}\")\n",
    "    # print(\"Pass\" if result == expected_output else \"Fail\")\n",
    "    # print()\n",
    "\n",
    "# Count passed tests\n",
    "passed_tests = sum(1 for input_string, expected_output in test_cases if detect_id_type(input_string) == expected_output)\n",
    "print(f\"Passed {passed_tests} out of {len(test_cases)} tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Test with real IDs and by making a request to the API\n",
    "ids = ['38776920', '38701783', '38557723', '38422122', '38363432', '38175961', '38157855', \n",
    "'38048195', '37875108', '37779520', '37448622', '37083451', '37047709', '36763636', \n",
    "'36515678', '36736301', '36326697', '36342405', '36425144', '36094518', '36003377', \n",
    "'35670811', '35091979', '35090163', '34427831', '34623332', '34183838', '34413140', \n",
    "'34137790', '34214472', '34183371', '33876776', '33529170', '33497357', '33510449', \n",
    "'32960813', '33296702', '32972995', '32163377', '31995689', '31784499', '31270247', \n",
    "'31346092', '31046570', '30578925', '31231515', '31559014', '30578352', '30143481', \n",
    "'29907691', '29537367', '28437470', '28069966', '27347375', '26720836', '25819983', \n",
    "'24949794', '24332264', '24603545', '24391215', '24119913', '23543769', '23467413', \n",
    "'23487427', '22535679', '21695123', '21050116', '20176798', '18582518', '18424515']\n",
    "\n",
    "ids_string = \",\".join(ids)\n",
    "\n",
    "detected_id_types = json.loads(id_converter_tool(ids_string))[\"detected_id_types\"]\n",
    "assert detected_id_types.values(), \"No ID types were detected for any of the input IDs.\"\n",
    "\n",
    "data = convert_id(ids)\n",
    "assert data.get(\"status\") == \"ok\", f\"Conversion failed with status: {data.get('status', 'unknown')}\"\n",
    "\n",
    "for record in data.get(\"records\", []):\n",
    "    assert record.get(\"pmid\") or record.get(\"doi\"), f\"No PMID or DOI found for record: {record}\"\n",
    "    # print(f\"PMID: {record.get('pmid', 'N/A')}, DOI: {record.get('doi', 'N/A')}, PMCID: {record.get('pmcid', 'N/A')}\")\n",
    "print(\"All tests passed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Generate a list of actual DOIs and PMCIDs from the API response\n",
    "doi_list = []\n",
    "pmcid_list = []\n",
    "for record in data.get(\"records\", []):\n",
    "    doi_list.append(record.get(\"doi\"))\n",
    "    pmcid_list.append(record.get(\"pmcid\"))\n",
    "doi_list = list(filter(None, doi_list)) # filter to remore None values\n",
    "pmcid_list = list(filter(None, pmcid_list)) # filter to remore None values\n",
    "\n",
    "for doi in doi_list:\n",
    "    assert detect_id_type(doi) == \"doi\", f\"Failed to detect DOI for {doi}\"\n",
    "print(\"All DOIs detected successfully!\")\n",
    "for pmcid in pmcid_list:\n",
    "    assert detect_id_type(pmcid) == \"pmcid\", f\"Failed to detect PMCID for {pmcid}\"\n",
    "print(\"All PMCIDs detected successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "The function `query_openalex_api()` below is executed to query the OpenAlex database for additional information about a given a article, either by title, PubMed ID, PMC ID, or DOI.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# @json_schema_decorator\n",
    "# def query_openalex_api(identifyer: str, identifyer_type: str=\"title\") -> str:\n",
    "#     \"\"\"\n",
    "#     Retrieve metadata for a given article from OpenAlex, a comprehensive open-access catalog of global research papers.\n",
    "#     Use this tool to query the OpenAlex API by using either the title, the PubMed ID, or the digital object identifier (DOI) to retrieve the following metadata:\n",
    "#     - the OpenAlex ID\n",
    "#     - the digital object identifier (DOI) URL\n",
    "#     - Citation count\n",
    "#     - The open access status\n",
    "#     - URL to the open-access location for the work\n",
    "#     - Publication year\n",
    "#     - A URL to a website listing works that have cite the article\n",
    "#     - The type of the article\n",
    "#     Use this tool only if an article title, PubMed ID or DOI is provided by the user or was extracted from a local PDF file and is present in the conversation history.\n",
    "    \n",
    "#     Args:\n",
    "#         identifyer (str): The title, PubMed ID, or DOI of the article to retrieve metadata for.\n",
    "#         identifyter_type (str): The type of identifier to use for the query. Options are: 'title', 'pmid', or 'doi'. Default is 'title'.\n",
    "\n",
    "#     Returns:\n",
    "#         str: A JSON-formatted string including the search results from the OpenAlex database. If no results are found or the API query fails, an appropriate message is returned.\n",
    "#     \"\"\"\n",
    "\n",
    "#     if 'EMAIL' not in globals():\n",
    "#         try:\n",
    "#             EMAIL = os.getenv(\"EMAIL\")\n",
    "#         except KeyError:\n",
    "#             EMAIL = \"\"\n",
    "\n",
    "\n",
    "\n",
    "#     # Validate the input\n",
    "#     if not isinstance(identifyer, str) or not identifyer:\n",
    "#         return json.dumps({\"error\": \"The identifier must be a non-empty string.\"})\n",
    "#     if identifyer_type.lower().strip() not in ['title', 'pmid', 'doi']:\n",
    "#         return json.dumps({\"error\": \"The identifier type must be one of the following: 'title', 'pmid', or 'doi'.\"})\n",
    "#     if identifyer.startswith(\"https://doi.org/\"):\n",
    "#         identifyer = identifyer.replace(\"https://doi.org/\", \"\")\n",
    "\n",
    "#     # Constants\n",
    "#     base_url = \"https://api.openalex.org/\" # Define the base URL for the OpenAlex API\n",
    "#     doi_regex = r\"10.\\d{1,9}/[-._;()/:A-Za-z0-9]+\" # Regular expression to match DOIs\n",
    "\n",
    "#     # Initialize variables\n",
    "#     filter = \"\"\n",
    "\n",
    "#     if identifyer_type.lower() == 'title':\n",
    "#         url = f\"{base_url}works?\"\n",
    "#         filter = f\"title.search:{identifyer}\"\n",
    "#     elif identifyer_type.lower() == 'pmid':\n",
    "#         url = f\"{base_url}works/pmid:{identifyer}\"\n",
    "#     elif identifyer_type.lower() == 'doi':\n",
    "#         if identifyer.startswith(\"https://doi.org/\"):\n",
    "#             url = f\"{base_url}works/{identifyer}\"\n",
    "#         elif identifyer.startswith(\"doi.org/\"):\n",
    "#             url = f\"{base_url}works/https://{identifyer}\"\n",
    "#         elif re.match(doi_regex, identifyer):\n",
    "#             url = f\"{base_url}works/https://doi.org/{identifyer}\"\n",
    "\n",
    "#     # Set the query parameters\n",
    "#     params = {\n",
    "#         \"mailto\": EMAIL,\n",
    "#         \"page\": 1,\n",
    "#         \"per-page\": 5,\n",
    "#         \"select\": \"id,doi,title,publication_year,cited_by_count,cited_by_api_url,open_access,type,type_crossref\",\n",
    "#     }\n",
    "#     if filter:\n",
    "#         params[\"filter\"] = filter # Add the filter parameter for title search\n",
    "\n",
    "#     response = requests.get(url, params=params)\n",
    "\n",
    "#     if response.status_code != 200:\n",
    "#         return {\"error\": f\"Failed to query OpenAlex API. Status code: {response.status_code}\"}\n",
    "\n",
    "#     raw_search_results = response.json()\n",
    "\n",
    "#     if identifyer_type.lower() == \"title\":\n",
    "#         number_of_search_matches = raw_search_results['meta']['count']\n",
    "#         if len(raw_search_results['results']) == 0:\n",
    "#             return \"No results found for the provided title.\"\n",
    "#         elif number_of_search_matches > 5:\n",
    "#             return \"Error: The search results are more than 5. Please provide a correct title.\"\n",
    "#         else:\n",
    "#             formatted_results = []\n",
    "#             for result in raw_search_results['results']:\n",
    "#                 formatted_results.append(result)\n",
    "#             return json.dumps(formatted_results, indent=2)\n",
    "\n",
    "#     elif identifyer_type.lower() == \"pmid\":\n",
    "#         if len(raw_search_results) == 0:\n",
    "#             return {\"search result\": \"None\"}\n",
    "#         else:\n",
    "#             return json.dumps(raw_search_results, indent=2)\n",
    "    \n",
    "#     elif identifyer_type.lower() == \"doi\":\n",
    "#         return json.dumps(raw_search_results, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# assert type(query_openalex_api.json_schema) == dict\n",
    "# assert query_openalex_api.json_schema['function']['name'] == \"query_openalex_api\"\n",
    "# assert 'identifyer' in query_openalex_api.json_schema['function']['parameters']['properties'].keys()\n",
    "# assert 'identifyer_type' in query_openalex_api.json_schema['function']['parameters']['properties'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from unittest.mock import patch\n",
    "\n",
    "# # Mock responses for different scenarios\n",
    "# mock_title_response = {\n",
    "#     \"meta\": {\"count\": 1},\n",
    "#     \"results\": [{\n",
    "#         \"id\": \"https://openalex.org/W1234567890\",\n",
    "#         \"doi\": \"https://doi.org/10.1234/example\",\n",
    "#         \"title\": \"Example Article\",\n",
    "#         \"publication_year\": 2023,\n",
    "#         \"cited_by_count\": 42,\n",
    "#         \"cited_by_api_url\": \"https://api.openalex.org/works?filter=cites:W1234567890\",\n",
    "#         \"open_access\": {\"is_oa\": True, \"oa_status\": \"gold\"},\n",
    "#         \"type\": \"journal-article\",\n",
    "#         \"type_crossref\": \"journal-article\"\n",
    "#     }]\n",
    "# }\n",
    "\n",
    "# mock_pmid_response = {\n",
    "#     \"id\": \"https://openalex.org/W9876543210\",\n",
    "#     \"doi\": \"https://doi.org/10.5678/example\",\n",
    "#     \"title\": \"Example Article with a PMID\",\n",
    "#     \"publication_year\": 2022,\n",
    "#     \"cited_by_count\": 10,\n",
    "#     \"cited_by_api_url\": \"https://api.openalex.org/works?filter=cites:W9876543210\",\n",
    "#     \"open_access\": {\"is_oa\": False, \"oa_status\": \"closed\"},\n",
    "#     \"type\": \"journal-article\",\n",
    "#     \"type_crossref\": \"journal-article\"\n",
    "# }\n",
    "\n",
    "# mock_doi_response = {\n",
    "#     \"id\": \"https://openalex.org/W1357924680\",\n",
    "#     \"doi\": \"https://doi.org/10.9876/example\",\n",
    "#     \"title\": \"Example Book Chapter\",\n",
    "#     \"publication_year\": 2021,\n",
    "#     \"cited_by_count\": 100,\n",
    "#     \"cited_by_api_url\": \"https://api.openalex.org/works?filter=cites:W1357924680\",\n",
    "#     \"open_access\": {\"is_oa\": True, \"oa_status\": \"bronze\"},\n",
    "#     \"type\": \"book-chapter\",\n",
    "#     \"type_crossref\": \"book-chapter\"\n",
    "# }\n",
    "\n",
    "# # Test case\n",
    "# def test_query_openalex_api():\n",
    "#     # Mock the requests.get function\n",
    "#     with patch('requests.get') as mock_get:\n",
    "#         # Test with a title\n",
    "#         mock_get.return_value.status_code = 200\n",
    "#         mock_get.return_value.json.return_value = mock_title_response\n",
    "#         result = query_openalex_api(\"Example Article\", \"title\")\n",
    "#         assert isinstance(result, str), \"Result should be a string\"\n",
    "#         parsed_result = json.loads(result)\n",
    "#         assert len(parsed_result) == 1, \"Should return one result for title search\"\n",
    "#         assert parsed_result[0]['title'] == \"Example Article\", \"Title should match\"\n",
    "\n",
    "#         # Test with a PMID\n",
    "#         mock_get.return_value.json.return_value = mock_pmid_response\n",
    "#         result = query_openalex_api(\"12345678\", \"pmid\")\n",
    "#         assert isinstance(result, str), \"Result should be a string\"\n",
    "#         parsed_result = json.loads(result)\n",
    "#         assert parsed_result['title'] == \"Example Article with a PMID\", \"Title should match for PMID search\"\n",
    "\n",
    "#         # Test with a DOI\n",
    "#         mock_get.return_value.json.return_value = mock_doi_response\n",
    "#         result = query_openalex_api(\"10.9876/example\", \"doi\")\n",
    "#         assert isinstance(result, str), \"Result should be a string\"\n",
    "#         parsed_result = json.loads(result)\n",
    "#         assert parsed_result['doi'] == \"https://doi.org/10.9876/example\", \"DOI should match\"\n",
    "\n",
    "#         # Test with an invalid identifier type\n",
    "#         result = query_openalex_api(\"Example\", \"invalid_type\")\n",
    "#         assert \"error\" in json.loads(result), \"Should return an error message for invalid identifier type\"\n",
    "\n",
    "#         # Test with an empty identifier\n",
    "#         result = query_openalex_api(\"\", \"title\")\n",
    "#         assert \"error\" in json.loads(result), \"Should return an error message for empty identifier\"\n",
    "\n",
    "#         # Test with multiple results for title search\n",
    "#         mock_get.return_value.json.return_value = {\"meta\": {\"count\": 10}, \"results\": [{}] * 10}\n",
    "#         result = query_openalex_api(\"Common Title\", \"title\")\n",
    "#         assert result == \"Error: The search results are more than 5. Please provide a correct title.\", \"Should return error for too many results\"\n",
    "\n",
    "#         # Test with no results\n",
    "#         mock_get.return_value.json.return_value = {\"meta\": {\"count\": 0}, \"results\": []}\n",
    "#         result = query_openalex_api(\"Non-existent Article\", \"title\")\n",
    "#         assert result == \"No results found for the provided title.\", \"Should return a message indicating no results found\"\n",
    "\n",
    "#     print(\"All tests passed!\")\n",
    "\n",
    "# test_query_openalex_api()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# title = \"Human leukocyte antigen class II gene diversity tunes antibody repertoires to common pathogens\"\n",
    "# args = [\n",
    "#     (title, \"title\"),\n",
    "#     (\"36003377\", \"pmid\"),\n",
    "#     (\"10.3389/fimmu.2022.856497\", \"doi\"),\n",
    "#     (\"doi.org/10.3389/fimmu.2022.856497\", \"doi\"),\n",
    "#     (\"https://doi.org/10.3389/fimmu.2022.856497\", \"doi\"),\n",
    "# ]\n",
    "# try:\n",
    "#     api_responses = [query_openalex_api(*arg) for arg in args]\n",
    "#     assert all(title in response for response in api_responses), \"All responses should contain the title.\"\n",
    "#     assert all(isinstance(response, str) for response in api_responses), \"All responses should be strings.\"\n",
    "#     assert all(response == api_responses[1] for response in api_responses[1:]), \"All responses should be the same, except for the title search.\"\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def query_openalex_api(query_param: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve metadata for a given article from OpenAlex, a comprehensive open-access catalog of global research papers.\n",
    "    Use this tool to search the OpenAlex API by using the article title, the PubMed ID (PMID), the PubMed Central ID (PMCID) or the digital object identifier (DOI) of an article as the query parameter. \n",
    "    This tool returns the following metadata:\n",
    "    - the OpenAlex ID\n",
    "    - the digital object identifier (DOI) URL\n",
    "    - Citation count\n",
    "    - The open access status\n",
    "    - URL to the open-access location for the work\n",
    "    - Publication year\n",
    "    - A URL to a website listing works that have cite the article\n",
    "    - The type of the article\n",
    "    Use this tool only if an article title, PubMed ID or DOI is provided by the user or was extracted from a local PDF file and is present in the conversation history.\n",
    "    \n",
    "    Args:\n",
    "        query_param (str): The article title, the PubMed ID (PMID), the PubMed Central ID (PMCID) or the digital object identifier (DOI) of the article to retrieve metadata for. May be provided by the user or extracted from a local PDF file and present in the conversation history.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON-formatted string including the search results from the OpenAlex database. If no results are found or the API query fails, an appropriate message is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    if 'EMAIL' not in globals():\n",
    "        try:\n",
    "            EMAIL = os.getenv(\"EMAIL\")\n",
    "        except KeyError:\n",
    "            EMAIL = \"\"\n",
    "\n",
    "    # Validate the input\n",
    "    if query_param is None or query_param == \"\":\n",
    "        return json.dumps({\"error\": \"The query parameter must be a non-empty string.\"})\n",
    "    elif not isinstance(query_param, str):\n",
    "        query_param = str(query_param)\n",
    "    \n",
    "    if query_param.startswith(\"https://doi.org/\"):\n",
    "        query_param = query_param.replace(\"https://doi.org/\", \"\")\n",
    "    elif query_param.startswith(\"doi.org/\"):\n",
    "        query_param = query_param.replace(\"doi.org/\", \"\")\n",
    "\n",
    "    # Constants\n",
    "    base_url = \"https://api.openalex.org/\" # Define the base URL for the OpenAlex API\n",
    "    \n",
    "    # Initialize variables\n",
    "    filter = \"\"\n",
    "\n",
    "    if detect_id_type(query_param) == \"potential_title\":\n",
    "        url = f\"{base_url}works?\"\n",
    "        filter = f\"title.search:{query_param}\"\n",
    "    elif detect_id_type(query_param) == \"pmid\":\n",
    "        url = f\"{base_url}works/pmid:{query_param}\"\n",
    "    elif detect_id_type(query_param) == \"doi\":\n",
    "        url = f\"{base_url}works/https://doi.org/{query_param}\"\n",
    "    elif detect_id_type(query_param) == \"pmcid\":\n",
    "        url = f\"{base_url}works/pmcid:{query_param}\"\n",
    "    else:\n",
    "        return json.dumps({\"error\": \"The query parameter must be a valid title, PMID, PMCID, or DOI.\"})\n",
    "        \n",
    "    # Set the query parameters\n",
    "    params = {\n",
    "        \"mailto\": EMAIL,\n",
    "        \"page\": 1,\n",
    "        \"per-page\": 5,\n",
    "        \"select\": \"id,doi,title,publication_year,cited_by_count,cited_by_api_url,open_access,type,type_crossref\",\n",
    "    }\n",
    "    if filter:\n",
    "        params[\"filter\"] = filter # Add the filter parameter for title search\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return {\"error\": f\"Failed to query OpenAlex API. Status code: {response.status_code}\"}\n",
    "\n",
    "    raw_search_results = response.json()\n",
    "\n",
    "    if filter:\n",
    "        number_of_search_matches = raw_search_results['meta']['count']\n",
    "        if len(raw_search_results['results']) == 0:\n",
    "            return \"No results found for the provided title.\"\n",
    "        elif number_of_search_matches > 5:\n",
    "            return \"Error: The search results are more than 5. Please provide a correct title.\"\n",
    "        else:\n",
    "            formatted_results = []\n",
    "            for result in raw_search_results['results']:\n",
    "                formatted_results.append(result)\n",
    "            return json.dumps(formatted_results, indent=2)\n",
    "\n",
    "    \n",
    "    if len(raw_search_results) == 0:\n",
    "        return {\"search result\": \"None\"}\n",
    "    else:\n",
    "        return json.dumps(raw_search_results, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assert the correct format of the JSON schema..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "assert type(query_openalex_api.json_schema) == dict\n",
    "assert query_openalex_api.json_schema['function']['name'] == \"query_openalex_api\"\n",
    "assert 'query_param' in query_openalex_api.json_schema['function']['parameters']['properties'].keys()\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test case for the `query_openalex_api()` function is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from unittest.mock import patch\n",
    "\n",
    "# Mock responses for different scenarios\n",
    "mock_title_response = {\n",
    "    \"meta\": {\"count\": 1},\n",
    "    \"results\": [{\n",
    "        \"id\": \"https://openalex.org/W1234567890\",\n",
    "        \"doi\": \"https://doi.org/10.1234/example\",\n",
    "        \"title\": \"Example Article\",\n",
    "        \"publication_year\": 2023,\n",
    "        \"cited_by_count\": 42,\n",
    "        \"cited_by_api_url\": \"https://api.openalex.org/works?filter=cites:W1234567890\",\n",
    "        \"open_access\": {\"is_oa\": True, \"oa_status\": \"gold\"},\n",
    "        \"type\": \"journal-article\",\n",
    "        \"type_crossref\": \"journal-article\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "mock_pmid_response = {\n",
    "    \"id\": \"https://openalex.org/W9876543210\",\n",
    "    \"doi\": \"https://doi.org/10.5678/example\",\n",
    "    \"title\": \"Example Article with a PMID\",\n",
    "    \"publication_year\": 2022,\n",
    "    \"cited_by_count\": 10,\n",
    "    \"cited_by_api_url\": \"https://api.openalex.org/works?filter=cites:W9876543210\",\n",
    "    \"open_access\": {\"is_oa\": False, \"oa_status\": \"closed\"},\n",
    "    \"type\": \"journal-article\",\n",
    "    \"type_crossref\": \"journal-article\"\n",
    "}\n",
    "\n",
    "mock_doi_response = {\n",
    "    \"id\": \"https://openalex.org/W1357924680\",\n",
    "    \"doi\": \"https://doi.org/10.9876/example\",\n",
    "    \"title\": \"Example Book Chapter\",\n",
    "    \"publication_year\": 2021,\n",
    "    \"cited_by_count\": 100,\n",
    "    \"cited_by_api_url\": \"https://api.openalex.org/works?filter=cites:W1357924680\",\n",
    "    \"open_access\": {\"is_oa\": True, \"oa_status\": \"bronze\"},\n",
    "    \"type\": \"book-chapter\",\n",
    "    \"type_crossref\": \"book-chapter\"\n",
    "}\n",
    "\n",
    "# Test case\n",
    "def test_query_openalex_api():\n",
    "    # Mock the requests.get function\n",
    "    with patch('requests.get') as mock_get:\n",
    "        # Test with a title\n",
    "        mock_get.return_value.status_code = 200\n",
    "        mock_get.return_value.json.return_value = mock_title_response\n",
    "        result = query_openalex_api(\"Example Article\")\n",
    "        assert isinstance(result, str), \"Result should be a string\"\n",
    "        parsed_result = json.loads(result)\n",
    "        assert len(parsed_result) == 1, \"Should return one result for title search\"\n",
    "        assert parsed_result[0]['title'] == \"Example Article\", \"Title should match\"\n",
    "\n",
    "        # Test with a PMID\n",
    "        mock_get.return_value.json.return_value = mock_pmid_response\n",
    "        result = query_openalex_api(\"12345678\")\n",
    "        assert isinstance(result, str), \"Result should be a string\"\n",
    "        parsed_result = json.loads(result)\n",
    "        assert parsed_result['title'] == \"Example Article with a PMID\", \"Title should match for PMID search\"\n",
    "\n",
    "        # Test with a DOI\n",
    "        mock_get.return_value.json.return_value = mock_doi_response\n",
    "        result = query_openalex_api(\"10.9876/example\")\n",
    "        assert isinstance(result, str), \"Result should be a string\"\n",
    "        parsed_result = json.loads(result)\n",
    "        assert parsed_result['doi'] == \"https://doi.org/10.9876/example\", \"DOI should match\"\n",
    "\n",
    "        # Test with an empty identifier\n",
    "        result = query_openalex_api(\"\")\n",
    "        assert \"error\" in json.loads(result), \"Should return an error message for empty identifier\"\n",
    "\n",
    "        # Test with multiple results for title search\n",
    "        mock_get.return_value.json.return_value = {\"meta\": {\"count\": 10}, \"results\": [{}] * 10}\n",
    "        result = query_openalex_api(\"Common Title\")\n",
    "        assert result == \"Error: The search results are more than 5. Please provide a correct title.\", \"Should return error for too many results\"\n",
    "\n",
    "        # Test with no results\n",
    "        mock_get.return_value.json.return_value = {\"meta\": {\"count\": 0}, \"results\": []}\n",
    "        result = query_openalex_api(\"Non-existent Article\")\n",
    "        assert result == \"No results found for the provided title.\", \"Should return a message indicating no results found\"\n",
    "\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_query_openalex_api()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Below are tests that make calls to the OpenAlex API... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "print(query_openalex_api(\"36003377\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "title = \"Human leukocyte antigen class II gene diversity tunes antibody repertoires to common pathogens\"\n",
    "args = [title, \"36003377\", \"10.3389/fimmu.2022.856497\", \"doi.org/10.3389/fimmu.2022.856497\", \"https://doi.org/10.3389/fimmu.2022.856497\"]\n",
    "try:\n",
    "    api_responses = [query_openalex_api(arg) for arg in args]\n",
    "    # for response in api_responses:\n",
    "    #     print(response[:300])\n",
    "    assert all(title in response for response in api_responses), \"All responses should contain the title.\"\n",
    "    assert all(isinstance(response, str) for response in api_responses), \"All responses should be strings.\"\n",
    "    assert all(response == api_responses[1] for response in api_responses[1:]), \"All responses should be the same, except for the title search.\"\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "The follwoing code cells are for demonstrating the use of **Semantic Scholar's Academic Graph API** to retrieve information about scholarly articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Try loading the Semantic Scholar API key from the environment variables\n",
    "try:\n",
    "    SEMANTIC_SCHOLAR_API_KEY\n",
    "except NameError:\n",
    "    SEMANTIC_SCHOLAR_API_KEY = os.environ.get(\"SEMANTIC_SCHOLAR_API_KEY\")\n",
    "\n",
    "# Construct the URL to query the Semantic Scholar API by paper ID, and define headers with an API key\n",
    "paper_id = \"PMID:36003377\"  # Example paper ID\n",
    "academicgraph_base_url = \"https://api.semanticscholar.org/graph/v1\"\n",
    "resource = \"/paper/\"\n",
    "resource_path = f\"{resource}{paper_id}\"\n",
    "fields = \"title,year,tldr\"\n",
    "query_params = f\"?fields={fields}\"\n",
    "url = f\"{academicgraph_base_url}{resource_path}{query_params}\"\n",
    "headers = {'x-api-key': SEMANTIC_SCHOLAR_API_KEY}\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Send the API request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "   response_data = response.json()\n",
    "   # Process and print the response data as needed\n",
    "   print(json.dumps(response_data, indent=2))\n",
    "else:\n",
    "   print(f\"Request failed with status code {response.status_code}: {response.text}\")\n",
    "time.sleep(1) # sleep for 1 second to avoid rate limiting issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Query by title; this may return multiple results\n",
    "title = \"Human leukocyte antigen class II gene diversity tunes antibody repertoires to common pathogens\"\n",
    "url = f\"{academicgraph_base_url}/paper/search?query={title}&fields={fields}\"\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_data = response.json()\n",
    "    # print(json.dumps(response_data, indent=2))\n",
    "    assert title in response_data['data'][0]['title'], \"Title should match the query\"\n",
    "    print(\"Test passed successfully!\")\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code}: {response.text}\")\n",
    "time.sleep(1) # sleep for 1 second to avoid rate limiting issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Title search; this only returns the top result\n",
    "title = \"Human leukocyte antigen class II gene diversity tunes antibody repertoires to common pathogens\"\n",
    "url = f\"{academicgraph_base_url}/paper/search/match?query={title}&fields={fields}\"\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_data = response.json()\n",
    "    # print(json.dumps(response_data, indent=2))\n",
    "    assert title in response_data[\"data\"][0][\"title\"], \"Title should match the query\"\n",
    "    print(\"Test passed successfully!\")\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code}: {response.text}\")\n",
    "time.sleep(1) # sleep for 1 second to avoid rate limiting issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "The function `query_semantic_scholar_api()` below is executed to query the Semantic Scholar database for additional information about a given article, either by title, PubMed ID, or DOI. To\n",
    "increase the rate limit, provide your own API key (see the documentation for more information).\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# @json_schema_decorator\n",
    "# def query_semantic_scholar_api(identifyer: str, identifyer_type: str = \"title\") -> str:\n",
    "#     \"\"\"\n",
    "#     Retrieve metadata for a given article from the Semantic Scholar Academic Graph (S2AG), a large knowledge graph of scientific literature that combines data from multiple sources.\n",
    "#     Use this tool to query the Semantic Scholar Graph API by using either the title, the PubMed ID, or the digital object identifier (DOI) to retrieve the following metadata:\n",
    "#     - the title\n",
    "#     - the publication year\n",
    "#     - the abstract\n",
    "#     - a tldr (too long, didn't read) summary\n",
    "#     - the authors of the article\n",
    "#     - the URL to the open-access PDF version of the article, if available\n",
    "#     - the journal name\n",
    "#     - a url to the article on the Semantic Scholar website\n",
    "#     Use this tool only if an article title, PubMed ID or DOI is provided by the user or was extracted from a local PDF file and is present in the conversation history.\n",
    "    \n",
    "#     Args:\n",
    "#         identifyer (str): The title, PubMed ID, or DOI of the article to retrieve metadata for.\n",
    "#         identifyter_type (str): The type of identifier to use for the query. Options are: 'title', 'pmid', or 'doi'. Default is 'title'.\n",
    "\n",
    "#     Returns:\n",
    "#         str: A JSON-formatted string including the search results from the Semantic Scholar database. If no results are found or the API query fails, an appropriate message is returned.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Validate the input\n",
    "#     if not isinstance(identifyer, str) or not identifyer:\n",
    "#         return json.dumps({\"error\": \"The identifier must be a non-empty string.\"})\n",
    "#     if identifyer_type.lower().strip() not in ['title', 'pmid', 'doi']:\n",
    "#         return json.dumps({\"error\": \"The identifier type must be one of the following: 'title', 'pmid', or 'doi'.\"})\n",
    "\n",
    "#     # Constants\n",
    "#     academicgraph_base_url = \"https://api.semanticscholar.org/graph/v1\"\n",
    "#     fields = \"title,year,authors,tldr,abstract,citationCount,openAccessPdf,journal,url\" # The values to retrieve from the API\n",
    "#     doi_regex = r\"10.\\d{1,9}/[-._;()/:A-Za-z0-9]+\" # Regular expression to match DOIs\n",
    "\n",
    "#     # Try to get the API key from the environment variables, if available, and define the headers\n",
    "#     try:\n",
    "#         SEMANTIC_SCHOLAR_API_KEY\n",
    "#     except NameError:\n",
    "#         SEMANTIC_SCHOLAR_API_KEY = os.environ.get(\"SEMANTIC_SCHOLAR_API_KEY\")\n",
    "#     headers = {'x-api-key': SEMANTIC_SCHOLAR_API_KEY}\n",
    "\n",
    "#     # Construct the URL based on the identifier type\n",
    "#     if identifyer_type.lower() == 'title':\n",
    "#         url = f\"{academicgraph_base_url}/paper/search/match?query={identifyer}&fields={fields}\"\n",
    "#     else:\n",
    "#         # Construct resource path when searching by PMID or DOI\n",
    "#         if identifyer_type.lower() == 'pmid':\n",
    "#             paper_id = f\"PMID:{identifyer}\"\n",
    "#         elif identifyer_type.lower() == 'doi':\n",
    "#             if identifyer.startswith(\"https://doi.org/\"):\n",
    "#                 paper_id = f\"DOI:{identifyer.replace('https://doi.org/', '')}\"\n",
    "#             elif identifyer.startswith(\"doi.org/\"):\n",
    "#                 paper_id = f\"DOI:{identifyer.replace('doi.org/', '')}\"\n",
    "#             elif re.match(doi_regex, identifyer):\n",
    "#                 paper_id = f\"DOI:{identifyer}\"\n",
    "#         url = f\"{academicgraph_base_url}/paper/{paper_id}?&fields={fields}\"\n",
    "    \n",
    "#     response = requests.get(url, headers=headers) # Send the API request\n",
    "#     # print(response.url) # Uncomment for debugging\n",
    "#     time.sleep(2) # sleep for 2 seconds to avoid rate limiting issues\n",
    "    \n",
    "#     # Check response status\n",
    "#     if response.status_code == 200:\n",
    "#         return json.dumps(response.json(), indent=2)\n",
    "#     else:\n",
    "#         return f\"Error: Failed to query Semantic Scholar API. Status code: {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "\n",
    "# import json\n",
    "# from unittest.mock import patch\n",
    "\n",
    "# # Mock response for successful API call\n",
    "# mock_success_response = {\n",
    "#     \"title\": \"Example Article\",\n",
    "#     \"year\": 2023,\n",
    "#     \"authors\": [{\"name\": \"John Doe\"}, {\"name\": \"Jane Smith\"}],\n",
    "#     \"tldr\": {\"text\": \"This is a summary of the article.\"},\n",
    "#     \"abstract\": \"This is the abstract of the example article.\",\n",
    "#     \"citationCount\": 42,\n",
    "#     \"openAccessPdf\": {\"url\": \"https://example.com/paper.pdf\"},\n",
    "#     \"journal\": {\"name\": \"Example Journal\"},\n",
    "#     \"url\": \"https://www.semanticscholar.org/paper/example\"\n",
    "# }\n",
    "\n",
    "# # Test case for query_semantic_scholar_api function\n",
    "# def test_query_semantic_scholar_api():\n",
    "#     # Mock the requests.get function\n",
    "#     with patch('requests.get') as mock_get:\n",
    "#         # Configure the mock to return a successful response\n",
    "#         mock_get.return_value.status_code = 200\n",
    "#         mock_get.return_value.json.return_value = mock_success_response\n",
    "\n",
    "#         # Test with a title\n",
    "#         result = query_semantic_scholar_api(\"Example Article\", \"title\")\n",
    "#         assert isinstance(result, str), \"Result should be a string\"\n",
    "        \n",
    "#         parsed_result = json.loads(result)\n",
    "#         assert parsed_result == mock_success_response, \"Returned JSON should match the mock response\"\n",
    "\n",
    "#         # Test with a DOI\n",
    "#         result = query_semantic_scholar_api(\"10.1234/example.doi\", \"doi\")\n",
    "#         assert isinstance(result, str), \"Result should be a string\"\n",
    "        \n",
    "#         parsed_result = json.loads(result)\n",
    "#         assert parsed_result == mock_success_response, \"Returned JSON should match the mock response\"\n",
    "\n",
    "#         # Test with an invalid identifier type\n",
    "#         result = query_semantic_scholar_api(\"Example\", \"invalid_type\")\n",
    "#         assert \"error\" in json.loads(result), \"Should return an error message for invalid identifier type\"\n",
    "\n",
    "#     # Test with an empty identifier\n",
    "#     result = query_semantic_scholar_api(\"\", \"title\")\n",
    "#     assert \"error\" in json.loads(result), \"Should return an error message for empty identifier\"\n",
    "\n",
    "#     print(\"All tests passed!\")\n",
    "\n",
    "# # Run the test\n",
    "# test_query_semantic_scholar_api()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assert the correct format of the JSON schema..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def query_semantic_scholar_api(query_param: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve metadata for a given article from the Semantic Scholar Academic Graph (S2AG), a large knowledge graph of scientific literature that combines data from multiple sources.\n",
    "    Use this tool to query the Semantic Scholar Graph API by using either the article title, the PubMed ID, or the digital object identifier (DOI) to retrieve the following metadata:\n",
    "    - the title\n",
    "    - the publication year\n",
    "    - the abstract\n",
    "    - a tldr (too long, didn't read) summary\n",
    "    - the authors of the article\n",
    "    - the URL to the open-access PDF version of the article, if available\n",
    "    - the journal name\n",
    "    - a url to the article on the Semantic Scholar website\n",
    "    Use this tool only if an article title, PubMed ID or DOI is provided by the user or was extracted from a local PDF file and is present in the conversation history.\n",
    "    \n",
    "    Args:\n",
    "        query_param (str): The article title, the PubMed ID, or the digital object identifier of the article to retrieve metadata for. May be provided by the user or extracted from a local PDF file and present in the conversation history. Do not include the 'https://doi.org/' prefix for DOIs, or keys such as 'DOI', 'PMCID' or 'PMID'. The tool will automatically detect the type of identifier provided.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON-formatted string including the search results from the Semantic Scholar database. If no results are found or the API query fails, an appropriate message is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    # Try to get the API key from the environment variables, if available, and define the headers\n",
    "    try:\n",
    "        SEMANTIC_SCHOLAR_API_KEY\n",
    "    except NameError:\n",
    "        SEMANTIC_SCHOLAR_API_KEY = os.environ.get(\"SEMANTIC_SCHOLAR_API_KEY\")\n",
    "    headers = {'x-api-key': SEMANTIC_SCHOLAR_API_KEY}\n",
    "\n",
    "    # Validate the input\n",
    "    if query_param is None or query_param == \"\":\n",
    "        return json.dumps({\"error\": \"The query parameter must be a non-empty string.\"})\n",
    "    elif not isinstance(query_param, str):\n",
    "        query_param = str(query_param)\n",
    "    \n",
    "    # Clean the query parameter\n",
    "    query_param = query_param.strip().lower() # Convert to lowercase and remove leading/trailing whitespace\n",
    "    if query_param.startswith(\"https://doi.org/\"):\n",
    "        query_param = query_param.replace(\"https://doi.org/\", \"\")\n",
    "    elif query_param.startswith(\"doi.org/\"):\n",
    "        query_param = query_param.replace(\"doi.org/\", \"\")\n",
    "    elif query_param.startswith(\"doi\"):\n",
    "        query_param = query_param.replace(\"doi\", \"\")\n",
    "    elif query_param.startswith(\"pmid\"):\n",
    "        query_param = query_param.replace(\"pmid\", \"\")\n",
    "    elif query_param.startswith(\"pmcid\"):\n",
    "        query_param = query_param.replace(\"pmcid\", \"\")\n",
    "    if detect_id_type(query_param) != \"potential_title\":\n",
    "        query_param = query_param.replace(\":\", \"\") # Remove any colons from the query parameter if it is not a title\n",
    "        query_param = query_param.replace(\" \", \"\") # Remove spaces from the query parameter if it is not a title\n",
    "\n",
    "    # Constants\n",
    "    academicgraph_base_url = \"https://api.semanticscholar.org/graph/v1\"\n",
    "    fields = \"title,year,authors,tldr,abstract,citationCount,openAccessPdf,journal,url\" # The values to retrieve from the API\n",
    "\n",
    "\n",
    "    # Construct the URL based on the identifier type\n",
    "    if detect_id_type(query_param) == \"potential_title\":\n",
    "        url = f\"{academicgraph_base_url}/paper/search/match?query={query_param}&fields={fields}\"\n",
    "    elif detect_id_type(query_param) == \"pmid\":\n",
    "        url = f\"{academicgraph_base_url}/paper/PMID:{query_param}?&fields={fields}\"\n",
    "    elif detect_id_type(query_param) == \"doi\":\n",
    "        url = f\"{academicgraph_base_url}/paper/DOI:{query_param}?&fields={fields}\"\n",
    "    else:\n",
    "        return json.dumps({\"error\": \"The query parameter must be a valid title, PMID, or DOI.\"})\n",
    "    \n",
    "    response = requests.get(url, headers=headers) # Send the API request\n",
    "    # print(response.url) # Uncomment for debugging\n",
    "    time.sleep(2) # sleep for 2 seconds to avoid rate limiting issues\n",
    "    \n",
    "    # Check response status\n",
    "    if response.status_code == 200:\n",
    "        return json.dumps(response.json(), indent=2)\n",
    "    else:\n",
    "        return f\"Error: Failed to query Semantic Scholar API. Status code: {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "assert type(query_semantic_scholar_api.json_schema) == dict\n",
    "assert query_semantic_scholar_api.json_schema['function']['name'] == \"query_semantic_scholar_api\"\n",
    "assert 'query_param' in query_semantic_scholar_api.json_schema['function']['parameters']['properties'].keys()\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test case for the `query_semantic_scholar_api()` function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import json\n",
    "from unittest.mock import patch\n",
    "\n",
    "# Mock response for successful API call\n",
    "mock_success_response = {\n",
    "    \"title\": \"Example Article\",\n",
    "    \"year\": 2023,\n",
    "    \"authors\": [{\"name\": \"John Doe\"}, {\"name\": \"Jane Smith\"}],\n",
    "    \"tldr\": {\"text\": \"This is a summary of the article.\"},\n",
    "    \"abstract\": \"This is the abstract of the example article.\",\n",
    "    \"citationCount\": 42,\n",
    "    \"openAccessPdf\": {\"url\": \"https://example.com/paper.pdf\"},\n",
    "    \"journal\": {\"name\": \"Example Journal\"},\n",
    "    \"url\": \"https://www.semanticscholar.org/paper/example\"\n",
    "}\n",
    "\n",
    "# Test case for query_semantic_scholar_api function\n",
    "def test_query_semantic_scholar_api():\n",
    "    # Mock the requests.get function\n",
    "    with patch('requests.get') as mock_get:\n",
    "        # Configure the mock to return a successful response\n",
    "        mock_get.return_value.status_code = 200\n",
    "        mock_get.return_value.json.return_value = mock_success_response\n",
    "\n",
    "        # Test with a title\n",
    "        result = query_semantic_scholar_api(\"Example Article\")\n",
    "        assert isinstance(result, str), \"Result should be a string\"\n",
    "        \n",
    "        parsed_result = json.loads(result)\n",
    "        assert parsed_result == mock_success_response, \"Returned JSON should match the mock response\"\n",
    "\n",
    "        # Test with a DOI\n",
    "        result = query_semantic_scholar_api(\"10.1234/example.doi\")\n",
    "        assert isinstance(result, str), \"Result should be a string\"\n",
    "        \n",
    "        parsed_result = json.loads(result)\n",
    "        assert parsed_result == mock_success_response, \"Returned JSON should match the mock response\"\n",
    "\n",
    "    # Test with an empty identifier\n",
    "    result = query_semantic_scholar_api(\"\")\n",
    "    assert \"error\" in json.loads(result), \"Should return an error message for empty identifier\"\n",
    "\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "# Run the test\n",
    "test_query_semantic_scholar_api()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "Below are tests that make API calls to Semantic Scholar to retrieve information about an actual article in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "response = query_semantic_scholar_api(\"36003377\")\n",
    "response = json.loads(response)\n",
    "assert response[\"paperId\"] == \"4d29302308973a7a92dc3a9f1295b2ba761e2a77\", \"PubMed ID should match the corresponding paper ID\"\n",
    "print(\"Test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "title = \"Human leukocyte antigen class II gene diversity tunes antibody repertoires to common pathogens\"\n",
    "args = [title, \"36003377\", \"10.3389/fimmu.2022.856497\", \"doi.org/10.3389/fimmu.2022.856497\", \"https://doi.org/10.3389/fimmu.2022.856497\"]\n",
    "try: \n",
    "    api_responses = [query_semantic_scholar_api(arg) for arg in args]\n",
    "    # for response in api_responses:\n",
    "    #     print(response[:300])\n",
    "    assert all(title in response for response in api_responses), \"All responses should contain the title.\"\n",
    "    assert all(isinstance(response, str) for response in api_responses), \"All responses should be strings.\"\n",
    "    assert all(response == api_responses[1] for response in api_responses[1:]), \"All responses should be the same, except for the title search.\"\n",
    "    print(\"All tests passed!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@json_schema_decorator\n",
    "def respond_to_generic_queries() -> str:\n",
    "    \"\"\"\n",
    "    A function to respond to generic questions or queries from the user. Use this tool if no better tool is available.\n",
    "\n",
    "    This tool does not take any arguments.\n",
    "\n",
    "    Returns:\n",
    "        str: A response to a generic question.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"There is no specific tool available to respond this query from the user. State your capabilities based the system message or provide a response based on the conversation history.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "assert type(respond_to_generic_queries.json_schema) == dict\n",
    "assert respond_to_generic_queries.json_schema['function']['name'] == \"respond_to_generic_queries\"\n",
    "assert type(respond_to_generic_queries()) == str\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assistant class\n",
    "To simplify the process of chat and tool use, we define the Assistant class, along with a fucntion to show responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_response(response: Dict[str, Any] or Generator[Dict[str, Any], None, None]) -> None:\n",
    "    \"\"\"\n",
    "    Print the response from the LLM in a human-readable format.\n",
    "\n",
    "    Args:\n",
    "        response (Dict[str, Any] or Generator[Dict[str, Any], None, None]): The response from the LLM.\n",
    "    \"\"\"\n",
    "    # ANSI escape code for blue and red text\n",
    "    BLUE = \"\\033[94m\"\n",
    "    RED = \"\\033[91m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "\n",
    "    if isinstance(response, dict):\n",
    "        print(f\"\\n{BLUE}{response['message']['content']}{RESET}\")\n",
    "        return response['message']['content']\n",
    "\n",
    "    elif isinstance(response, Generator):\n",
    "        print(\"\\n\")\n",
    "        _response = \"\"\n",
    "        for chunk in response:\n",
    "            _response += chunk['message']['content']\n",
    "            print(f\"{BLUE}{chunk['message']['content']}{RESET}\", end='', flush=True)\n",
    "        return _response\n",
    "    \n",
    "    elif response is None:\n",
    "        print(f\"\\n{RED}No response from the LLM.{RESET}\")\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"\\n{RED}nvalid response type. Must be a dictionary or a generator.{RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Test with dictionary input\n",
    "mock_response = {\n",
    "    \"message\": {\n",
    "        \"content\": \"This is a mock response for testing.\"\n",
    "    }\n",
    "}\n",
    "response = show_response(mock_response)\n",
    "assert response == \"This is a mock response for testing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import ollama\n",
    "from typing import Dict, Any, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Assistant:\n",
    "    def __init__(self,\n",
    "        sys_message: str or None = None, # The system message for the assistant; if not provided, a default message is used\n",
    "        model: str = \"llama3.1:latest\", # The model to use for the assistant\n",
    "        tools: Dict[str, Any] = { # The tools available to the assistant\n",
    "           \"get_file_names\": get_file_names,\n",
    "           \"extract_text_from_pdf\": extract_text_from_pdf,\n",
    "           \"get_titles_and_first_authors\": get_titles_and_first_authors,\n",
    "           \"summarize_local_document\": summarize_local_document,\n",
    "           \"describe_python_code\": describe_python_code,\n",
    "           \"id_converter_tool\": id_converter_tool,\n",
    "           \"query_openalex_api\": query_openalex_api,\n",
    "           \"query_semantic_scholar_api\": query_semantic_scholar_api,\n",
    "           \"respond_to_generic_queries\": respond_to_generic_queries,\n",
    "        },\n",
    "        add_tools: Dict[str, Any] = {}, # Optional argument to add additional tools to the assistant, when initializing\n",
    "        authentication: Optional[Dict[str, str]] = None, # Authentication credentials for API calls to external services\n",
    "        dir_path: str = \"../data\", # The directory path to which the assistant has access on the local computer\n",
    "        messages: List[Dict[str, str]] = [], # The conversation history\n",
    "        stream: bool = True): # Whether to stream the final response from the LLM\n",
    "        self.sys_message = sys_message\n",
    "        self.model = model\n",
    "        self.tools = tools\n",
    "        self.tools.update(add_tools) # Add additional tools to the assistant, if provided\n",
    "        if self.tools:\n",
    "            self.tools[\"describe_tools\"] = self.describe_tools # Add the describe_tools function to the tools list for the assistant, if the tools list is not empty\n",
    "        self.authentication = authentication or {}\n",
    "        self.dir_path = dir_path\n",
    "        self.messages = messages\n",
    "        self.stream = stream\n",
    "\n",
    "        # Set global variables\n",
    "        global DIR_PATH\n",
    "        DIR_PATH = self.dir_path\n",
    "        global MODEL\n",
    "        MODEL = self.model\n",
    "        # TODO: Consider allowing the user to set different models for different tasks and tools\n",
    "        # e.g. a model such as llama 3.1 for function calls, command-r-plus for summarization, aya for translation, etc.\n",
    "        \n",
    "        # Load the API keys from the environment variables or the authentication dictionary\n",
    "        self.SEMANTIC_SCHOLAR_API_KEY = self.authentication.get(\"SEMANTIC_SCHOLAR_API_KEY\")\n",
    "        self.EMAIL = self.authentication.get(\"EMAIL\")\n",
    "\n",
    "        if not self.SEMANTIC_SCHOLAR_API_KEY:\n",
    "            self.SEMANTIC_SCHOLAR_API_KEY = os.environ.get(\"SEMANTIC_SCHOLAR_API_KEY\")\n",
    "            if self.SEMANTIC_SCHOLAR_API_KEY:\n",
    "                print(\"Loaded Semantic Scholar API key from the environment variables.\")\n",
    "        if not self.EMAIL:\n",
    "            self.EMAIL = os.environ.get(\"EMAIL\")\n",
    "            if self.EMAIL:\n",
    "                print(\"Loaded email address from the environment variables.\")\n",
    "\n",
    "        # Generate the default directory for storing data files if it does not exist\n",
    "        if not os.path.exists(DIR_PATH):\n",
    "            os.mkdir(DIR_PATH)\n",
    "            print(f\"Created directory {DIR_PATH} for storing data files.\\n\")\n",
    "        else: \n",
    "            print(f\"A local directory {DIR_PATH} already exists for storing data files. No of files: {len(os.listdir(DIR_PATH))}\\n\")\n",
    "\n",
    "        # Set the default system message if not provided\n",
    "        if not self.sys_message:\n",
    "            self.sys_message =\"\"\"You are an AI assistant specialized in analyzing research articles.\n",
    "        Your role is to provide concise, human-readable responses based on information from tools and conversation history.\n",
    "\n",
    "        Key instructions:\n",
    "        1. Use provided tools to gather information before answering.\n",
    "        2. Interpret tool results and provide clear, concise answers in natural language.\n",
    "        3. If you can't answer with available tools, state this clearly.\n",
    "        4. Don't provide information if tool content is empty.\n",
    "        5. Never include raw JSON, tool outputs, or formatting tags in responses.\n",
    "        6. Format responses as plain text for direct human communication.\n",
    "        7. Use clear formatting (e.g., numbered or bulleted lists) when appropriate.\n",
    "        8. Provide article details (e.g., DOI, citation count) in a conversational manner.\n",
    "\n",
    "        Act as a knowledgeable research assistant, offering clear and helpful information based on available tools and data.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check if the model is available\n",
    "        downloaded_models = []\n",
    "        for model in ollama.list()[\"models\"]:\n",
    "            downloaded_models.append((model[\"name\"].replace(\":latest\", \"\")))\n",
    "        assert self.model.replace(\":latest\", \"\") in downloaded_models, f\"Model {self.model} not found. Please pull the latest version from the server.\"\n",
    "\n",
    "        # Check if the selected model supports tool calling\n",
    "        # for more information, visit https://ollama.com/blog/tool-support\n",
    "        assert self.model.split(\":\")[0] in [\"llama3.1\", \"command-r-plus\", \"mistral-nemo\", \"firefunction-v2\"], f\"Model {self.model} does not support tool calling. Please select a different model.\"\n",
    "\n",
    "        if len(self.tools) == 0:\n",
    "            print(f\"\\033[91mNo tools provided! Please add tools to the assistant.\\033[0m\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Assistant, powered by {self.model.split(':')[0]}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def list_tools(self):\n",
    "        \"List the available tools in the assistant.\"\n",
    "        for tool in self.tools.keys():\n",
    "            print(tool)\n",
    "\n",
    "    def get_tools_schema(self):\n",
    "        \"Return the JSON schema for the available tools.\"\n",
    "        return [func.json_schema for func in self.tools.values()]\n",
    "\n",
    "    @json_schema_decorator\n",
    "    def describe_tools(self) -> str:\n",
    "        \"\"\"Use this tool when asked about the assistant's available tools and capabilities.\n",
    "\n",
    "        Returns:\n",
    "            str: A string with the descriptions of the available tools.\n",
    "        \"\"\"\n",
    "        return f\"Available tools are: {self.get_tools_schema()}\\n State your capabilities based the available tools in a conversational manner.\"\n",
    "        # return f\"{self.pprint_tools()}\\n State your capabilities based the available tools in a conversational manner.\"\n",
    "\n",
    "    def chat(self, prompt: str, show_progress: bool = False):\n",
    "        \"\"\"\n",
    "        Start a conversation with the AI assistant.\n",
    "\n",
    "        Args:\n",
    "            prompt (str): The user's prompt or question.\n",
    "            show_progress (bool): Whether to show the step-by-step progress of the fuction calls, including the tool calls and tool outputs. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            str: The AI assistant's response.\n",
    "        \"\"\"\n",
    "        # At the start of the conversation, if no messages are provided, add the system message and user prompt\n",
    "        if not self.messages:\n",
    "            self.messages = [\n",
    "                {'role': \"system\", 'content': self.sys_message},\n",
    "                {'role': 'user', 'content': prompt},\n",
    "            ]\n",
    "        else:\n",
    "            self.messages.append({'role': 'user', 'content': prompt})\n",
    "\n",
    "        # Generate JSON schemas for the available tools\n",
    "        tools_schema = self.get_tools_schema()\n",
    "\n",
    "        # Make a request to the LLM to select a tool\n",
    "        if show_progress: print(\"Selecting tools...\\n\")\n",
    "        response = ollama.chat(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            tools=tools_schema,\n",
    "            stream=False, # Set to False to avoid streaming the tool calls\n",
    "        )\n",
    "\n",
    "        # Add the model's response to the conversation history\n",
    "        if response.get('message', {}).get('tool_calls'):\n",
    "            if show_progress: print(response['message']['tool_calls']) # Uncomment for debugging\n",
    "            self.messages.append(\n",
    "                {'role': 'assistant', 'tool_calls': response['message']['tool_calls']}\n",
    "                )\n",
    "        else:\n",
    "            # print(\"LLM response (not added to the conversation history):\", response['message']['content']) # Uncomment for debugging\n",
    "            self.messages.append(\n",
    "                {'role': 'assistant', 'tool_calls': []}\n",
    "                )\n",
    "            print(f\"\\033[91mNo tool calls found in the response. Adding an empty tool_calls list to the conversation history. Aborting...\\033[0m\\n\")\n",
    "            return None # Abort the function if no tool calls are found in the response. Goal is to force the assistant to use a tool. We will generate a tool for generic responses.\n",
    "\n",
    "        # Call the function if a tool is selected\n",
    "        for tool in response['message']['tool_calls']:\n",
    "            # print(\"Arguments:\", tool['function']['arguments'])\n",
    "            function_to_call = self.tools[tool['function']['name']]\n",
    "            if show_progress: print(f\"Calling {tool['function']['name']}() with arguments {tool['function']['arguments']}...\\n\")\n",
    "            args = tool['function']['arguments']\n",
    "\n",
    "            try:\n",
    "                function_response = function_to_call(**args)\n",
    "                # print(f\"Function response type: {type(function_response)}\\n\") # Uncomment for debugging\n",
    "                # print(f\"Function response: {function_response}\\n\") # Uncomment for debugging\n",
    "                function_response = str(function_response) if function_response is not None else \"\"\n",
    "                # assert isinstance(function_response, str), \"Function response must be a string.\"\n",
    "            except Exception as e:\n",
    "                function_response = f\"Error: {e}\"\n",
    "\n",
    "                if show_progress: print(f\"Function response:\\n{function_response}\\n\")\n",
    "            # Add the fucntion response to the conversation history\n",
    "            self.messages.append( \n",
    "                {\n",
    "                    'role': 'tool',\n",
    "                    'content': function_response,\n",
    "                }\n",
    "            ) \n",
    "\n",
    "        # Make a second request to the LLM with the tool output to generate a final response\n",
    "        if show_progress: print(\"Generating final response...\")\n",
    "        response = ollama.chat(\n",
    "            model=self.model,\n",
    "            format=\"\", # Set to empty string to avoid JSON formatting; If JSON formatting is needed, set to \"json\"\n",
    "            messages=self.messages,\n",
    "            stream=self.stream,\n",
    "        )\n",
    "\n",
    "        # Advanced parameters (optional):\n",
    "        # keep_alive: controls how long the model will stay loaded into memory following the request (default: 5m)\n",
    "        # options: additional model parameters listed in the documentation for the Modelfile such as temperature\n",
    "        # for more information, visi:\n",
    "        # https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "        # https://github.com/ollama/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values\n",
    "\n",
    "        # Show the response message and add it to the conversation history\n",
    "        response_message = show_response(response)\n",
    "        # print(response_message)\n",
    "        self.messages.append({'role': 'assistant', 'content': response_message})\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "try:\n",
    "    assistant = Assistant()\n",
    "    assistant.chat(\"Hi\", show_progress=True)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def add_to_class(Class: type):\n",
    "    \"\"\"Register functions as methods in a class that has already been defined.\"\"\"\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@add_to_class(Assistant)\n",
    "def show_conversion_history(self):\n",
    "    \"\"\"Display the conversation history.\"\"\"\n",
    "\n",
    "    # ANSI escape code for blue and red text\n",
    "    BLUE = \"\\033[94m\"\n",
    "    BOLD = \"\\033[1m\"\n",
    "    GREY = \"\\033[90m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "\n",
    "    for message in self.messages:\n",
    "        if message['role'] != 'system':\n",
    "            if message['role'] == 'user':\n",
    "                print(f\"{BOLD}User:{RESET} {message['content']}\\n\")\n",
    "            elif message['role'] == 'assistant':\n",
    "                if 'content' in message and message['content']:\n",
    "                    print(f\"{BOLD}{BLUE}Assistant response:{RESET} {BLUE}{message['content']}{RESET}\\n\")\n",
    "                if 'tool_calls' in message and message['tool_calls']:\n",
    "                    print(f\"{BOLD}{BLUE}Assistant function calls:{RESET} \", end='')\n",
    "                    for tool in message['tool_calls']:\n",
    "                        print(f\"{BLUE}{tool['function']['name']}() with arguments {tool['function']['arguments']}{RESET}\\n\")\n",
    "            elif message['role'] == 'tool':\n",
    "                # convert str to list\n",
    "                if isinstance(message['content'], str):\n",
    "                    message['content'] = [message['content']]\n",
    "                for fn_return in message['content']:\n",
    "                    print(f\"{BOLD}{GREY}Function return:{RESET} {GREY}{fn_return}{RESET}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@add_to_class(Assistant)\n",
    "def clear_conversion_history(self):\n",
    "    \"\"\"Clear the conversation history.\"\"\"\n",
    "    self.messages = [{'role': \"system\", 'content': self.sys_message},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "try:\n",
    "    assistant.clear_conversion_history()\n",
    "    assert assistant.show_conversion_history() == None\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@add_to_class(Assistant)\n",
    "def pprint_tools(self):\n",
    "    for tool in self.get_tools_schema():   \n",
    "        print(f\"\"\"* Tool name: {tool.get(\"function\", {}).get(\"name\", \"No name available.\")}\n",
    "    Description: {tool.get(\"function\", {}).get(\"description\", \"No description available.\")}\n",
    "        \"\"\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# remember to save the notebook before running this command\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "assistant = Assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Tell me about your capabilities.\",\n",
    "    \"Which PDF files do you have access to in the local data directory?\",\n",
    "    \"Does this document have a title?\",\n",
    "    \"Summarize the content of this file.\",\n",
    "    \"How often has the article with the DOI 10.3389/fimmu.2022.856497 been cited?\",\n",
    "    \"Has this article been archived in Semantic Scholar? Can you provide a TLDR summary of the article with the DOI 10.3389/fimmu.2022.856497?\",\n",
    "    \"Can you provide the correcponding PMID for another article with the DOI 10.1126/science.adh4059?\",\n",
    "    \"What is the capital of France?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# for prompt in prompts:\n",
    "#     assistant.chat(prompt)\n",
    "#     print(\"\\n-----------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "assistant.show_conversion_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
