{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check environment, branch, downloaded models and server status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"scholaris-env\" not in sys.executable: # Check if the environment is activated\n",
    "    raise Exception(\"Activate the scholaris-env environment\")\n",
    "    \n",
    "current_branch = %system git branch --show-current # Get the current branch\n",
    "if current_branch[0] != \"demo\":\n",
    "    raise Exception(\"Switch to the 'demo' branch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)\n",
    "models_list = result.stdout\n",
    "if \"llama3.1:latest\" not in [word.strip() for line in models_list.splitlines() if line.strip() for word in line.split()]:\n",
    "    raise Exception(\"The 'llama3.1:latest' model is not available\")\n",
    "print(models_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(\"http://localhost:11434\")\n",
    "if response.status_code != 200:\n",
    "    raise Exception(\"The server is not running\")\n",
    "!curl -X GET \"http://localhost:11434\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a response\n",
    "# !curl http://localhost:11434/api/generate -d '{\"model\": \"llama3.1\", \"prompt\":\"Why is the sky blue?\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat with the model\n",
    "# !curl http://localhost:11434/api/chat -d '{\"model\": \"llama3.1\", \"messages\": [{ \"role\": \"user\", \"content\": \"why is the sky blue?\" }]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholaris.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = Assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = assistant.chat(\"Briefly tell me about the tools you have available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant.list_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assistant.pprint_tools()\n",
    "# assistant.get_tools_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = assistant.chat(\"Which PDF files do you have access to in the local data directory\", show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = assistant.chat(\"Does this document have a title?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = assistant.chat(\"\"\"\n",
    "Tell me the doi of the article with the following title:\n",
    "'Harnessing large language models (LLMs) for candidate gene prioritization and selection'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assistant.show_conversation_history(show_function_calls=True)\n",
    "assistant.show_conversation_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assistant.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run ../scholaris/ui.py --browser.serverAddress localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scholaris-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
