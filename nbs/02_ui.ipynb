{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Interfaces\n",
    "\n",
    "> Scholaris has primarily been developed to work in a **[Jupyter notebook](https://jupyter.org/)** environment, utilizing a code-first approach. The higher-level `Assistant` class and its methods are user-friendly and can be seamlessly integrated with Python's built-in functions. However, if you prefer a web-browser-based application with a graphical user interface to interact with LLMs and utilize the tools available through Scholaris, you can use the **Streamlit app** as described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{layout-ncol=2}\n",
    "![Jupyter](jupyter.png)\n",
    "\n",
    "![Streamlit](streamlit.png)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working in a Jupyter notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholaris.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mLoaded Semantic Scholar API key from the environment variables.\u001b[0m\n",
      "\u001b[90mLoaded email address from the environment variables.\u001b[0m\n",
      "\u001b[90mA local directory /Users/user2/GitHub/scholaris/data already exists for storing data files. No of files: 1\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assistant = Assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can assist with a variety of tasks, including:\n",
      "\n",
      "* Extracting text from PDF files\n",
      "* Retrieving titles and first authors of research articles\n",
      "* Summarizing local documents (PDF, markdown, or text)\n",
      "* Describing Python code in local files\n",
      "* Converting IDs (PMIDs, PMCIDs, DOIs) using the id_converter_tool\n",
      "* Querying OpenAlex API for article metadata based on title, PMID, PMCID, or DOI\n",
      "* Querying Semantic Scholar Academic Graph API for article metadata based on title, PMID, or DOI\n",
      "\n",
      "Please let me know how I can assist you with any of these capabilities!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I can assist with a variety of tasks, including:\\n\\n* Extracting text from PDF files\\n* Retrieving titles and first authors of research articles\\n* Summarizing local documents (PDF, markdown, or text)\\n* Describing Python code in local files\\n* Converting IDs (PMIDs, PMCIDs, DOIs) using the id_converter_tool\\n* Querying OpenAlex API for article metadata based on title, PMID, PMCID, or DOI\\n* Querying Semantic Scholar Academic Graph API for article metadata based on title, PMID, or DOI\\n\\nPlease let me know how I can assist you with any of these capabilities!'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant.chat(\"Tell me about your tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "To list the files in the local data directory that has been created at initialization, simply use the Python built-in `os` module. Pass the assistant's `data_dir` attribute as an argument to the `os.listdir()` function, like so:\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jci.insight.144499.v2.pdf']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(assistant.dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "You can use Python's built-in functions to copy files from a designated source (e.g., Downloads) to the local data directory that was created at initialization. For example, to copy a file named `example.md` from the Downloads directory to the local data directory, use the following code:\n",
    "```python\n",
    "import shutil\n",
    "shutil.copy(os.path.expanduser('~/Downloads/example.md'), assistant.dir_path)\n",
    "```\n",
    "\n",
    "Likewise, to remove a file from the local data directory, use the following code:\n",
    "```python\n",
    "os.remove(os.path.join(assistant.dir_path, 'example.md'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the assistant with Streamlit\n",
    "\n",
    "To use the assistant with [**Streamlit**](https://streamlit.io/), you need to install the [Streamlit package](https://pypi.org/project/streamlit/). \n",
    "\n",
    ":::{.callout-note}\n",
    "Remember to set up a virtual environment for your project before installing Streamlit. This will help you avoid conflicts with other packages that you may have installed in your base environment.\n",
    ":::\n",
    "You can install Streamlit  using pip:\n",
    "\n",
    "```sh\n",
    "pip install streamlit\n",
    "```\n",
    "\n",
    "Then, download the `ui.py` file from the `scholaris` directory in the Scholaris repository. Run the following command in the terminal to download the file to your current working directory:\n",
    "\n",
    "```sh\n",
    "wget https://raw.githubusercontent.com/nicomarr/scholaris/main/ui.py\n",
    "```\n",
    "\n",
    "If wget is not installed on your local computer, you may also use curl, like so:\n",
    "```sh\n",
    "curl -O https://raw.githubusercontent.com/nicomarr/scholaris/main/ui.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the streamlit app, use execute following command in the terminal/shell:\n",
    "```sh\n",
    "!streamlit run ./scholaris/ui.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "If you don't want to download the `ui.py` file from Github, you can also copy the code from below and paste it into a new Python file in your working directory. Then run it using the command `streamlit run <filename>.py`.\n",
    "::: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scholaris/ui.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scholaris/ui.py\n",
    "from scholaris.core import *\n",
    "import streamlit as st\n",
    "import ollama\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def download_conversation_history():\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d_%Hh%Mm%Ss\")\n",
    "    conversation_history = st.session_state.assistant.messages\n",
    "    filename = f\"conversation_history_{now}.json\"\n",
    "    return json.dumps(conversation_history, indent=2), filename\n",
    "\n",
    "def show_local_data(dir_path: Path) -> None:\n",
    "    try:\n",
    "        for file in dir_path.iterdir():\n",
    "            st.write(f\"{file.name}\")\n",
    "    except Exception as e:\n",
    "        st.write(f\"Error: {e}\")\n",
    "    \n",
    "def handle_file_uploads(uploaded_files):\n",
    "    dir_path = st.session_state.assistant.dir_path\n",
    "    if not dir_path.exists():\n",
    "        return\n",
    "\n",
    "    for uploaded_file in uploaded_files:\n",
    "        file_path = st.session_state.assistant.dir_path / uploaded_file.name\n",
    "        if file_path.exists():\n",
    "            continue\n",
    "        try:\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(uploaded_file.getbuffer())\n",
    "            if \"uploaded_files\" not in st.session_state:\n",
    "                st.session_state[\"uploaded_files\"] = []\n",
    "            st.session_state[\"uploaded_files\"].append(file_path)\n",
    "        except Exception as e:\n",
    "            error_placeholder = st.empty()\n",
    "            error_placeholder.error(f\"Error saving {uploaded_file.name}: {str(e)}\")\n",
    "            time.sleep(1)  # Display error for 1 second\n",
    "            error_placeholder.empty()\n",
    "    uploaded_files = []\n",
    "    \n",
    "def delete_uploaded_files():\n",
    "    if \"uploaded_files\" in st.session_state and st.session_state[\"uploaded_files\"] != []:\n",
    "        file_count = 0\n",
    "        for file_path in st.session_state[\"uploaded_files\"]:\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                file_count += 1\n",
    "            except Exception as e:\n",
    "                error_placeholder = st.empty()\n",
    "                error_placeholder.error(f\"Error deleting {file_path}: {str(e)}\")\n",
    "                time.sleep(1)  # Display error for 1 seconds\n",
    "                error_placeholder.empty()\n",
    "        st.write(f\"{file_count} file(s) deleted.\")\n",
    "        st.session_state.uploaded_files = []\n",
    "\n",
    "def get_last_tool_names(messages):\n",
    "    \"\"\"Returns the tool names from the most recent tool call in the messages.\"\"\"\n",
    "    tool_names = []\n",
    "    for message in reversed(messages):\n",
    "        if message[\"role\"] == \"assistant\" and \"tool_calls\" in message:\n",
    "            for fn in message[\"tool_calls\"]:\n",
    "                name = fn[\"function\"].get(\"name\")\n",
    "                if name:\n",
    "                    tool_names.append(name)\n",
    "            break # Exit the loop after the first occurrence\n",
    "    return \", \".join(tool_names) if tool_names else \"No tools used.\"\n",
    "\n",
    "# Page configuration\n",
    "st.set_page_config(\n",
    "        page_title=\"Scholaris\", \n",
    "        page_icon=\":speech_balloon:\",\n",
    "        layout=\"wide\", \n",
    "        initial_sidebar_state=\"collapsed\", \n",
    "        menu_items={\n",
    "            \"About\": \"This is a graphical user interface for Scholaris, a conversational AI assistant for academic research.\",\n",
    "            \"Get Help\": \"https://github.com/nicomarr/scholaris/blob/main/nbs/02_ui.ipynb\",\n",
    "            \"Report a Bug\": \"https://github.com/nicomarr/scholaris/issues/new\"\n",
    "        }\n",
    "        )\n",
    "\n",
    "# Initialize the assistant if not already in session state\n",
    "if \"assistant\" not in st.session_state:\n",
    "    try:\n",
    "        st.session_state.assistant = Assistant(model=\"llama3.1\", dir_path=\"./data\")\n",
    "    except Exception as e:\n",
    "        if \"[Errno 61] Connection refused\" in str(e):\n",
    "            st.error(f\"\"\"An error occurred: {e}. Please make sure Ollama is installed on your local computer and the server is running.\n",
    "            For troubleshooting, refer to the Ollama docs of GitHub:\n",
    "            [README](https://github.com/ollama/ollama/blob/main/docs/README.md)\n",
    "            [FAQ](https://github.com/ollama/ollama/blob/main/docs/faq.md).\n",
    "            \"\"\")\n",
    "        else:\n",
    "            st.error(f\"An error occurred: {e}\")\n",
    "        st.stop()\n",
    "\n",
    "# Initialize other session state variables\n",
    "if \"uploaded_files\" not in st.session_state:\n",
    "    st.session_state.uploaded_files = []\n",
    "\n",
    "# Start conversation\n",
    "if len(st.session_state.assistant.messages) < 2: # <2 because the assistant is initialized with a system message\n",
    "    st.session_state.assistant.messages.append({\"role\": \"assistant\", \"content\": \"How can I help you?\"})\n",
    "\n",
    "if st.session_state.assistant:\n",
    "    with st.sidebar:\n",
    "        # Set up the sidebar\n",
    "        st.title(\"Scholaris\")\n",
    "        st.caption(str(st.session_state.assistant))\n",
    "        # Conversation History Section\n",
    "        st.write(\"---\")\n",
    "        st.subheader(\"Conversation History\") \n",
    "        st.download_button(label=\"Download\", \n",
    "            help=\"Download the conversation history as a JSON file.\",\n",
    "            data=download_conversation_history()[0],\n",
    "            file_name=download_conversation_history()[1],\n",
    "            mime=\"text\")\n",
    "\n",
    "        if st.button(label=\"Reset\", type=\"primary\", \n",
    "            help=\"Click to restart the conversation.\", \n",
    "            key=\"reset_messages\"):\n",
    "                st.session_state.assistant.clear_conversion_history()\n",
    "                st.session_state.assistant.messages.append({\"role\": \"assistant\", \"content\": \"How can I help you?\"})\n",
    "                st.write(\"Conversation history cleared!\")\n",
    "            # st.rerun()  # Rerun the script to update the chat interface and the sidebar\n",
    "\n",
    "        # Local Data Section\n",
    "        st.write(\"---\")\n",
    "        st.subheader(\"Local Data\")\n",
    "        dir_path = st.session_state.assistant.dir_path\n",
    "        with st.expander(\"Data files\"): \n",
    "            show_local_data(dir_path)\n",
    "\n",
    "        # File Upload Section\n",
    "        uploaded_files = st.file_uploader(\n",
    "            label=\"Upload files\",\n",
    "            type=['pdf','txt','md','markdown','py'],\n",
    "            accept_multiple_files=True,\n",
    "            )\n",
    "        if uploaded_files:\n",
    "            handle_file_uploads(uploaded_files)\n",
    "\n",
    "        # Delete Uploaded Files Section\n",
    "        if st.session_state.uploaded_files:\n",
    "            if st.button(\n",
    "                label=\"Delete uploaded files\", \n",
    "                type=\"primary\",\n",
    "                help=\"Only uploaded files will be deleted. Already existing files will not be deleted.\", \n",
    "                key=\"delete_data_files\"\n",
    "            ):\n",
    "                delete_uploaded_files()\n",
    "\n",
    "        st.write(\"---\")\n",
    "        st.write(\"Source code available on [GitHub](https://github.com/nicomarr/scholaris/blob/main/scholaris/ui.py)\")\n",
    "\n",
    "\n",
    "    # Main Chat Interface\n",
    "    for msg in st.session_state.assistant.messages: # Display chat messages from history on app rerun\n",
    "        if msg[\"role\"] == \"system\" or msg[\"role\"] == \"tool\": # Skip system message and tool returns\n",
    "            continue\n",
    "        elif msg[\"role\"] == \"assistant\" and \"content\" not in msg: # Skip tool calls where no content is returned\n",
    "            continue\n",
    "        with st.chat_message(msg[\"role\"]):\n",
    "            st.markdown(msg[\"content\"])\n",
    "    \n",
    "    if prompt := st.chat_input(): # Await user input\n",
    "        with st.chat_message(\"user\"): # Display user message in chat message container\n",
    "            st.markdown(prompt)\n",
    "        with st.spinner(\"Thinking...\") as status: # Display status while assistant is processing\n",
    "            with st.chat_message(\"assistant\"):\n",
    "                stream = st.session_state.assistant.chat(prompt=prompt, redirect_output=True)\n",
    "                try:\n",
    "                    if stream:\n",
    "                        response = st.write_stream(stream)\n",
    "                    else:\n",
    "                        st.markdown(\"I'm sorry, I am unable to respond to that query.\")\n",
    "                except Exception as e:\n",
    "                    st.error(f\"An error occurred: {e}\")\n",
    "        with st.popover(\"Tools used\"):\n",
    "            st.markdown(get_last_tool_names(st.session_state.assistant.messages))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
